# 人脸图片伪造和鉴伪技术研究

韩胜杰1 张义2 葛涵涛2

( 1. 中国人民解放军 61889 部队，北京 100010;2. 中国信息通信研究院泰尔终端实验室，北京 100191)

摘要: 近年来，基于人工智能技术的应用逐渐成熟落地，在为大家工作生活带来便利的同时，关于隐私和安全伦理方面的隐患逐渐凸显。相关技术带来的一系列社会问题，同时也引起了政府部门的重视。从技术角度，结合各自的算法特点，分别对现有常见人脸图片伪造以及鉴伪算法进行了比较全面的梳理，并为后续相关政策标准研究提供了参考。

关键词: 人脸图片伪造; 人脸图片鉴伪; 人工智能; 安全伦理

# 1 引言

2019 年 8 月30 日，各大手机应用市场上线了一款由北京陌陌科技有限公司开发的 AI 换脸 APP。据介绍，用户仅仅需要上传一张自己的正脸照片，该软件即可通过 AI 技术把视频中的明星面部换掉，生成效果逼真的用户自己的视频片段。该 APP 一经推出就在网络上迅速走红，同时也引发了严重的隐私争议。2019年9 月 3 日，针对该软件中用户隐私协议不规范、存在数据泄露风险等问题，工业和信息化部网络安全局对北京陌陌科技有限公司相关负责人进行了约谈，要求其严格按照国家相关法律法规组织开展自查整改，强化用户个人安全信息保护。

近年来，人工智能技术获得了极大关注，相关应用也纷纷落地，在为大家的工作生活带来便利的同时，也带来了隐私和数据安全的隐患。这次“换脸”风波，已经不是人工智能技术引起的第一次巨大争议了。之前的“DeepNude”和“DeepFakes”事件，就曾引起了国内外相关专家针对人脸伪造技术侵犯个人隐私以及肖像权的广泛讨论。相关技术带来的一系列社会问题，同时也引起了政府部门的重视。2019 年 6 月 13 日，美国众议院情报委员会召开关于人工智能深度伪造的听证会，针对基于人工智能的深度伪造技术对国家、社会和个人的风险和防范措施进行了讨论。本文从技术角度，对现有人脸图片伪造和鉴伪技术进行了比较全面的梳理，以期对人脸安全的相关政策和标准制定提供参考。

# 2 人脸图片伪造技术概述

人脸图片( 视频) 伪造，是2020 年以来计算机视觉领域一个逐渐热门的话题，相关技术也随着新算法的改进而逐渐迭代提高。最早实现的人脸互换技术是基于特征匹配算法实现的，即通过提取一张脸中的眉毛、眼睛等特征信息再匹配到另一张脸上。该方法不需要训练，不用数据集，只是效果比较差，合成的图片很不自然，也无法修改表情。

# 2.1 Face2Face

真正使人脸伪造( 换脸) 图片质量获得极大提升的，是对抗生成网络( Generative Adversarial Networks，GAN) 算法的提出。对于给定的源图片和目标图片，GAN 可以学习到两种图片的转换关系。德国纽伦堡大学 Justus Thies 在 2016 年发表了一篇基于 GAN 的关于 Face2Face 算法的论文［1］，该算法可以把视频中一个人的面部特征、表情甚至说话时面部肌肉的变化实时地复制到另一个视频中的角色上。这不仅是第一个能够实现实时面部转换的算法，而且其真实程度几乎可以以假乱真。Justus Thies 的论文对“换脸”技术做出了详细的解释: 首先使用算法重构目标人脸和源人脸的脸型特征，并实时追踪目标人脸和源人脸的表情，接着使用设计的变形函数，使用源人脸的形状和光照对目标人脸进行重新渲染，最终使目标人脸和背景进行复合。与现有模型不同，Face2Face 算法仍然维持了目标人脸的嘴部形状，最终的表现具有极高的实时性和真实性。

# 2.2 DeepFakes

2017 年 12 月，一 个 名 为“DeepFakes”的 用 户 在Reddit 上发布了一个“假视频”，视频中的明星人脸其实是后期加上的，但是看起来几乎毫无破绽。这个被命名为 DeepFakes 算法的核心是“自动编码器”，是早期深度神经网络模型的一种。自动编码器通过将接收的数据压缩编码，并从这个编码中重新生成原始数据。该算法的原理是: 假定使用自动编码器可以把任意人脸 A 通过变换得到人脸 B，其中人脸 B 表示任意一张人脸，则可以通过大量数据训练网络学会从人脸 B 解码修复至人脸A，最终模型即可从任意一张脸变换成人脸 A。Korshunov 和 Pavel 在另一篇文章中试验表明［2］，使用DeepFakes 算法生成的伪造人脸可以欺骗大部分基于深度学习的人脸识别和监测系统。shaoanlu［3］对DeepFakes 算法进行了改进，在原自动编码器的架构中加入了“对抗损失”和“感知损失”两个函数，提出了“faceswap-GAN”模型，获得了更自然真实的伪造人脸图片。随后 DeepFakes 还推出了一款应用程序，可以使用户只用简单几步即可创建换脸的视频，但该应用程序很快就因为引起大量批评而被各大网站封杀。

# 2.3 HeadOn

2018 年 6 月，“Face2Face”团队在其发表的论文中发布了他们新开发的“HeadOn”技术［4］。HeadOn 技术可以被理解为Face2Face 技术的升级版，其核心将对变形代理( proxy) 的精确跟踪和基于视图的纹理相结合，进行视频的重新渲染。有关研究人员声称: “该系统为首个人体肖像视频实时的源到目标重演方法，实现了躯干运动、头部运动、面部表情和视线注视的迁移”。之前的相关技术虽然能够实时伪造视频中的人脸，但是头部和身体的姿态一直是保持不变的，而且视线方向也不会随着身体的移动而变化，导致生成的图片或视频有些不自然，HeadOn 技术弥补了这两方面的不足。如图 1 所示，HeadOn 技术生成的视频加入了人物身体、头部动作和视线的实时迁移，使得生成的视频中的人更加真实。

# 2.4 paGAN

2018 年 8 月，SIGGRAPH 2018 会议中一篇来自华裔教授黎颢团队的论文引起业界很大反响。他们开发了一 种 基 于 GAN 的 深 度 学 习 技 术，命 名 为“paGAN”［5］。如图 2 所示，paGAN 技术能够仅使用单幅照片生成人像视频，并以1000 帧每秒的速度对人脸进行跟踪。相对之前的视频对视频的换脸技术，paGAN 技术的提出进一步降低了人脸视频伪造的技术门槛。该方法先制作合理的 3D 网格，然后对输入图像和 3D 形状执行形状匹配和角度变换，接着使用他们自己开发的脸部追踪器 VGPT 追踪人脸的位置和细节状态。其最显著的特点就是速度非常惊人，在搭载 1080P 的个人电脑上，该追踪器的最高帧数可达1000; 即使在手机端，也可以达到60～90 每秒传输帧数( Frames Per Second，FPS) ，满足手机摄像头拍摄视频的帧数要求，即可以对视频人脸进行实时追踪和伪造。

![](images/6723f5c728d3e24e2788cf07f22ba9b68a526248b69a5137003bc77ab08183b7.jpg)  
图片来源： 《HeadOn:Real-timeReenactmentofHumanPortraitVideos》  
图 1 HeadOn 技术示例

![](images/23b193d30b3ba59754e24cce3f807006953acbcac62c30aa12b4c5c1f87a3f4f.jpg)  
图2 paGAN 技术生成的人脸视频示例

图片来源：https://www.sohu.com/a/245674103_473283

可以看出，随着相关研究的深入，人脸图像和视频的伪造质量愈加真实，门槛也越来越低，其中潜藏的用户数据安全和隐私方面的风险也日益凸显。基于个人和国家安全的考虑，相关部门已经高度关注人工智能技术被恶意使用的潜在风险，并呼吁联合学术界、产业界以及相关政府支撑部门的力量，共同做好前瞻技术的研究，及早掌握应对之策。

# 3 人脸图片鉴伪技术概述

2017 年 3 月15 日，央视315 晚会曝光了支付宝人脸识别系统的缺陷，现场演示了经过换脸后的照片成功完成了身份认证，进入了他人的账户。虽然支付宝团队在随后的回应中说明人脸识别只是支付宝的多重保护系统的一环，并不存在只用人脸即可登录的可能。但是，随着 paGAN 等仅使用一张图片即可生成实时人脸视频的算法开源于众，传统的基于人脸视频的“眨眨眼”“读出一段随机数字”等人脸鉴伪方法就变得更为不堪一击。

# 3.1 基于眨眼检测

2018 年 5 月，美 国 国 防 部 高 级 研 究 计 划 局( DAPRA) 资助了纽约州立大学研究团队一项名为“媒体内容鉴定”的研究。该研究团队通过研究发现，通过

GAN 技术生成的伪造人脸极少甚至不会眨眼，这是因为生成伪造人脸模型的训练集极少有闭眼的人脸图像。随后他们于 2018 年 8 月研发出全球首款“反变脸”的人工智能刑侦检测工具，以 AI 攻 AI。该工具通过检测视频中眼睛的状态，在特定的伪造人脸数据集上检测准确率可以达到 $9 9 \%$ 。但这也只是阶段性的成果，现有基于数据驱动的人工智能算法的典型特点是可以通过使用最新的特定数据进行调优，来弥补算法不足。这意味着这款伪造人脸检测工具的诞生，也仅仅是标志着人脸伪造和鉴伪技术之间的人工智能竞赛正式开始。

# 3.2 基于 CNN 和 LSTM

基 于 卷 积 神 经 网 络 ( Convolutional NeuralNetworks，CNN) 模型在图像识别和分类任务中的优秀表现，研究人员先后提出了一系列基于 CNN 的人脸鉴伪算法并取得了不错的效果。慕尼黑工业大学等高校的研究人员通过使用常见的 Face2Face、DeepFakes 和FaceSwap 等前文提到的人脸伪造算法生成了一个名为 FaceForensics $^ { + + }$ 的大型人脸伪造视频数据集［6］，该数据集包含来自 1000 个真实视频的 510，207 张图片和标签，以保证监督学习的有效性。Li Y 等作者在发表的论文中介绍了使用 XceptionNet 算法在该数据集上检测伪造人脸的试验，最终获得了最高 $9 9 . 0 8 \%$ 的检测准确率，远超人类观察者的正确率。Li Y 等还提出了一种基于检测面部扭曲伪影的人脸图像鉴伪方法［7］，且认为，当前的人脸伪造算法只能生成有限分辨率的图像，需要进一步扭曲这些图像来匹配源视频中的面部，这样就会在伪造的视频中留下扭曲的伪影，并会被卷积神经网络有效捕获。通过训练分类器，可以有效区分伪造视频。 $\mathrm { { H s u } ~ C ~ C }$ 提出了一种深度伪造辨别器( Deepfd)［8］，采用对比损失的方法来寻找由不同GAN 算法生成的伪造图像的典型特征，最后级联一个分类器来进行分类。试验表明 Deepfd 在几个最先进的 GAN 算法生成的虚假人脸图像数据集上获得了$9 4 . 7 \%$ 的鉴伪准确率。

Güera D 提出了一种基于 CNN 和长短记忆网络( Long Short Term Memory Network，LSTM ) 算法的人脸鉴伪方法［9］。因为目前大部分人脸伪造技术都是基于自动编码器或者 GAN 算法，所以生成的视频当前帧与前一帧之间是独立的，即存在帧不连续问题而使得前一帧的一些重要信息变化无法应用于当前帧。比如当视频中的光源有变化时，生成的伪造视频会有人眼难以观察到的像素异常变化。Li Y 等使用 CNN 来提取图像特征，再使用 LSTM 进行时序分析，利用视频时间维度上的信息变化进行识别。该方法在 600 个视频中获得了最高 $9 7 . 1 \%$ 的鉴伪准确率。同样地，使用$\mathrm { C N N + L S T M }$ 的方法，Li Y 等通过判断视频中人像是否眨眼来判断真假视频［10］，且将这种方法称之为长期递归 卷 积 网 络 ( Long-term Recurrent ConvolutionalNetworks，LRCN) 方法。LRCN 方法基于面部对齐以后眼睛周围的 6 个标签点使用 CNN 来提取特征，并使用 LSTM 算法进行序列学习与眼睛状态的预测，最终做出判别。如图 3 所示，第一行的真实人脸视频序列中，人物存在眨眼现象，而第二行的虚假视频中的人物则没有眨眼。

# 4 结束语

本次人工智能浪潮极大地推动了 AI 垂直行业的发展，给很多行业都带来了颠覆性的创新和发展，但在各行业迎接人工智能浪潮的同时，需防备其隐藏的隐私伦理安全风险。希望相关研究人员和从业人员坚持做正向的研究，杜绝人工智能技术给人类带来的伤害和威胁; 也希望相关支撑科研政策单位尽快完善人工智能相关产品、算法和框架的标准体系的建立，尽快推动行业标准化发展。只要国内科研力量加紧人工智能伪造图片鉴伪技术的研究，其可能带来的社会风险将得到最大限度的降低。

![](images/f5475ceed8a722ab38723738ac5c2c5ecb2efde511319d9916759bcc95c0594b.jpg)  
图片来源：http://www.aminoacid-jirong.com/news/9z2fq393qs2zzss.html  
图3 通过检测视频人物是否眨眼辨别虚假视频

# 参考文献

［1］Thies J，Zollhofer M ，Stamminger M ，et al. Face2Face: real-time face capture and reenactment of rgb videos ［C］/ /Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition，2016.   
［2］Korshunov P，Marcel S. Deepfakes: a new threat to face recognition? assessment and detection ［J ］． arXiv: 1812. 08685，2018.   
［3］GitHub. A denoising autoencoder $^ +$ adversarial losses and attention mechanisms for face swapping［E /OL］． ( 2019- 10-04) ［2020-06-01 ］． https: / /github. com /shaoanlu / faceswap-GAN.   
［4］Thies J，Zollhfer M ，Theobalt C，et al. Headon: realtime reenactment of human portrait videos ［J］． ACM Transactions on Graphics ( TOG) ，2018，37( 4) : 164.   
［5］ Nagano K，Seo J，Xing J，et al. paGAN: real-time avatars using dynamic textures［J］． ACM Trans. Graph. ， 2018，37( 6) : 258.   
［6］Rssler A， Cozzolino D， Verdoliva L， et al. Faceforensics $+ +$ : learning to detect manipulated facial images［J］． arXiv: 1901. 08971，2019.   
［7］Li Y，Lyu S. Exposing deepfake videos by detecting face warping artifacts［J］． arXiv: 1811. 00656，2018.   
［8］Hsu C C，Lee C Y，Zhuang Y X. Learning to detect fake face images in the wild ［C ］/ /2018 International Symposium on Computer， Consumer and Control ( IS3C) ． IEEE，2018.   
［9］Güera D， Delp E J. Deepfake video detection using recurrent neural networks ［C ］/ /2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance ( AVSS) . IEEE，2018.   
［10］Li Y，Chang M C，Lyu S. In ictu oculi: exposing ai created fake videos by detecting eye blinking［C］/ /2018 IEEE International Workshop on Information Forensics and Security ( WIFS) . IEEE，2018.

# 作者简介:

韩胜杰 中国人民解放军 61889 部队正高级工程师  
张义 中国信息通信研究院泰尔终端实验室战略规划与研究部工程师，博士，主要研究方向为人工智能  
葛涵涛 中国信息通信研究院泰尔终端实验室战略规划与研究部副主任，IoT 行业首席研究员

# Face image forgery and detection techniques review

HAN Shengjie1，ZHANG Yi2，GE Hantao2

( 1. People’s Liberation Army of China，61889，Beijing 100010，China; 2. CTTL Terminal Labs，China Academy of Information Communications Technology，Beijing 100191，China)

Abstract: In recent years，the application based on artificial intelligence technology has gradually matured and widely used. While the AI technology has brought convenience to people’s work and life，the hidden dangers of privacy and security ethics have gradually emerged. Furthermore，the social issues caused by related technologies have attracted great attention of government authorities. This paper reviews the existing face image forgery and its detection algorithms， providing references for the research on relevant policy standards.

Key words: face image forgery; face image forgery detection; artificial intelligence; security ethics

( 收稿日期: 2020－06－08)