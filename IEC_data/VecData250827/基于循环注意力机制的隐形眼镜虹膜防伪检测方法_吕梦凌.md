# 基于循环注意力机制的隐形眼镜虹膜防伪检测方法

吕梦凌， 何玉青\*， 杨峻凯， 金伟其， 张丽君北京理工大学光电学院光电成像技术与系统教育部重点实验室， 北京 100081摘要 虹膜纹理容易被纹理隐形眼镜隐藏甚至伪造，进而对虹膜识别系统的安全性构成了威胁。针对真实虹膜与纹理隐形眼镜伪造虹膜光学特性和纹理特征差异较小的问题，提出了一种循环注意力隐形眼镜虹膜防伪检测方法RAINet。利用循环注意力机制对能区分真伪虹膜的关键区域进行无监督定位，并通过多层级特征融合提升防伪检测精度，构建了端到端防伪检测网络，无需图像预处理即可直接进行真伪特征检测。采用MobileNetV2 作为特征分类网络，在保持检测精度的同时，减少了网络的参数量和计算量。在包含真实虹膜样本和隐形眼镜虹膜样本的两个公开数据库（IIITD CLI和ND 系列）上进行了实验验证。结果表明，RAINet 的检测精度优于其他防伪检测网络，在同传感器、跨传感器和跨数据库实验条件下的平均正确分类率分别可达到 $9 9 . 9 3 \% . 9 7 . 3 1 \%$ 和 $9 7 . 8 6 \%$ 。

关键词 机器视觉；纹理隐形眼镜；虹膜防伪检测；循环注意力机制；多层级特征融合中图分类号 TP391. 4 文献标志码 A

DOI：10.3788/AOS202242.2315001

# Anti-Spoofing Detection Method for Contact Lens Irises Based on Recurrent Attention Mechanism

Luƃ  Mengling, He Yuqing , Yang Junkai, Jin Weiqi, Zhang Lijun Key Laboratory of Photoelectronic Imaging Technology and System , Ministry of Education, School of Optics and Photonics, Beijing Institute of Technology, Beijing 100081, China

Abstract Iris textures are easily hidden or even forged by textured contact lenses, which further threatens the security of the iris recognition system.  Considering the tiny differences in the optical properties and texture features of authentic irises and irises forged by textured contact lenses, this paper proposes an anti-spoofing detection method for contact lens irises based on recurrent attention, namely recurrent attention iris net (RAINet).  Specifically, the recurrent attention mechanism is employed to locate the key regions that can be used to distinguish authentic irises from forged ones in an unsupervised manner, and multi-level feature fusion is applied to improve the anti-spoofing detection accuracy.  An end-to-end antispoofing detection network is built for the direct detection of authentic and forged features without image pre-processing. MobileNetV2 is used as the feature classification network to reduce the number of parameters and amount of computation of the network in addition to maintaining the detection accuracy.  Experimental verification is performed on two public databases (IIITD CLI and ND series) containing both authentic iris samples and contact lens iris samples.  The results show that the proposed RAINet outperforms other anti-spoofing detection networks in detection accuracy.  Its average correct classification rates under intra-sensor, inter-sensor, and inter-database experimental conditions reach $9 9 . 9 3 \%$ , $9 7 . 3 1 \%$ , and $9 7 . 8 6 \%$ , respectively.

Key words machine vision; textured contact lens; iris anti-spoofing detection; recurrent attention mechanism; multi-level feature fusion

# 1　 引        言

虹膜识别具有唯一性、稳定性和非接触性等优势，已在金融、海关和公安等重要的身份认证场景中得到广泛应用［1］。基于近红外光能穿透虹膜并被结缔组织和色素细胞吸收的光学特性，虹膜传感器普遍会在近红外波段中采集虹膜纹理［2］。佩戴隐形眼镜会对进入人眼及其反射的光线产生影响，透明隐形眼镜基本不改变虹膜纹理，而纹理隐形眼镜会使虹膜覆盖上隐形眼镜印刷的纹理和色彩。由于隐形眼镜的透光特性，故佩戴纹理隐形眼镜仍然能在虹膜传感器上获得带有纹理的虹膜图像，从而可以隐藏甚至伪造虹膜纹理。防伪检测是保证生物特征识别安全性的重要环节［3］。文献［4］指出，佩戴纹理隐形眼镜是目前隐蔽性最好、检测难度最大的虹膜伪造手段，会严重影响虹膜识别系统的安全性，故针对是否佩戴纹理隐形眼镜进行虹膜防伪检测尤为重要。

传统虹膜防伪检测方法基于虹膜的光学特性或纹理特征进行检测。He 等［5］利用虹膜在不同波段光照下的反射率特性差异，通过计算虹膜与巩膜的反射率比来区分真实虹膜和隐形眼镜伪造虹膜，但该方法需要使用多波段光源并多次采集虹膜图像，实时性较差。Lee 等［6］通过检测眼睑曲率、眨眼反应和瞳孔缩放等多种人眼光学特性来综合判别真伪虹膜，但该方法需要进行虹膜定位分割预处理，在效率和成本方面并无优势。Daugman［7］使用傅里叶变换分析虹膜图像的频谱，可以区分真实虹膜和隐形眼镜伪造虹膜，但该方法无法处理离焦或模糊的图像，也无法应对多层印刷的隐形眼镜。He 等［8］先将归一化后的虹膜图像划分出子区域，再提取子区域的局部二进制特征，利用AdaBoost 选择有效特征进行活体虹膜分类。Doyle 和Bowyer［9］提取了虹膜图像中的二进制统计图像特征，以支持向量机（SVM）进行真伪虹膜分类。Lovish等［10］提出了基于局部相位量化和二进制Gabor 模式的虹膜纹理检测方法。Agarwal 等［11］根据归一化虹膜图像的特点，设计了基于中心像素和六边形邻域的特征描述子 $\mathrm { L B H _ { X } E P }$ ，再结合SVM 进行真伪虹膜分类。这些利用纹理特征检测的方法对图像质量有一定的要求，在跨传感器、跨数据库检测时性能有所降低。

随着深度学习在生物特征识别领域中的发展，研究人员陆续提出了一些能自适应提取深度特征的虹膜防伪检测网络。Raghavendra 等［12］设计了基于深度卷积神经网络（CNN）的隐形眼镜检测网络ContlensNet，先通过圆检测对虹膜环状区域进行定位分割，再将分割后的区域归一化成矩形并分解为小块依次输入到15 层的卷积神经网络中，最后平均所有小块的结果进行综合判别。Chen 和 Ross［13］提出了多任务卷积神经网络（MTCNN），该网络可以对虹膜图像同时进行目标检测和活体检测。Gupta 等［14］通过改变网络连接方式设计了并行结构的虹膜防伪检测网络MVANet，利用多分支分类提升了跨数据库检测真伪虹膜的效果。

Singh 等［15］提出了具有通用性的分层隐形眼镜检测网络 GHCLNet，使用了两个相同的 ResNet-50 构建，该网络可以直接检测未经定位分割预处理的原始虹膜图像。Choudhary 等［16］利用基于 DenseNet $+$ SVM 的密集连接隐形眼镜检测网络DCLNet 对原始虹膜图像进行直接检测，并在网络层之间采用密集连接以学习到更丰富的虹膜特征信息。基于深度学习的虹膜防伪检测网络无需手动设计和提取特征描述子［17］，不仅提高了训练优化效率，还提升了准确率，但仍存在一定的局限性：1）部分网络需要输入虹膜环状区域定位分割、分块等预处理后的虹膜图像，会对网络的实时性和泛化性产生影响［16］；2）部分网络将未经预处理的虹膜图像直接输入，会在网络传播过程中产生冗余的背景信息，在一定程度上会影响网络的准确性和泛化性；3）为了提升网络的检测精度，部分网络使用较为复杂的结构，这对硬件设备的算力和内存都提出了很高的要求，导致网络难以在小型化、低功耗的边缘计算设备上应用部署［18］。

鉴于上述背景，本文提出了一种基于循环注意力卷积神经网络（RACNN）［19］的循环注意力隐形眼镜虹膜防伪检测网络（RAINet）。将解决细粒度图像分类问题的循环注意力机制应用于纹理隐形眼镜伪造虹膜的防伪检测中，该网络能对可以区分真伪虹膜的关键区域进行无监督定位，并融合多层级尺度特征以实现对真实虹膜和纹理隐形眼镜伪造虹膜的有效判别。考虑实际应用需求，在特征提取部分采用轻量级 CNN（MobileNetV2）［20］，以更好地平衡网络的检测精度和运算成本。在两个公开数据库（IIITD CLI 和 ND 系列）上验证了RAINet 的可行性与先进性。

# 2 RAINet 网络设计

# 2. 1 设计思路

虹膜传感器采集到的同一人的真实虹膜图像和纹理隐形眼镜虹膜图像，如图 1 所示。在原始虹膜图像中，真实虹膜与纹理隐形眼镜伪造虹膜非常相似，虽然真实虹膜与纹理隐形眼镜伪造虹膜的特征差异非常微小，但是两者还是存在一定的特征差异［18］：1）纹理隐形眼镜边缘存在一定的过渡区域，该区域与巩膜的交界处会产生比真实虹膜边缘更显著的灰度变化；2）纹理隐形眼镜印刷的特征一般是有规律性的散状或点状纹理，而真实虹膜的纹理特征是一些随机生成的不规则形状纹理。因此，对纹理隐形眼镜虹膜进行防伪检测的关键在于如何有效检测这些微小特征差异。

为了有效地针对关键区域的特征差异进行防伪检测，将纹理隐形眼镜虹膜防伪检测看作细粒度图像分类进行处理。真实虹膜与纹理隐形眼镜伪造虹膜的相似度极高，且图像中大部分区域被相近的巩膜、眼睑和睫毛等背景特征占据［21］，从而使得虹膜图像的类间差异较小。虹膜传感器的非接触采集受到光照、角度、姿态和遮挡等方面的影响，使得虹膜图像的类内差异较大，故真伪虹膜图像与细粒度图像的特点一致。另外，基于图像纹理特征的传统虹膜防伪检测方法使用经过虹膜定位分割预处理后的归一化虹膜图像进行特征提取和检测，这与细粒度图像分类的原理相同。因此，所提防伪检测网络 RAINet 主要借鉴了 RACNN 的思想［19］：利用区域定位和特征提取之间存在的相互关联性，通过多次循环对网络的定位能力和提取能力进行交替训练，从而达到相互强化的目的，最终使网络聚焦于对关键区域的微小特征差异进行检测。

# 2. 2 网络框架

RAINet 的网络框架如图 2 所示，特征分类网络（FCN）和注意力网络（APN）构成循环网络结构，并分别使用不同的损失函数优化，其中 $( x _ { t } , y _ { t } )$ 为虹膜区域的中心坐标， $\mathbf { \Psi } _ { l _ { t } }$ 为虹膜区域边长的一半， $( x _ { t } ^ { \prime } , y _ { t } ^ { \prime } )$ 为纹理区域的中心坐标， $\boldsymbol { l } _ { t } ^ { \prime }$ 为纹理区域边长的一半。该网络在 RACNN 的基础上，针对虹膜防伪检测任务的特殊性进行了改进：1）在特征提取部分使用 MobileNetV2替换 VGG16，降低网络的运算成本；2）在网络输出部分舍弃全局特征分类网络G-FCN 的预测结果，避免了网络受到原始虹膜图像中眼睑、睫毛等背景特征的干扰。RAINet 对真伪虹膜图像进行了三级尺度特征的防伪检测，各级特征尺度的输入图像分别记为 $\boldsymbol { X } _ { t } ( t =$ $1 , 2 , \cdots , n )$ 、 $\boldsymbol { { X } } _ { t } ^ { \prime }$ 和 $X _ { t } ^ { \prime \prime } ,$ ，其中 $X _ { t }$ 代表第 $t$ 张虹膜图像。首先，将图像输入到各级特征分类网络中进行特征提取，得到特征图 $F _ { t } , F _ { t } ^ { \prime }$ 和 $\boldsymbol { F } _ { t } ^ { \prime \prime }$ 。然后，在对特征图 $\boldsymbol { F } _ { t }$ 和 $\boldsymbol { F } _ { t } ^ { \prime }$ 进

![](images/ce4f29247330a5badaa0f850e5c79dd6057b00c29f34b1b9497dc611e509de45.jpg)  
图 1　真实虹膜与纹理隐形眼镜虹膜。（a）真实虹膜；（b）纹理隐形眼镜虹膜Fig.  1　Real iris and textured contact lens iris.  (a) Real iris; (b) textured contact lens iris  
图 2　RAINet 虹膜防伪检测网络框架  
Fig.  2　RAINet iris anti-spoofing detection network framework

G-FCN:global featureclassificationnetwork   
X H H H □real iris contact lens iris Bottleneck1:224×224×16 Bottleneck7:14×14×320 fully connected layer1 crop M:region parameters $( x _ { t } , y _ { t } , l _ { t } )$ ? M fully connected layer 2 interpolation I-APN:irisattentionproposal network   
X HH 1 □real iris contact lens iris Bottleneck1:112×112×16 Bottleneck7:7×7×320 fully connected layer1 crop M':region parameters(x,y', ? fully connected layer2 Y interpolation T-APN: texture attention proposal network T-FCN:texture featureclassification network   
X HH H H □realiris → contact lensiris Bottleneck1:112×112×16 Bottleneck7:7×7×320

行分类预测的同时，将其输入到注意力网络中以定位关键区域，结合关键区域的图像掩膜与当前特征尺度的输入图像生成下一级特征尺度的输入图像。最后，对虹膜特征分类网络 I-FCN 和纹理特征分类网络 T-FCN 的预测结果进行平均，输出 RAINet 的真伪判别结果 $\boldsymbol { Y } _ { t }$ 。

# 2. 3 实现原理

RAINet 中包含三级特征分类网络：全局特征分类网络G-FCN、虹膜特征分类网络I-FCN 和纹理特征分类网络 T-FCN，均采用了 MobileNetV2 的特征层结构，但各自拥有独立的参数。MobileNetV2 使用深度可分离卷积进行特征提取，将计算复杂度减少为使用标准卷积的 $1 / k ^ { 2 }$ （k 为卷积核的尺寸）。如表 1 所示，MobileNetV2 相 较 于 RACNN 中 使 用 标 准 卷 积 的VGG16 网络大幅减少了网络的参数量（Params）和浮点计算量（FLOPs），可以减少防伪检测网络的运算成本，更有利于防伪检测网络在虹膜识别系统中的集成部署。

MobileNetV2 的特征层由 Conv2d 和 Bottleneck 组成，具体结构参数如表 2 所示。其中，Bottleneck 使用的是倒残差结构，既能增加特征的重复利用率，使模型提取到更多的特征信息［22］，又能提升计算效率，降低网络的内存占用。

表 1　MobileNetV2 与 VGG16 的对比  
Table 1　Comparison of MobileNetV2 and VGG16  

<html><body><table><tr><td>Network</td><td>Params /MB</td><td>FLOPs/109</td></tr><tr><td>VGG16</td><td>134.28</td><td>61.75</td></tr><tr><td>MobileNetV2</td><td>2.22</td><td>1. 28</td></tr></table></body></html>

表 2　MobileNetV2 的特征层结构参数Table 2　Structural parameters of MobileNetV2 feature layer  

<html><body><table><tr><td>Input</td><td>Operator</td><td>Factor</td><td>Output</td><td>Frequency</td><td>Step</td></tr><tr><td>224×224×3</td><td>Conv2d</td><td></td><td>32</td><td>1</td><td>2</td></tr><tr><td>112×112×32</td><td>Bottleneck</td><td>1</td><td>16</td><td>1</td><td>1</td></tr><tr><td>112×112×16</td><td>Bottleneck</td><td>6</td><td>24</td><td>2</td><td>2</td></tr><tr><td>56×56×24</td><td>Bottleneck</td><td>6</td><td>32</td><td>3</td><td>2</td></tr><tr><td>28×28×32</td><td>Bottleneck</td><td>6</td><td>64</td><td>4</td><td>2</td></tr><tr><td>14×14×64</td><td>Bottleneck</td><td>6</td><td>96</td><td>3</td><td>1</td></tr><tr><td>14×14×96</td><td>Bottleneck</td><td>6</td><td>160</td><td>1</td><td>1</td></tr><tr><td>7×7×160</td><td>Bottleneck</td><td>6</td><td>320</td><td>1</td><td>1</td></tr></table></body></html>

Bottleneck 的工作原理如图3 所示，首先输入图像经过 $1 \times 1$ 的逐点卷积将通道数扩张 6 倍，然后使用$3 \times 3$ 的深度卷积在高维进行特征提取，最后使用 $1 \times 1$ 的逐点卷积将通道数压缩还原。当卷积步长为 1 时，尺寸相同的输入图像和输出图像之间进行残差连接。此外，Bottleneck 还将最后一个逐点卷积的激活函数由ReLU6 替换为 Linear，以解决在低维度进行非线性激活会导致特征信息损失的问题。因此，MobileNetV2利用Bottleneck 的倒残差结构和线性激活层可以在控制运算成本的同时对虹膜特征进行有效提取。

![](images/7fc8665a53c664a1882d081766be48add1851b0c5ffb6d9d01231c73529db567.jpg)  
图 3　Bottleneck 的倒残差结构Fig.  3　Inverse residual block of Bottleneck

RAINet 中引入了 RACNN 的循环注意力机制［19］，在各级特征分类网络之间循环插入I-APN 和T-APN，先后对原始虹膜图像的虹膜区域和纹理区域进行无监督定位，模拟人眼的视觉特性使特征分类网络的注意力集中到图像中的虹膜及其纹理部分。

虹膜是一个近似同心圆的圆环状结构，理想情况下定位到的虹膜区域和纹理区域应该是正方形，长宽比约为1∶1。如图4 所示，虹膜注意力网络I-APN 通过两个全连接层将特征图映射为虹膜区域的位置参数$( x _ { t } , y _ { t } , l _ { t } )$ ，其中 $( x _ { t } , y _ { t } )$ 是区域的中心坐标， $\boldsymbol { l } _ { t }$ 是区域边长的一半，纹理注意力网络T-APN 操作相同。

以虹膜注意力网络I-APN 为例，将虹膜图像的左上角设为坐标系的原点，其 $x$ 轴和 $y$ 轴分别从左到右和自上到下定义。根据虹膜区域位置参数 $( x _ { t } , y _ { t } , l _ { t } )$ ，可以获得虹膜区域左上角点坐标 $( \boldsymbol { x } _ { \mathrm { t l } } , \boldsymbol { y } _ { \mathrm { t l } } )$ 和右下角点坐标 $( x _ { \mathrm { b r } } , y _ { \mathrm { b r } } )$ ，计算公式为

$$
\left\{ \begin{array} { l l } { x _ { \mathrm { t l } } = x _ { t } - l _ { t } } \\ { y _ { \mathrm { t l } } = y _ { t } - l _ { t } } \\ { x _ { \mathrm { b r } } = x _ { t } + l _ { t } ^ { \circ } } \\ { y _ { \mathrm { b r } } = y _ { t } + l _ { t } } \end{array} \right.
$$

根据虹膜区域的顶点坐标，使用图像掩模函数$M \left( \cdot \right)$ 与虹膜图像 $X _ { t }$ 进行逐像素相乘的裁剪操作，即可得到裁剪后的虹膜区域图像 $X _ { t } ^ { \prime }$ ，即

![](images/ad6afa0fa10b58ecb3db342667024c9e43bf4d2ebe8c861d82f75fc214240a63.jpg)  
图 4　特征区域的位置参数。（a）虹膜区域位置参数；（b）纹理区域位置参数；（c）插值后的纹理区域Fig.  4　Location parameters of feature region.  (a) Location parameters of iris region; (b) location parameters of texture region;(c) texture region after interpolation

$$
X _ { t } ^ { \prime } { = } X _ { t } \odot M \left( x _ { \mathrm { t l } } , y _ { \mathrm { t l } } , x _ { \mathrm { b r } } , y _ { \mathrm { b r } } \right) \circ
$$

常规的图像裁剪方法是根据区域坐标生成一个二值图像掩模，该方法虽然操作简单且计算量小，但掩模函数 $M ( \cdot )$ 是一个阶跃函数，在网络训练优化的过程中无法进行反向传播。因此，定义一个连续可导的掩模函数

$$
\begin{array} { r } { M _ { \mathrm { n e w } } ( \bullet ) = \ \large \left[ \sigma \left( x - x _ { \mathrm { t l } } \right) - \sigma \left( x - x _ { \mathrm { b r } } \right) \large \right] \bullet } \\ { \quad \large \ \left[ \sigma \left( y - y _ { \mathrm { t l } } \right) - \sigma \left( y - y _ { \mathrm { b r } } \right) \large \right] , } \end{array}
$$

式中： $\sigma ( \cdot )$ 为Sigmoid 函数，其取值范围为 $0 { \sim } 1$ 。如图5 所示，只有位于虹膜区域（纹理区域）内的像素点（满足 $\boldsymbol { x } \in \left[ \boldsymbol { x } _ { \mathrm { t l } } , \boldsymbol { x } _ { \mathrm { b r } } \right]$ 和 $y \in \left[ y _ { \mathrm { t l } } , y _ { \mathrm { b r } } \right] )$ 才能使 $M _ { \mathrm { n e w } } ( \cdot )$ 的结果趋近于 1，其他像素点的结果都趋近于 0，由此生成一个近似的二值图像掩模。裁剪后的虹膜区域图像 $X _ { t } ^ { \prime }$ 和纹理区域图像 $X _ { t } ^ { \prime \prime }$ 经过双线性插值上采样后，分别作为下一级特征尺度的输入图像。

![](images/dcba74339ed6d03ec2798d9174d2203024aafe0648d564adf1f41bd857cd8ed4.jpg)  
图 5　特征区域的图像掩模。（a）虹膜区域图像掩膜；（b）纹理区域图像掩膜  
Fig.  5　Image masks of feature region.  (a) Image masks of iris region; (b) image masks of texture region

RAINet 使用两个不同的损失函数进行优化：对特征分类网络使用分类损失函数；对注意力网络使用排序损失函数［19］。RAINet 总体损失函数的定义为

$$
L \left( \boldsymbol { X } _ { t } \right) = \sum _ { s = 1 } ^ { 3 } L _ { \mathrm { c l s } } \boldsymbol { \left[ Y _ { t } ^ { * } , Y _ { t } ^ { ( s ) } \right] } + \sum _ { s = 1 } ^ { 2 } L _ { \mathrm { r a n k } } \boldsymbol { \left[ \hat { P } _ { t } ^ { ( s ) } , \hat { P } _ { t } ^ { ( s + 1 ) } \right] } ,
$$

式中： $s$ 为第 $s$ 级特征尺度； $L _ { \mathrm { c l s } } ( \cdot )$ 为分类损失函数；$L _ { \mathrm { r a n k } } ( \cdot )$ 为排序损失函数； $\boldsymbol { Y } _ { t } ^ { * }$ 为样本的标签值； $Y _ { t } ^ { ( s ) }$ 为第 $s$ 级特征分类网络对样本的预测值； $\boldsymbol { \phi } _ { t } ^ { ( s ) }$ 和 $\phi _ { t } ^ { ( s + 1 ) }$ 为第 $s$ 级和第 $s + 1$ 级特征分类网络对真实标签的预测概率。

分类损失使用交叉熵损失函数进行计算， $L _ { \mathrm { c l s } } ( \cdot )$ 的计算公式为

$$
\begin{array} { r } { L _ { \mathrm { c l s } } \big [ Y _ { \iota } ^ { * } , Y _ { \iota } ^ { ( s ) } \big ] = Y _ { \iota } ^ { * } \bullet \ln Y _ { \iota } ^ { ( s ) } + \big ( 1 - Y _ { \iota } ^ { * } \big ) \bullet \ln \big [ 1 - Y _ { \iota } ^ { ( s ) } \big ] , } \end{array}
$$

使用交叉熵损失函数可以避免网络出现梯度弥散问题，使特征分类网络的预测结果有效地向真实标签收敛。

排序损失通过相邻两级特征分类网络对真实标签的预测误差进行计算， $L _ { \mathrm { r a n k } } ( \cdot )$ 的计算公式为

$L _ { \mathrm { r a n k } } \Big [ \phi _ { t } ^ { ( s ) } , \phi _ { t } ^ { ( s + 1 ) } \Big ] { = } \operatorname* { m a x } \Big [ 0 , \phi _ { t } ^ { ( s ) } - \phi _ { t } ^ { ( s + 1 ) } + m _ { \mathrm { a r g i n } } \Big ] ,$ ，（6）式中： $m _ { \mathrm { a r g i n } }$ 为间隔差值，将其设置为 0. 05。当 $\rho _ { t } ^ { \left( s + 1 \right) } >$ $\phi _ { t } ^ { ( s ) } + m _ { \mathrm { a r g i n } }$ 时，损失较小，说明注意力网络所定位到的特征区域位置更有利于检测真伪虹膜的微小特征差异，能让下一级特征分类网络预测得更准确。

RAINet 的训练目的是让特征分类网络和注意力网络相互促进，训练过程为：固定两个注意力网络的各层参数，训练三级特征分类网络直至收敛；固定三级特征分类网络的各层参数，训练两个注意力网络直至收敛。在每个训练轮次中迭代交替进行直至两种网络的损失都收敛。

# 3 实验结果与分析

实验的硬件设备为：中央处理器（CPU）型号为Intel Xeon Silver 4110，图 形 处 理 单 元（GPU）型 号 为NVIDA Quadro GV100，内存为 32GB。软件环境为：Centos7 操 作 系 统 、Python3. 6 开 发 环 境 和 Pytorch1. 4

深度学习框架。

# 3. 1 实验数据集

实验选用包含真实虹膜样本和隐形眼镜虹膜样本的 两 个 公 开 数 据 库 IIITD CLI［23-24］和 ND 系 列［9， 25-26］对RAINet 进行训练和测试，数据样本的人种分布覆盖了欧美地区和亚洲，隐形眼镜来自强生、视康、博士伦等不同品牌，确保了数据样本的多样性。相关实验表明，虽然佩戴透明隐形眼镜会提高虹膜识别的拒识率（FRR），但是对虹膜识别的误识率（FAR）影响较小［10］，因此主要关注纹理隐形眼镜。在构建数据集的过程中剔除了透明隐形眼镜虹膜样本，将真实虹膜视为正样本，纹理隐形眼镜虹膜视为负样本。

IIITD CLI 数据库由印度理工学院德里分校提供，包含来自101 位实验者的6570 张样本图像，图像分辨 率 为 640 pixel $\times 4 8 0$ pixel。 图 6 为 IIITD CLI 数 据库中的样本图像示例。由于图像是通过 Cogent 和Vista 两种虹膜传感器独立采集的，故可划分为Cogent和 Vista 两个数据集：Cogent 数据集包含 1153 张真实虹膜样本图像和1192 张纹理隐形眼镜虹膜样本图像；Vista 数据集包含 1000 张真实虹膜样本和 1050 张纹理隐形眼镜虹膜样本图像。

![](images/222f35d9ed86e7f4fade0b4b4cede99860eac32e0cb9397a4ab810870809ca0c.jpg)  
图 6　IIITD CLI 数据库的样本图像。（a）Cogent 的真实虹膜；（b）Cogent 的纹理隐形眼镜虹膜；（c）Vista 的真实虹膜；（d）Vista 的纹理隐形眼镜虹膜  
Fig.  6　 Sample images from IIITD CLI database.  (a) Real iris from Cogent; (b) textured contact lens iris from Cogent; (c) real iris from Vista; (d) texture contact lens iris from Vista

ND 系列数据库来自美国圣母大学的计算机视觉实验室，该系列中有三个不同时期的图像数据库 NDContact、NDCLD15 和 NDSPI19 （NDSPI19 是 从NDCLD15 中筛选出来的），共计18196 张样本图像，图像 分 辨 率 为 640 pixel $\times$ 480 pixel。 图 7 为 ND 系 列 数据库的样本图像示例。由于ND 系列数据库的图像是由 LG4000 和 AD100 两种虹膜传感器采集的，故根据实 验 需 要 划 分 为 NDC LG4000、NDC AD100、ND15和 ND19 4 个数据集：NDC LG4000 数据集包含 1390张真实虹膜样本图像和 1409 张纹理隐形眼镜虹膜样本图像；NDC AD100 数据集包含300 张真实虹膜样本图像和300 张纹理隐形眼镜虹膜样本图像；ND15 数据集由挑选的1500 张真实虹膜样本图像和1500 张纹理隐形眼镜虹膜样本图像组成；ND19 数据集包含 1400张真实虹膜样本图像和 2664 张纹理隐形眼镜虹膜样本图像。

为了对数据样本进行批量化的训练和测试，先将各 个 数 据 集 的 样 本 图 像 归 一 化 为 448 pixel×448 pixel，再按照7∶3 的比例将数据集随机划分为训练

集和测试集。

# 3. 2　训练参数与评价指标

在训练阶段中，先加载经过 ImageNet 预训练的MobileNetV2 对三级特征分类网络进行初始化，再采用带动量的批量随机梯度下降算法（BSGD）更新网络参数，由一个批次的数据样本共同决定梯度的更新方向，既能降低梯度下降的随机性，又能降低梯度更新的时间成本。引入动量可以使参数更新方向与此前积累的更新方向关联，进而达到加速收敛和缓解震荡的目的。在网络训练过程中，将学习率的初始值设为0. 001，动量因子设为 0. 9，权重衰减设为 0. 0005，批尺寸设为32，迭代次数设为50。

测试阶段使用正确分类率（CCR）和受试者工作特性曲线（ROC）作为衡量检测精度的评价指标［27］，使用参数量和浮点计算量作为衡量运算成本的评价指标［28］。CCR 又称为准确率，表示正确分类的样本数占总样本数的比例，样本比例均衡时CCR 越高，说明网络的分类精度越高，CCR 的计算公式为

![](images/7c488a599a7227b4a86509144315fd11da27902af9f8c66dc2b489b9b133556f.jpg)  
图 7　ND 系列数据库的样本图像。（a）NDC LG4000 的真实虹膜；（b）NDC LG4000 的纹理隐形眼镜虹膜；（c）NDC AD100 的真实虹膜；（d） NDC AD100 的纹理隐形眼镜虹膜；（e） NDCLD15 的真实虹膜；（f） NDCLD15 的纹理隐形眼镜虹膜Fig.  7　Sample images from ND series databases.  (a) Real iris from NDC LG4000; (b) textured contact lens iris from NDC LG4000;(c) real iris from NDC AD100; (d) textured contact lens iris from NDC AD100; (e) real iris from NDCLD15; (f) textured contactlens iris from NDCLD15

$$
V _ { \mathrm { c c R } } = \frac { N _ { \mathrm { T P } } + N _ { \mathrm { T N } } } { N _ { \mathrm { T P } } + N _ { \mathrm { T N } } + N _ { \mathrm { F P } } + N _ { \mathrm { F N } } } ,
$$

式中： $N _ { \mathrm { T P } }$ 表示正确预测的正样本数量； $N _ { \mathrm { T N } }$ 表示正确预测的负样本数量； $N _ { \mathrm { F P } }$ 表示错误预测的正样本数量；$N _ { \mathrm { F N } }$ 表示错误预测的负样本数量。

ROC 曲线是以真正率（TPR）为纵坐标，假正率（FPR）为横坐标绘制而成的曲线，是反映网络灵敏性和特异性连续变化的综合性指标。ROC 曲线的线下面积（AUC）越大，说明网络的分类效果越好。TPR 和FPR 的计算公式为

$$
V _ { \mathrm { T P R } } = \frac { N _ { \mathrm { T P } } } { N _ { \mathrm { T P } } + N _ { \mathrm { F N } } } ,
$$

$$
V _ { \mathrm { F P R } } = \frac { N _ { \mathrm { F P } } } { N _ { \mathrm { T N } } + N _ { \mathrm { F P } } } \textmd { _ { o } }
$$

Params 为网络所有参数层的权重参数量，主要包括卷积层、批归一化层和全连接层等，可用于衡量网络的空间复杂度，网络整体的 Params 越小，说明网络参数量越少，内存占用越小。FLOPs 是指浮点运算数，可用于衡量网络的时间复杂度，FLOPs 越小，说明网络的计算量越小，计算速度越快消耗越小。

# 3. 3 实验结果

在同传感器、跨传感器和跨数据库三种不同实验条件下进行多组实验，评估 RAINet 的检测精度与运算 成 本 ，并 将 其 与 循 环 注 意 力 卷 积 神 经 网 络RACNN［19］ 、虹 膜 防 伪 检 测 网 络 GHCLNet［15］ 和DCLNet［16］进行对比。

# 3. 3. 1 消融实验

RAINet 与RACNN 使用相同的循环网络结构，但对网络融合策略进行了改进，为验证 RAINet 的循环网络结构和输出策略改进所产生的效果，对虹膜注意力网络I-APN、纹理注意力网络T-APN 和网络融合策略进行消融实验。实验结果如表 3 所示，其中 $V _ { \mathrm { C C R } } ,$ ，c代表纹理隐形眼镜虹膜样本的准确率， $V _ { \mathrm { C C R , \ i } }$ 代表真实虹膜样本的准确率， $V _ { \mathrm { C C R } , }$ a 代表所有样本的准确率，RAINet3 代表网络的输出结果是对三级特征分类网络G-FCN、I-FCN 和 T-FCN 的预测结果（对正负样本的预测概率）求均值而得到的，RAINet 代表在 RAINet3的基础上舍弃了全局特征分类网络G-FCN。

表3　消融实验结果Table 3　Results of ablation experiments unit: $\%$   

<html><body><table><tr><td>Database</td><td>Network</td><td>VcCR, c</td><td>VccR.i</td><td>VccR,a</td></tr><tr><td rowspan="5">Cogent (intra-sensor)</td><td>G-FCN</td><td>100.00</td><td>99.15</td><td>99.57</td></tr><tr><td>I-FCN</td><td>100.00</td><td>99.43</td><td>99.71</td></tr><tr><td>T-FCN</td><td>100.00</td><td>99.70</td><td>99.85</td></tr><tr><td>RAINet3</td><td>100.00</td><td>99.43</td><td>99.71</td></tr><tr><td>RAINet</td><td>100.00</td><td>99.70</td><td>99.85</td></tr><tr><td rowspan="4">Cogent/Vista (inter-sensor)</td><td>G-FCN</td><td>100.00</td><td>98.03</td><td>99.02</td></tr><tr><td>I-FCN</td><td>100.00</td><td>100.00</td><td>100.00</td></tr><tr><td>T-FCN</td><td>100.00</td><td>99.48</td><td>99.74</td></tr><tr><td>RAINet3</td><td>100.00</td><td>99.34</td><td>99.67</td></tr><tr><td rowspan="5">Cogent/NDCLG4000 (inter-database)</td><td>RAINet G-FCN</td><td>100.00 91.25</td><td>99.68 100.00</td><td>99.84 95.62</td></tr><tr><td>I-FCN</td><td>96.22</td><td>100.00</td><td>98.11</td></tr><tr><td>T-FCN</td><td>96.45</td><td>100.00</td><td>98.22</td></tr><tr><td>RAINet3</td><td>94.56</td><td>100.00</td><td>97.27</td></tr><tr><td>RAINet</td><td>96.93</td><td>100.00</td><td>98.46</td></tr></table></body></html>

消融实验的结果表明：使用全局特征分类网络G-FCN 对原始虹膜图像直接进行分类，检测精度并不理想；使用结构相同的虹膜特征分类网络I-FCN 对虹膜注意力网络I-APN 定位到的虹膜区域图像进行分类，检测精度有明显的提升；进一步使用结构相同的纹理特征分类网络T-FCN 对纹理注意力网络T-APN 定位到的纹理区域图像进行分类，在同传感器和跨数据库条件下的检测精度略有提升。融合多层级特征进行分类可以充分利用图像的特征信息，但因G-FCN 的分类效果不佳而影响了 RAINet3 的检测精度。在舍弃了G-FCN 的 预 测 结 果 后 ，RAINet 的 准 确 率 相 较 于RAINet3 有所提升，说明在虹膜防伪检测任务中减少背景特征的干扰，也有利于提升检测精度。

# 3. 3. 2 对比实验

# 1） 同传感器检测实验

用同一传感器采集的样本图像对网络进行训练与测试，训练样本和测试样本的光照亮度、采集角度等成像参数均保持一致。实验的数据集为 Cogent、Vista、NDC LG4000 和 NDC AD100，得到的 4 组实验结果如表 4 和图 8 所示。从表 4 可以看出，RAINet 对同传感器样本的检测精度要优于其他网络，在各个数据集下的 $V _ { \mathrm { C C R } } .$ ，a 接 近 $100 \%$ ， $V _ { \mathrm { C C R } }$ ， c 与其他网络相当， $V _ { \mathrm { C C R , \ i } }$ 较RACNN 提升了约 1 个百分点，较 GHCLNet 提升了 7个百分点，较 DCLNet 提升了 7. 37 个百分点。从图 8的 ROC 曲线可以看出，当使用 Cogent 数据集进行测试时，RAINet、RACNN 的 AUC 可达到 1. 0000，高于其他两个防伪检测网络。

Table 4　Comparison of CCR under intra-sensor detection unit: $\%$   

<html><body><table><tr><td>Database</td><td>Network</td><td>VccR. c</td><td>VccCR, i</td><td>VccR, a</td></tr><tr><td rowspan="4">Cogent</td><td>RACNN</td><td>100.00</td><td>99.24</td><td>99.62</td></tr><tr><td>GHCLNet</td><td>100.00</td><td>89.86</td><td>94.98</td></tr><tr><td>DCLNet</td><td>99.10</td><td>94.19</td><td>96.64</td></tr><tr><td>RAINet</td><td>100.00</td><td>99.70</td><td>99.85</td></tr><tr><td rowspan="4">Vista</td><td>RACNN</td><td>100.00</td><td>97.72</td><td>98.86</td></tr><tr><td>GHCLNet</td><td>100.00</td><td>94.60</td><td>97.30</td></tr><tr><td>DCLNet</td><td>100.00</td><td>93.19</td><td>96.60</td></tr><tr><td>RAINet</td><td>100.00</td><td>100.00</td><td>100.00</td></tr><tr><td rowspan="4">NDCLG4000</td><td>RACNN</td><td>100.00</td><td>99.21</td><td>99.60</td></tr><tr><td>GHCLNet</td><td>99.75</td><td>95.24</td><td>97.50</td></tr><tr><td>DCLNet</td><td>99.93</td><td>92.86</td><td>96.40</td></tr><tr><td>RAINet</td><td>100.00</td><td>99.78</td><td>99.89</td></tr><tr><td rowspan="4">NDC AD100</td><td>RACNN</td><td>100.00</td><td>99.52</td><td>99.76</td></tr><tr><td>GHCLNet</td><td>100.00</td><td>91.67</td><td>95.84</td></tr><tr><td>DCLNet</td><td>98.50</td><td>89.49</td><td>94.00</td></tr><tr><td>RAINet</td><td>100.00</td><td>100.00</td><td>100.00</td></tr></table></body></html>

# 2） 跨传感器检测实验

用同一数据库中不同传感器采集的样本图像对网络进行训练与测试，训练样本和测试样本的光照亮度、采集角度等成像参数有所不同。实验将 Cogent 数据集和 Vista 数据集成对使用，将 NDC LG4000 数据集和NDC AD100 数据集成对使用，得到的4 组实验结果

1.00 0.95 1 RACNN(AUC:1.0000) GHCLNet(AUC:0.9985) 0.65 DCLNet(AUC:0.9988) RAINet(AUC:1.0000) 0.60 0 0.1 0.2 0.3 0.4 0.5 False positive rate

如表 5 和图 9 所示。从表 5 可以看出，RAINet 对跨传感器样本的检测性能相较于同传感器样本的检测精度有所下降，但仍然优于其他网络。当使用样本数量较多的 Cogent 数据集和 NDC LG4000 数据集进行训练时，RAINet 保持了出色的检测精度，较其他防伪检测网络提升了 5 个百分点左右。然而，在交换用于训练和测试的数据集后，因训练样本数量偏少，RAINet 的$V _ { \mathrm { C C R , a } }$ 分别下降为 $9 6 . 0 3 \%$ 和 $9 3 . 3 6 \%$ ，但比其他网络仍高出 $3 { \sim } 5$ 个百分点。从图9 的ROC 曲线可以看出，当使用Cogent 数据集训练再使用Vista 数据集进行测试时，RAINet 与 RACNN 的 AUC 仍能达到 1. 0000，高于其他两个防伪检测网络。

表4　同传感器检测的CCR 对比  
表5　跨传感器检测的CCR 对比  
Table 5　Comparison of CCR under inter-sensor detection unit: $\%$   

<html><body><table><tr><td>Database</td><td>Network</td><td>VcCR. c</td><td>VccR.i</td><td>VcCR,a</td></tr><tr><td rowspan="4">Cogent/Vista</td><td>RACNN</td><td>100.00</td><td>99.68</td><td>99.84</td></tr><tr><td>GHCLNet</td><td>99.25</td><td>93.40</td><td>96.33</td></tr><tr><td>DCLNet</td><td>99.83</td><td>89.55</td><td>94.69</td></tr><tr><td>RAINet</td><td>100.00</td><td>99.68</td><td>99.84</td></tr><tr><td rowspan="4">Vista/Cogent</td><td>RACNN</td><td>90.21</td><td>96.17</td><td>93.19</td></tr><tr><td>GHCLNet</td><td>85.36</td><td>96.74</td><td>91.05</td></tr><tr><td>DCLNet</td><td>99.82</td><td>81.43</td><td>90.63</td></tr><tr><td>RAINet</td><td>94.54</td><td>97.48</td><td>96.03</td></tr><tr><td rowspan="4">NDCLG4000/AD100</td><td>RACNN</td><td>100.00</td><td>97.33</td><td>98.66</td></tr><tr><td>GHCLNet</td><td>98.00</td><td>91.90</td><td>94.95</td></tr><tr><td>DCLNet</td><td>100.00</td><td>92.00</td><td>96.00</td></tr><tr><td>RAINet</td><td>100.00</td><td>100.00</td><td>100.00</td></tr><tr><td rowspan="4">NDC AD100/LG4000</td><td>RACNN</td><td>100.00</td><td>84.18</td><td>92.09</td></tr><tr><td>GHCLNet</td><td>100.00</td><td>81.25</td><td>90.63</td></tr><tr><td>DCLNet</td><td>97.92</td><td>83.00</td><td>90.46</td></tr><tr><td>RAINet</td><td>100.00</td><td>86.76</td><td>93.36</td></tr></table></body></html>

# 3） 跨数据库检测实验

用不同数据库中不同传感器采集的样本图像对网络进行训练与测试，训练样本和测试样本在成像参数上有所不同，且样本源的人种分布、眼镜品牌也有差

1.00 0.95 1 RACNN(AUC:1.0000) GHCLNet(AUC:0.9975) 0.65 DCLNet(AUC:0.9970) RAINet(AUC:1.0000) 0.60 0 0.1 0.2 0.3 0.4 0.5 False positive rate

别。实验将Cogent 数据集和ND 系列的三个数据库集两两配对，得到的 6 组实验结果如表 6 和图 10 所示。从表6 可以看出，RAINet 对跨数据库样本的检测精度是所有网络中最高的：将Cogent 数据集和ND 系列数据集分别用于训练和测试时，RAINet 的 $V _ { \mathrm { C C R } } ,$ ， a 分别为$9 8 . 4 6 \% . 9 6 . 1 0 \%$ 和 $9 6 . 9 5 \%$ ，相较于其他网络大约提升了3 个百分点；当使用ND 系列数据集进行训练和测试 时 ，RAINet 的 $V _ { \mathrm { C C R } , }$ 分别为 $9 9 . 3 0 \% . 9 9 . 9 1 \%$ 和$9 6 . 4 5 \%$ ，相较其他网络提升了 $1 { \sim } 2$ 个百分点。从图10 的 ROC 曲线可以看出，当使用 Cogent 数据集训练再使用 ND19 数据集测试时，RAINet 与 RACNN 的AUC 值大体相当，高于其他两个防伪检测网络。

# 4） 检测成本实验

对比 RAINet 与 RACNN 和其他防伪检测网络的运算成本，实验结果如表7 所示。可以看出，使用循环网络结构的RAINet 和 RACNN 相较于使用标准网络结 构 的 GHCLNet 和 DCLNet 在 Params 方 面 并 不 占优，但 RAINet 仍可将 Params 控制在 100 MB 以内。此外，由于 RAINet 在特征提取部分的特征分类网络均使用 MobilNetV2 的特征层结构，故 FLOPs 降低到了$1 . 8 7 \times 1 0 ^ { 9 }$ 。

对比实验的结果表明：相比于其他防伪检测网络，RAINet 能够有效提取出真实虹膜与纹理隐形眼镜之间微小的特征差异并进行精确检测；即使在训练样本不足或跨数据库检测等特殊条件下，RAINet 仍有较好的表现，证明了 RAINet 的有效性和泛化性；虽然RAINet 的 Params 高 于 GHCLNet 和 DCLNet，但FLOPs 低于 GHCLNet 和 DCLNet，而计算量是决定运算成本的主要因素；相比于 RACNN，改进后的RAINet 更适用于虹膜防伪检测任务，显著降低运算成本的同时，还能保持良好的检测精度。因此，综合考虑网络的检测精度和运算成本，RAINet 具有更优的综合性能。

# 4　 结        论

为有效对真实虹膜与纹理隐形眼镜虹膜之间微小的特征差异进行防伪检测，将纹理隐形眼镜虹膜防伪检测问题视为细粒度图像分类问题进行处理，提出了

# 表6　跨数据库检测的CCR 对比

Table 6　Comparison of CCR under inter-database detection unit: $\%$   

<html><body><table><tr><td>Database</td><td>Network</td><td>VccR. </td><td>VccR, i</td><td>VccR, a</td></tr><tr><td rowspan="4">Cogent/NDCLG4000</td><td>RACNN</td><td>93.12</td><td>100.00</td><td>96.56</td></tr><tr><td>GHCLNet</td><td>90.07</td><td>100.00</td><td>95.02</td></tr><tr><td>DCLNet</td><td>87.94</td><td>100.00</td><td>93.95</td></tr><tr><td>RAINet</td><td>96.93</td><td>100.00</td><td>98.46</td></tr><tr><td rowspan="4">Cogent/ND 15</td><td>RACNN</td><td>100.00</td><td>88.80</td><td>94.40</td></tr><tr><td>GHCLNet</td><td>90.07</td><td>100.00</td><td>95.02</td></tr><tr><td>DCLNet</td><td>100.00</td><td>81.40</td><td>90.70</td></tr><tr><td>RAINet</td><td>100.00</td><td>92.20</td><td>96.10</td></tr><tr><td rowspan="4">Cogent/ND 19</td><td>RACNN</td><td>92.70</td><td>99.80</td><td>96.15</td></tr><tr><td>GHCLNet</td><td>90.17</td><td>99.76</td><td>93.46</td></tr><tr><td>DCLNet</td><td>88.68</td><td>100.00</td><td>92.57</td></tr><tr><td>RAINet</td><td>93.90</td><td>100.00</td><td>96.95</td></tr><tr><td rowspan="4">NDC LG4000/ND 15</td><td>RACNN</td><td>98.00</td><td>98.80</td><td>98.40</td></tr><tr><td>GHCLNet</td><td>99.60</td><td>95.60</td><td>97.60</td></tr><tr><td>DCLNet</td><td>98.80</td><td>99.40</td><td>99.10</td></tr><tr><td>RAINet</td><td>99.40</td><td>99.20</td><td>99.30</td></tr><tr><td rowspan="4">NDC LG4000/ND 19</td><td>RACNNt</td><td>100.00</td><td>99.52</td><td>99.77</td></tr><tr><td>GHCLNet</td><td>100.00</td><td>94.05</td><td>97.96</td></tr><tr><td>DCLNet</td><td>100.00</td><td>89.76</td><td>96.49</td></tr><tr><td>RAINet</td><td>100.00</td><td>99.76</td><td>99.91</td></tr><tr><td rowspan="4">ND 15/ND 19</td><td>RACNN</td><td>92.82</td><td>100.00</td><td>96.43</td></tr><tr><td>GHCLNet</td><td>93.03</td><td>100.00</td><td>95.42</td></tr><tr><td>DCLNet</td><td>92.41</td><td>100.00</td><td>95.02</td></tr><tr><td>RAINet</td><td>92.91</td><td>100.00</td><td>96.45</td></tr></table></body></html>

1.00 0.95 1 RACNN(AUC:0.9996) GHCLNet(AUC:0.9901) 0.65 DCLNet(AUC:0.9912) RAINet (AUC: 0.9999) 0.60 0 0.1 0.2 0.3 0.4 0.5 False positive rate

表7　各网络的运算成本对比  
Table 7　Comparison of calculated costs for each network   

<html><body><table><tr><td>Network</td><td>Params /MB</td><td>FLOPs/109</td></tr><tr><td>RACNN</td><td>373.34</td><td>92.65</td></tr><tr><td>GHCLNet</td><td>23.51</td><td>4. 12</td></tr><tr><td>DCLNet</td><td>6.96</td><td>2.88</td></tr><tr><td>RAINet</td><td>86.96</td><td>1.87</td></tr></table></body></html>

一种循环注意力隐形眼镜虹膜防伪检测方法RAINet。首先，RAINet 引入循环注意力机制先后对原始虹膜图像的虹膜区域和纹理区域进行无监督定位，使网络能模拟人眼的视觉特性，进而不断聚焦于关键区域的特征 差 异 以 进 行 防 伪 检 测 。 其 次 ，RAINet 采 用MobileNetV2 对特征分类网络进行轻量化处理，解决了使用循环网络结构导致的运算成本过高的问题。此外，RAINet 作为端到端网络无需图像预处理或人工标注，能够方便地集成到虹膜识别系统中。在 IIITDCLI 数据库和 ND 系列数据库上进行的实验表明：RAINet 可以针对真伪虹膜之间关键区域的微小特征差异进行检测，相比于其他虹膜防伪检测网络具有更好的准确性和泛化性； RAINet 控制了运算成本，相比于 RACNN 更符合在边缘计算设备上应用部署的条件。后续的研究可以对网络的损失函数进行进一步优化，以提升防伪检测精度。

# 参 考 文 献

[1] 李海青, 孙哲南, 谭铁牛, 等 . 虹膜识别技术进展与趋 势[J]. 信息安全研究, 2016, 2(1): 40-43. Li H Q, Sun Z N, Tan T N, et al. Progress and trends in iris recognition[J]. Journal of Information Security Research, 2016, 2(1): 40-43.   
[2] Chen R, Lin X R, Ding T H. Liveness detection for iris recognition using multispectral images[J]. Pattern Recognition Letters, 2012, 33(12): 1513-1519.   
[3] 毋立芳, 马玉琨, 周鹏, 等. 生物特征模板保护综述[J]. 仪器仪表学报, 2016, 37(11): 2407-2420. Wu L F, Ma Y K, Zhou P, et al. Review of biometric template protection[J]. Chinese Journal of Scientific Instrument, 2016, 37(11): 2407-2420.   
[4] Das P, Mcfiratht J, Fang Z Y, et al. Iris liveness detection competition (LivDet-Iris) - the 2020 edition [C]//2020 IEEE International Joint Conference on Biometrics, September 28-October 1, 2020, Houston, TX, USA. New York: IEEE Press, 2020.   
[5] He Y Q, Hou Y S, Li Y J, et al. Liveness iris detection method based on the eye′s optical features[J]. Proceedings of SPIE, 2010, 7838: 236-243.   
[6] Lee J, Lee S H, Park J I. Detection of abnormal iris authentication[C]//2019 IEEE International Conference on Consumer Electronics, January 11-13, 2019, Las Vegas, NV, USA. New York: IEEE Press, 2019.   
[7] Daugman J. Demodulation by complex-valued wavelets for stochastic pattern recognition[J]. International Journal of Wavelets, Multiresolution and Information Processing, 2003, 1(1): 1-17.   
[8] He Z F, Sun Z N, Tan T N, et al. Efficient iris spoof detection via boosted local binary patterns [M]//Tistarelli M, Nixon M S. Advances in biometrics. Lecture notes in computer science. Heidelberg: Springer, 2009, 5558: 1080-1090.   
[9] Doyle J S, Bowyer K W. Robust detection of textured contact lenses in iris recognition using BSIF[J]. IEEE Access, 2015, 3: 1672-1683. pattern[M]//Azzopardi G, Petkov N. Computer analysis of images and patterns. Lecture notes in computer science. Cham: Springer, 2015, 9256: 702-714.   
[11] Agarwal R, Jalal A S, Arya K V. Local binary hexagonal extrema pattern $( \mathrm { L B H _ { X } E P } )$ : a new feature descriptor for fake iris detection[J]. The Visual Computer, 2021, 37(6): 1357-1368.   
[12] Raghavendra R, Raja K B, Busch C. ContlensNet: robust iris contact lens detection using deep convolutional neural networks[C]//2017 IEEE Winter Conference on Applications of Computer Vision, March 24-31, 2017, Santa Rosa, CA, USA. New York: IEEE Press, 2017: 1160-1167.   
[13] Chen C J, Ross A. A multi-task convolutional neural network for joint iris detection and presentation attack detection[C]//2018 IEEE Winter Applications of Computer Vision Workshops, March 15, 2018, Lake Tahoe, NV, USA. New York: IEEE Press, 2018: 44-51.   
[14] Gupta M, Singh V, Agarwal A, et al. Generalized iris presentation attack detection algorithm under crossdatabase settings[C]//2020 25th International Conference on Pattern Recognition (ICPR), January 10- 15, 2021, Milan, Italy. New York: IEEE Press, 2021: 5318-5325.   
[15] Singh A, Mistry V, Yadav D, et al. GHCLNet: a generalized hierarchically tuned contact lens detection network[C]//2018 IEEE 4th International Conference on Identity, Security, and Behavior Analysis, January 11- 12, 2018, Singapore. New York: IEEE Press, 2018.   
[16] Choudhary M, Tiwari V, Venkanna U. An approach for iris contact lens detection and classification using ensemble of customized DenseNet and SVM[J]. Future Generation Computer Systems, 2019, 101: 1259-1270.   
[17] 于福升, 余江, 鲁远甫, 等 . 基于残差网络的虹膜图像 性 别 分 类 [J]. 激 光 与 光 电 子 学 进 展 , 2021, 58(16): 1610022. Yu F S, Yu J, Lu Y F, et al. Gender classification of iris image based on residual network[J]. Laser & Optoelectronics Progress, 2021, 58(16): 1610022.   
[18] Agarwal R, Jalal A S. Presentation attack detection system for fake Iris: a review[J]. Multimedia Tools and Applications, 2021, 80(10): 15193-15214.   
[19] Fu J L, Zheng H L, Mei T. Look closer to see better: recurrent attention convolutional neural network for finegrained image recognition[C]//2017 IEEE Conference on Computer Vision and Pattern Recognition, July 21-26, 2017, Honolulu, HI, USA. New York: IEEE Press, 2017: 4476-4484.   
[20] Sandler M, Howard A, Zhu M L, et al. MobileNetV2: inverted residuals and linear bottlenecks[C]//2018 IEEE/ CVF Conference on Computer Vision and Pattern Recognition, June 18-23, 2018, Salt Lake City, UT, USA. New York: IEEE Press, 2018: 4510-4520.   
[21] 苑玮琦, 白云, 柯丽. 虹膜区域选取与识别率对应关系 分析[J]. 光学学报, 2008, 28(5): 937-942. Yuan W Q, Bai Y, Ke L. Analysis of relationship between region of iris and the accuracy rate[J]. Acta Optica Sinica, 2008, 28(5): 937-942.   
[22] 张文秀, 朱振才, 张永合, 等 . 基于残差块和注意力机 制 的 细 胞 图 像 分 割 方 法 [J]. 光 学 学 报 , 2020, 40(17): 1710001. Zhang W X, Zhu Z C, Zhang Y H, et al. Cell image segmentation method based on residual block and attention mechanism[J]. Acta Optica Sinica, 2020, 40 (17): 1710001.   
[23] Kohli N, Yadav D, Vatsa M, et al. Revisiting iris recognition with color cosmetic contact lenses[C]//2013 International Conference on Biometrics (ICB), June 4-7, 2013, Madrid, Spain. New York: IEEE Press, 2013.   
[24] Yadav D, Kohli N, Doyle J S, et al. Unraveling the effect of textured contact lenses on iris recognition[J]. IEEE Transactions on Information Forensics and Security, 2014, 9(5): 851-862.   
[25] Doyle J S, Bowyer K W, Flynn P J. Variation in accuracy of textured contact lens detection based on sensor and lens pattern[C]//2013 IEEE Sixth International Conference on Biometrics: Theory, Applications and Systems, September 29-October 2, 2013, Arlington, VA, USA. New York: IEEE Press, 2013.   
[26] Czajka A, Fang Z Y, Bowyer K. Iris presentation attack detection based on photometric stereo features[C]//2019 IEEE Winter Conference on Applications of Computer Vision, January 7-11, 2019, Waikoloa, HI, USA. New York: IEEE Press, 2019: 877-885.   
[27] Silva P, Luz E, Baeta R, et al. An approach to iris contact lens detection based on deep image representations[C]//2015 28th SIBGRAPI Conference on Graphics, Patterns and Images, August 26-29, 2015, Salvador, Brazil. New York: IEEE Press, 2015: 157-164.   
[28] 尤轩昂, 赵鹏, 慕晓冬, 等 . 融合注意力机制与密集多 尺度特征的异质噪声虹膜分割方法[J]. 激光与光电子学 进展, 2022, 59(4): 0410006. You X A, Zhao P, Mu X D, et al. Heterogeneous noise iris segmentation based on attention mechanism and dense multiscale features[J]. Laser $\&$ Optoelectronics Progress, 2022, 59(4): 0410006.