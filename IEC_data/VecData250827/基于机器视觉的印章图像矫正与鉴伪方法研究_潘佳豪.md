# 湘潭大学

# 硕 士 学 位 论 文

# 基于机器视觉的印章图像矫正与鉴伪方法研究

学 位 申 请 人 潘佳豪指  导  教  师 印峰 副教授学  院  名  称 自动化与电子信息学院学  科  专  业 控制科学与工程研  究  方  向 模式识别与人工智能

# Research on Stamp Image Correction and Counterfeiting Detection Method Based on Machine Vision

Candidate JiaHao Pan

Supervisor Prof. Feng Yin

College School of Automation & Electronic Information

Program Control Science and Engineering

Specialization Pattern recognition and artificial intelligence

Degree Master

University Xiangtan University

Date May, 2023

# 摘要

印章作为一种具有法律效应的标志和证据，在合同、公文、票据和支票等现代交易中发挥着重要作用。因此，其防伪性检测和识别问题值得关注。本文通过传统图像处理方法以及深度学习的方法对盖印在公文以及票据上的印章图像进行了一系列的处理与鉴别，对多形制印章都能较好的识别，具体的工作内容如下：

（1）介绍印章预处理中的用到的传统图像处理方法，首先采用基于 HSI 颜色空间模型的印章图像提取方法，同时针对印章盖印时因盖印条件差异产生的色彩分布不均衡问题，提出了印章图像灰度均衡化的方法来解决。最后为了检测到印章图案的轮廓以便于后续的定位和识别，采用了 Canny 边缘检测的方法。

（2）针对印章噪声和畸变问题分别提出了解决方法，首先对提取出来的印章图像噪声污染的问题，提出了一种基于改进 BM3D 算法的去噪方法，该方法通过聚类的思想，可对生成的权重矩阵进行再聚类，进一步缩短去噪时间提高PSNR值。针对人为对印章进行拍摄采样时印章发生畸变的问题，提出了一种基于透视变换的多形制印章矫正方法，该方法可有效还原印章原有姿态和特征，同时，处理以后的印章样本图像可继续作为后续鉴伪过程的部分数据集。

（3）自制印章数据集，基于深度学习的方法对印章进行真伪鉴别，需要搜集大量的印章样本数据集，本文将网站生成的样本印章图像与实际矫正处理后的部分印章图像按一定比例相结合而成的圆形印章图像数据集作为训练和测试样本。网站生成的样本图像严格按照标准印章规格，生成了模拟现实情况的印章图像，同时对生成的样本进行数据增强处理，将其进行旋转、偏移等操作，扩展数据集至110 组，220 类共计2200 张图像，使得数据更具真实可靠。

（4）通过深度学习的方法使用了三种典型的网络模型对数据样本进行训练和测试，主要包括 VGGNet、MobileNet、ResNet，同时引入 ECA 注意力机制对网络进行改进，最后使用了迁移学习的方法优化网络的训练，分别对优化后的网络进行测试，综合分析网络的训练测试结果，得到了最优的算法模型训练结果，准确率可达 0.92，误检率较之迁移学习前更低。

关键词：多形制印章；灰度均衡化；去噪；矫正.；真伪鉴别；迁移学习

# Abstract

As a sign and evidence with legal effect, seals play an important role in modern transactions such as contracts, official documents, bills and checks. Therefore, its anticounterfeiting detection and identification problems are worth paying attention to. This paper uses traditional image processing methods and deep learning methods to process and identify the seal images printed on official documents and bills, and can better identify multi-form seals, the specific work content is as follows:

(1) To introduce the traditional image processing methods used in seal preprocessing, the seal image extraction method based on HSI color space model is first adopted, and the problem of uneven color distribution caused by the difference in sealing conditions during seal stamping is proposed to solve the problem of grayscale equalization of seal images. Finally, in order to detect the outline of the stamp pattern for subsequent positioning and identification, the Canny edge detection method is adopted.

(2) Aiming at the problems of seal noise and distortion, a denoising method based on the improved BM3D algorithm is proposed, which can recluster the generated weight matrix through the idea of clustering, further shorten the denoising time and improve the PSNR value. Aiming at the problem of distortion of seals when artificial sampling of seals, a multi-form seal correction method based on perspective transformation is proposed, which can effectively restore the original posture and characteristics of seals, and at the same time, the processed seal sample images can continue to be used as part of the data set in the subsequent forgery process.

(3) Self-made seal dataset, based on deep learning method to identify the authenticity of the seal, need to collect a large number of seal sample dataset, this paper will generate the website generated the sample seal image and the actual correction of some seal images in a certain proportion combined with the circular seal image dataset as training and test samples. The sample images generated by the website are generated in strict accordance with the standard seal specifications, and the seal images that simulate the real situation are generated, and at the same time, the data is enhanced and processed to rotate, offset and other operations on the generated samples, and the data set is expanded to 110 groups and 220 categories with a total of 2200 images, making the data more realistic and reliable.

(4) Three typical network models are used to train and test data samples through deep learning methods, mainly including VGGNet, MobileNet, ResNet, and the ECA attention mechanism is introduced to improve the network, and finally the transfer learning method is used to optimize the training of the network, the optimized network is tested separately, and the training results of the network are comprehensively analyzed, and the optimal algorithm model training results are obtained. The accuracy rate can reach 0.92, and the false detection rate is lower than before transfer learning.

Key words: polymorphic seals; grayscale equalization; denoising; Correction; authenticity identification; transfer learning

# 目  录

第 1 章 绪论. 1  
1.1 研究背景及意义.  
1.2 国内外研究现状 .. 2  
1.3 研究内容 ..3  
1.4 论文章节安排 .5  
第2 章 相关理论基础 .6  
2.1 引言 . ...6  
2.2 印章图像预处理 . ..6  
2.2.1 色彩空间模型 ...6  
2.2.2 形态学方法 . ...8  
2.2.3 印章图像灰度化 ..9  
2.2.4 印章图像灰度均衡化. ..9  
2.2.5 印章图像去噪 . .. 11  
2.2.6 印章图像二值化 ..12  
2.2.7 Canny 边缘检测 ..13  
2.3 深度学习与孪生神经网络 ..14  
2.3.1 卷积神经网络 . ..14  
2.3.2 孪生神经网络 ...17  
2.4 本章小结 ..18  
第3 章 基于透视变换的多形制印章矫正算法 .. ..19  
3.1 引言 . ...19  
3.2 基于改进的 BM3D 去噪算法 ..19  
3.2.1 印章图像的预处理. ..19  
3.2.2 算法去噪效果 ..21  
3.3 印章图像姿态矫正 . ..23  
3.3.1 姿态畸变程度的判断 .. .23  
3.3.2 姿态矫正 ...24  
3.3.3 外接框定位 ..25  
3.4 实验结果与分析 . .26  
3.5 本章小结 . ....28  
第4 章 基于注意力机制的孪生网络印章鉴伪算法 . ..29  
4.1 引言. ..29  
4.2 融合注意力机制的孪生网络印章鉴伪算法 ...29  
4.3 主干网络模型 .30  
4.3.1 VGGNet 网络 30  
4.3.2 MobileNet 网络 .31  
4.3.3 ECA-ResNet 网络. .33  
4.4 实验流程与对比分析 . .35  
4.4.1 环境配置. .35  
4.4.2 数据准备 .36  
4.4.3 模型训练 .37  
4.4.4 训练结果对比分析 . .38  
4.4.5 基于迁移学习的算法性能分析. .42  
4.4.6 印章图像矫正对鉴伪性能的比较分析 .43  
4.5 本章小结 .44  
第5 章 总结与展望 .45  
5.1 总结 .45  
5.2 展望 .46  
参考文献 . .47

# 第 1 章  绪论

# 1.1  研究背景及意义

印章，古时又被称为“玺”，主要作为个人信物使用，在当今社会，印章起到越来越重要的作用，人们经常使用的票据、文件、契约等都通过印章来说明其身份和可靠性，印章在某种程度上已经成为了具有最高法律效力的身份证据。同时印章作为权力和信用的象征，在全世界范围内应用广泛，以中国为例，目前执行中的《中华人民共和国票据法》中有关“签章”的条款就多达 34 处[1]。通过与金融科技公司的项目合作，前期主要对印章的提取与矫正部分做了研究，后面随着研究的深入，通过与银行从业者的沟通、结合目前社会上印章起到的法律作用以及对相关文献的阅读，印章鉴伪是一个很有价值的选题方向，正是由于印章起到作用和影响巨大，印章识别的相关研究也越来越多。

印章从用途、材料、制作工艺等多个层面可细分为公章、私人用章以及专用章等[2]。目前所有的企事业单位或者个人为验证其身份的有效性和合法性都会在其票据上加盖印章。例如，一些古玩收藏家在鉴别相关文物的真伪性时，其中加盖的印章会起到至关重要的辅助作用[3]。而目前关于印章鉴别大多还采用人工的手工折角法[4]来进行比对，这种方式会受到人工的主观因素限制，同时印章在盖印时，会出现因盖印不均导致字迹模糊、缺损等情况。而随着科技的发展，印章伪造的技术也在与时俱进，从一开始的手工设计法到如今的扫描制版法[5]，不管是伪造端还是鉴别端都一定程度的加重了鉴伪的难度。

印章伪造技术的提高，对公司和人民造成了巨大的经济损失，截止至 2023年 1 月，在中国裁判文书网网站中以印章伪造为关键词搜索共计可查询到相关案件 6488 篇，例如 2020 年 9 月 30 日最高法院发布了一起民事判决，泛海旗下民生证券一分公司经理许某涉嫌伪造公司印章，涉及诈骗金额超 3 亿，这一事件彻底给全国人民敲响了警钟。由此可见，提高印章鉴别的效率和准确率非常重要。

印章图案在实际生产和生活并非原原本本的盖印在一张白纸上，通常会受到背景和印章本身等条件的限制和干扰，在提取印章时，黑色字体通常会对红色印章造成污染，如何摆脱限制，去除噪声的问题，大大增加了印章鉴伪的难度。同时，印章在加盖时，由于用力条件和盖印角度的差异，也会使得印章的部分特征丧失或者扭曲而增大后续的鉴伪难度[6]。因此如何来解决这些问题也显得至关重要。

# 1.2  国内外研究现状

目前关于印章鉴伪主要通过三类方式。分别是人工鉴别、基于传统的图像处理方法以及深度学习的方法。人工判别印章真伪仍然是当前检验印章的主流形式，其中不仅包括剪贴法、测量法，还包括重叠法以及折角法等。而这些方法中“折角检验法”的应用最为广泛，其做法主要由工作人员把文件或票据上的印章折去一角，通过与预留印章的反复比对，检查两者的吻合程度，如果能够吻合则为真。这种方式可以在一定程度上检测出印章的真伪，尽可能的避免伪章所造成的损失，但这种方法检测效率不高，且其检验结果对工作人员的专业程度要求较高，一旦伪章与预留印章间差别太小，就可能导致鉴别出现问题。

迄今为止，传统的图像处理方法大致可分为两种：第一种方法直接将待测印章以及预留印章两幅印章图像进行配准，然后识别。主要可细分为三种配准算法，包括：基于几何特征的、特征点的以及基于边框的印章配准算法。其中Ueda 等人[7]提出了统计决策的印章识别方法，该方法利用印章的全局和局部信息，将印章的位置信息和参数与真实印章进行比对，但该方式在印章畸变时效果不佳。Fan 等人[8]则通过对印章文字的字符架构进行分析，提出了一种更加精细化的印章真伪识别方法，将骨架拓扑结构和印章的几何位置相关联，但适用场景单一，只能应用于矩形印章。Chang 等人[9]运用点匹配算法对印章进行识别，进一步的提出印鉴防伪检测方法，通过此方法可对印章伪造区域进行检测。胡庆等人[10]通过分析真假印章的差图像，引入真差假差的概念，对印章进行真伪判别，但该方法稳定性不强。姚敏、牟雪儿等人[11]通过使用 HSI 颜色模型实现印章与复杂背景的剥离，采用 SIFT 算子以及随机抽样一致性算法结合提取特征点来对印章进行识别，准确率可达百分之 92.6。吉林大学的张巍[12]沿用上述尺度不变特征变换来提取特征点，并将提取到的特征点搭建动态的三角网格，通过三角形相似的原理来对印章进行真伪识别。Liang 等人[13]则通过改变印章的轮廓结构，利用投影变换得到的变换矩阵来对印章进行判别，这种方式可以使计算流程简化但适用场景有限。刘丰威等人[14]利用待测印章和预留印章之间的像素差异性，提出了一种新的印章真伪判别算法，这种方法主要是：若两印章之间的差异最小值处于设定的阈值区间，则表示印章可信。该方法识别印章种类单一，只适用于矩形印章，同时对于像素丢失的印鉴识别效果不佳。

第二种方法是无需对印章进行配准操作，直接通过选定的特征向量对待侧印章进行识别。南开大学杨新军等[15]设计了一种基于环投影模板匹配的印章图像识别方法，这一方法把印章分为了内部文字和外部边框，然后利用二维坐标将印章进行投影得到特征向量，最后对比常用的一维模板匹配方法以及统计决策法，得到了更优的效果。张先盟等[16]使用了一种Hu不变矩特征值的方法，此方法不需要配准印章，但对噪声敏感。孙红岩等[17]在频谱特征和向量机的基础上，提出了一种新的印章识别方法。张淼[18]利用加权欧式距离的方法来提取印章图像的Zernike 矩阵特征，但该方法对图像的分辨率有一定要求。朱根胜等[19]开发了一款指令集的印章识别系统，该系统从印章的形态特征出发，通过 SIFT算子提取特征向量，并且经过 SVM 来进行判别，最终识别的准确率为百分之93.2。之后，赵红东、朱根胜等人[20]还继续对其进行了一系列优化，利用印章的 Krawtchouk 矩作为 SVM 的参数，经过此方法优化后的印章识别效果相比之前更好。

基于深度学习的处理方法目前主要通过孪生神经网络来对印章进行真伪识别。1993 年，由 LeCun 等在[21]上提出了孪生神经网络（Siamese network），并将其首次用于支票上的签名验证，即比对支票上的签名与银行预留签名是否相同。通过神经网络提取特征，得到特征向量，然后利用两个图片的特征向量判断图片相似度。经过长时间的发展历程，孪生神经网络应用广泛，主要有 2005 年由LeCun 等在[22]中和 2010 年 Hinton 等在[23]中应用于人脸验证，之后 2015 年 hjimce等[24]将 Siamese network 进行了改进，借助空间池化金字塔实现了不同大小的图片输入。Horiuchi 等人[25]构建三维模型来分析二维的印章图像，通过 RNN（循环卷积神经网络）来识别印章。复旦大学的陈运文等人[26]将待测印章与标准印章对比作差，将差值在空间上做结构化分析，得到的特征输入到 3 层反向传播网络进行印章识别。Zhu等人[27]将SIFT算子和反向传播网络相结合，把SIFT算子提取到的特征放入反向传播网络得到最优的参数从而完成识别。章毅等利用PCNN（脉冲耦合神经网络）识别印章，对处于复杂背景下的印章提取有很好的效果。万水龙，余彪等[28]提出了一种以 Krawtch-RBF 为基础的印章识别方式，把提取到的 Krawtchouk 矩加入到 RBF（径向基函数神经网络）中，这种方法具有极高的准确率。2020 年宋禹廷[29]在硕士论文中提出的基于深度孪生网络的印章识别，但其最后效果不佳。西安电子科技大学的张娜[30]提出了一种基于 SIFT算子和 Horn-Schunck 光流运动矢量法的印章匹配算法，通过提取印章的关键点和计算特征描述子，最终印章的匹配率可达百分之 80。

# 1.3  研究内容

近些年来，伴随着社会经济体系的不断完善和发展，如何提高印章的自动识别准确率和效率已经越来越受到重视。然而，通过计算机视觉方法来对处于复杂背景下印章图像进行提取和识别，仍然存在巨大的挑战，这主要体现在以下几个方面：

（1）盖印条件限制

印章图像是人为的使用印章蘸取印泥加盖在文件或者票据上形成的图案，它在加盖时与人的用力是否均匀、盖印的角度、文件本身的纸张类型等因素密切相关，这些因素会导致印章图像轮廓或字体出现颜色深浅不一、背景噪声干扰以及模糊残缺的情况。当盖印条件处于理想状态下时，此时的印章图像清晰，易于后续的提取和识别；而当用力过大时，印章图像特征会过于明显；过小时，又会导致特征不明；盖印角度也会影响印章的盖印效果；而文件本身的纸张类型也会影响印章图像的细节特征，若纸张易晕染或者盖印时加垫了其它纸张，都易造成印章图案的特征冗余或丢失。由此可见，盖印条件的情况不同，都会对后续的印章提取以及鉴伪造成影响和干扰，因此，如何规避这些因素对后续印章鉴伪产生的影响是重中之重。

# （2）印章数据集的缺少以及人为的干扰

真实印章样本由于涉及到个人的隐私等问题，目前实际公开的印章样本数据集几乎没有，而想要通过深度学习的方法对印章进行鉴别，一定的数据集是必不可缺的。另一类问题是人在采集印章图像时，由于人为的视觉因素等干扰，极易出现拍摄时印章出现畸变等情况，这或多或少的会加大后续印章鉴伪的难度，因此，如何扩充数据集样本以及避免印章出现畸变的情况也成为后续工作的方向之一。

通过对当前印章检验中面临的的问题进行分析，本文从以下三部分着手进行相关研究：

（1）对于印章盖印条件的差异性，使得后续印章图像丢失必要的特征导致其难以鉴别的问题。本文从图像预处理出发，针对因盖印力度和角度使印章图案缺损模糊等不符合规格的问题，提出了一种改进的 BM3D 去噪算法，同时引入腐蚀和膨胀等形态学处理方法用于印章图像增强，为后续的印章图像矫正和鉴伪研究奠定了基础。

（2）针对拍摄时因人工引起的印章畸变问题，根据各类印章的特点，从印章识别定位、畸变判别到矫正处理分别制定了不同的方法。首先根据轮廓检测剔除无关的轮廓，接着定位到印章轮廓并计算该轮廓的最小外接矩形框，通过构建最小外接矩形框即可根据相应的长度关系判别各形制印章的畸变程度。最后，若印章发生畸变，提出了一种基于改进透视变换的方法对畸变印章进行矫正。

（3）基于注意力机制的孪生神经网络算法。此部分将第三章识别以后的印章图像以及自制印章样本作为数据集，并将其放入到基于 ECA 的孪生 VGGNet、MobileNet、ResNet 网络中进行训练和测试，同时引入了迁移学习的方法对这三种网络模型分别进行了优化，最后得到的结果以ResNet 网络作为Backbone为最

优。

# 1.4  论文章节安排

全文结构安排如下：

第 1 章为绪论部分，该部分主要介绍本课题的来源、研究意义以及国内外对印章的两种主流识别技术的发展历程，这其中还穿插了对各种算法的优缺点的论述，并且对当前印章识别过程中所面临的实际问题进行了列举，同时提出了自己的解决方案。最后详细阐述了本文的研究内容和章节安排。

第 2 章介绍了印章识别的相关基础理论。首先阐述了图像预处理的算法基础，通过色彩空间模型方法完成印章图像的提取；接着介绍了印章提取时需要用到的二值化处理、去噪以及边缘检测等基础理论；最后介绍了深度学习中的神经网络，由卷积神经网络引入到孪生神经网络并详细介绍了其网络架构，为后续的印章鉴伪提供了理论基础。

第 3 章介绍了基于透视变换的多形制印章矫正算法。这部分首先对各类印章的噪声通过改进的 BM3D 算法进行了去除；接着通过定位印章图像，引入最小外界框来判别印章是否畸变，接着结合透视变换的方法对各类畸变印章进行了矫正；最后通过多组实验验证了本文算法的有效性同时表明了下一步的研究方向。最后本章将识别矫正后的一部分印章图像作为第四章的实验样本，进一步保证了结果的可靠性。

第 4 章介绍了基于注意力机制下的孪生神经网络的印章鉴伪算法。本章针对目前印章鉴伪中数据集不充足的问题，通过引入孪生神经网络来解决；同时面对细微特征关注不够的问题，引入了注意力机制来加强特征提取并分别进行了实验测试；接着介绍了三种代表性的网络模型并以此为架构搭建了孪生神经网络，并将效果最好的ECA-ResNet 作为最后的算法模型。最后对印章样本数据集做了真伪鉴别的测试，同时引入了迁移学习对模型做了进一步优化。

第 5 章为总结与展望。首先对论文的研究内容进行总结，一方面给出了工作的待改进点和相关研究成果，另一方面对研究的后续工作做出了展望。

# 第2 章  相关理论基础

# 2.1  引言

随着多年的发展，印章形制各异，常见的有圆、椭圆、以及矩形，本文在矫正部分分别对各式印章进行了研究，鉴伪部分主要针对圆形印章做了验别。本章主要对各式印章图案做了提取、去噪以及矫正操作。首先介绍了基于 HSI颜色空间下印章图像提取的基本原理，进一步的，针对文字或背景干扰造成噪声的印章图像，提出了基于改进 BM3D 的去噪算法，并对拍摄采样时发生畸变的印章图像通过构造外接框，引入透视变换的方法，对畸变印章作了矫正。最后介绍了相关的深度学习理论以及孪生神经网络的基本原理。

# 2.2  印章图像预处理

# 2.2.1  色彩空间模型

印章图像都是盖印在票据或公文中，提取通常都是借助印章本身颜色与背景的差异性，故而基于颜色空间模型的印章提取分割技术一直以来被广泛应用，目前，根据色彩空间模型不同，主要可分为 RGB 模型和 HSI 模型。

# （1）RGB 色彩空间模型

基于 RGB 色彩空间模型是通过比对票据背景颜色和印章颜色间的差异性，利用三原色的差值来提取印章。以本文图示的红色印章为例，是将 RGB 模型中的红色部分通道值与其它两个基色进行差异性对比，从而提取出红色印章。公式如下所示：

$$
{ \bigl ( } R ( x , y ) - G ( x , y ) { \bigr ) } + ( ( R ( x , y ) - B ( x , y ) ) > T
$$

其中， $R ( x , y )$ 是红色分量， $\boldsymbol { G } ( x , y )$ 是绿色分量， $B ( x , y )$ 是蓝色分量。 $T$ 为阈值。但该算法有较为明显的限制，主要取决于 $T$ 的大小，若 $T$ 值取得较大，则会提取出多余干扰信息； $T$ 较小，则会导致印章提取不完整，丢失关键信息。

（2）HSI 色彩空间模型

HSI 色彩空间模型以人的视觉为基础，通过饱和度（Saturation）、色调（Hue）、亮度（Intensity）三种特征[31]来描述色彩。通过这三个特征可对任意一种颜色进行描述，其颜色空间模型如图 2.1 所示。

![](images/0cb3142fb543f3e8294e44a9ae6db2852f80e176827f9dbc548fd723c7019004.jpg)  
图 2.1 HSI 色彩空间模型

如图 2.1 所示，左侧圆锥体的中轴代表亮度 I，上顶点为白色，下端为黑色。横向切割圆锥体可得到任意大小的圆行截面，该截面可表示一定亮度下饱和度S 与色度 H 的组合。色调可用角度来表示，范围为[0,360]，例如红色可用 0 或$3 6 0 ^ { \circ }$ °来表示，各颜色都可用一定角度来体现；圆心到平面某点的距离表示饱和度，圆心饱和度为0，范围为[0,1]。基于此，图中三维立体图中任意一个坐标点都可描述某一颜色。而实际的印章图像是用RGB颜色模型描述，从公式（2.2）可完成将印章图像从 RGB 颜色空间到 HSI 颜色空间的转化。

$$
\left. \begin{array} { l } { \displaystyle \theta = \operatorname { a r c c o s } \left\{ \frac { \left[ \left( R - G \right) + \left( R - B \right) \right] / 2 } { \left[ \left( R - G \right) ^ { 2 } + \left( R - G \right) \left( G - B \right) \right] ^ { | J | ^ { 2 } } } \right\} } \\ { \displaystyle I = \left( R + G + B \right) / 3 } \\ { \displaystyle S = 1 - \frac { 3 } { R + G + B } \Big [ \operatorname* { m i n } ( R , G , B ) \Big ] } \\ { \displaystyle H = \left\{ \theta , G \geq B \right. } \\ { \displaystyle 3 6 0 - \theta , G < B } \end{array} \right.
$$

由于 HSI 色彩空间模型各个分量之间的独立性更强，相比 RGB 色彩模型之间的相互影响，HSI 色彩模型更适合于本文场景，故本文采取基于 HSI 的色彩模型做印章的提取。其流程如图 2.2 所示。

![](images/a1b160409df540210ae294170875af93b6fdab0fdd8c1fd868a9f71514dc9549.jpg)  
图 2.2 印章提取流程图

其主要实施过程如下：

（1）限制提取轮廓大小的临界值，根据公式（2.2）将印章图像从 BGR 色彩空间转换到HSI。（2）限制红色阈值从[156,43,46]到[180,255,255]，提取红色印章 P1。（3）为防止提取印章的轮廓不清晰，再次限制阈值空间[0,43,46]到[9,255,255]，得到印章图像 P2。（4）生成指定大小的空白图像，将两幅图像作像素值的叠加，最终提取结果如图2.3 所示。

![](images/26d618b6ba5a4c1cd41d2b700b41da7c62452638042e145f4298380aecb70b4b.jpg)  
图 2.3 印章提取对比图

# 2.2.2  形态学方法

数字形态学是以集合论作为数学基础[32]的数学工具，用来对图像进行数学分析。它的基本原理是通过使用形态各异的结构元素去度量和提取特定区域的像素点，从而达到保持基本的形态结构、简化图像信息以及去除不相干的像素块的目的。常见的基本运算分为开运算、闭运算、腐蚀和膨胀四种，并且广泛应用于图像滤波、增强、分割等场景中，本节主要用到腐蚀和膨胀运算，以下对这两种运算进行分别阐述：

（1）腐蚀运算

设元素 $Z ^ { 2 }$ 有 A 和 B 集合，其中 A 表示原始图像，B 表示结构元矩阵，则 B腐蚀A 图像定义为：

$$
A \Theta B = \left\{ Z | B _ { Z } \subseteq A \right\}
$$

其中Z 表示图像中某个像素点，若原始图像A 整个小于结构元矩阵B，那么经腐蚀操作后，A 会完全消失；反之，A 中部分区域会出现断裂、分离的现象，

从而达到去除干扰，消除噪声的目的。

# （2）膨胀运算

设元素 $Z ^ { 2 }$ 有A 和B 集合，其中 A 表示原始图像，B 表示结构元矩阵，则 B膨胀A 图像定义为：

$$
A \oplus B = \left\{ \mathbf { z } \big | ( \hat { \mathbf { B } } ) _ { z } \mathrm { ~ I ~ } A \neq \emptyset \right\}
$$

其中Z 表示图像中某点， $z$ 表示集合平移量，用结构元矩阵来膨胀原始图像时，将结构元素的原点与二值图像中的相对的像素值 Z 进行重叠，若 A 与 B 的集合为非空集合，那么将 Z 处的像素值置 1，否则置为 0。膨胀运算具备扩大原本图像的作用，实际中常被用来连接或填充图像中的孔洞或间隙。

1 B ?   
中 ★   
宝 3

# 2.2.3  印章图像灰度化

将彩色图像转变为灰度图像的操作称为图像灰度化。灰度图像有 256 个分级，对于 RGB 色彩空间模型的图像而言，当三个分量相同时，图像变为灰度格式；去除其它两个分量只提取一个分量时，图像也为灰度形式。通常计算机在处理 RGB 格式的图像时，需要同时对三个分量进行处理，处理方式复杂且耗时较长。因此本文主要对改变亮度后的灰度图像进行操作。为便于处理，本文采用加权平均的方法对印章图像的三个分量进行加权处理，具体可表示为：

$$
I ( x , y ) = 0 . 3 I _ { _ R } ( x , y ) + 0 . 6 I _ { _ G } ( x , y ) + 0 . 1 I _ { _ B } ( x , y )
$$

其中， $I ( x , y )$ 为图像中像素点的灰度值， $I _ { \scriptscriptstyle R }$ 为红色分量 ， $I _ { \scriptscriptstyle G }$ 为绿色分量，$I _ { { } _ { B } }$ 为蓝色分量。

# 2.2.4  印章图像灰度均衡化

图像的灰度均衡化又被称为直方图均衡化[33]。灰度直方图对图像中的灰度分布以及各个灰度级所占的比例具有直观的描述。其做法是将图像的直方图分布函数转化为另一种分布，从而使其范围分布更广。灰度均衡化的公式如下表

示：

$$
D _ { _ B } = f ( D _ { _ A } ) = D _ { _ { M A X } } \int _ { 0 } ^ { D _ { _ A } } p _ { _ { D _ { _ A } } } ( \mu ) d _ { \mu }
$$

其中 $D _ { { } _ { B } }$ ， $D _ { \scriptscriptstyle A }$ 分别代表转换后和转换前的像素， $D _ { \ / { M A X } }$ 表示转化前像素的最大值， PDA代表概率密度函数。

而对于常见的离散形式的像素分布，直方图均衡化公式为：

$$
D _ { B } = \sum _ { j = 0 } ^ { k } \frac { n _ { j } } { n } \quad k = 0 , 1 , 2 \cdots L - 1
$$

其中， $D _ { { } _ { B } }$ 表示映射以后的值， $n _ { j }$ 表示当前像素级的像素个数， $n$ 表示图像中的像素总和， $\mathrm { ~ L ~ }$ 表示图像中的灰度级总和。对于印章图像来说，通常易受到盖印力度而出现盖印不均的情况，而灰度均衡化能在一定程度上解决此类问题。

X 信息信 X 信 X 信 息  
电 产 电 电 酒  
潭 汉 潭 ☆ 公 潭 公  
福 测试专用章 心 4 票 测试专用章 C 新 测试专用章 心63中 （15  
(a)盖印力度不同的原图像 (b)均衡化前 (c)均衡化后

如上图 2.5 所示，图像经过灰度均衡化后特征更明显，之前颜色不突出的区域经均衡化后颜色特征更为突出。

![](images/36da6aefcd332d74163da83a47a47ec00416eaf6bc774533150f7c34dce248b3.jpg)  
图2.5  均衡化前后图像的对比图  
图 2.6  灰度均衡化前后的直方图对比

图 2.6 中 $\mathbf { x }$ 轴表示像素点的灰度值，y 坐标轴表示像素点的个数，由上图可以看出，经均衡化后的灰度直方图中的像素值分布更均匀。

# 2.2.5  印章图像去噪

通常，提取到的印章图像会受到一定的背景遮挡以及噪声干扰影响，导致印章图像关键信息丢失，这时，图像去噪算法可一定程度上解决此类问题。去噪算法也可以理解为滤波算法[34]，常见的滤波算法可去除大部分的椒盐噪声以及高斯噪声，但印章图像的噪声除了这两种以外，还会因背景与印章图案重叠使其提取的印章图像受叠加像素干扰，使提取的印章图案增添额外的噪声干扰，此类噪声依靠传统的去噪方法较难去除，本文采用基于改进的 BM3D 权值聚合去噪算法[35]来对印章进行去噪。此方法相比原算法不仅能缩短去噪时间，还能有效还原印章边缘纹理信息，去噪性能优越。主要去噪流程如下图 2.7 所示：

![](images/9a76e9fc9a39871c5740181a7de5b10a6d4f7542f851bbe178d17f5a0f6674e1.jpg)  
图 2.7 聚合权重的 K 均值聚类处理

如上图所示，改进后的算法第一步为计算噪声图像的基础估计图，其又可分为三个主要步骤：（1）相似块匹配：根据相似度确定参考块并将其组合成三维的图像块。（2）协调滤波：对这些组合块进行协同变换和滤波处理；（3）权重整合。首先，将印章图像分为 $N _ { 1 } \times N _ { 1 }$ 的大小块，记无噪声图像 $\mathbf { y }$ 中某个大小为 $N _ { 1 } ^ { \mathrm { { h t } } } \times N _ { 1 } ^ { \mathrm { { h t } } }$ 块为 $Y _ { _ { X } }$ ,与其同样大小的不同位置上的块记为 $Y _ { _ { X R } }$ ,一般以 3 \~ 6 的步长，从图像左上角出发，采用栅格扫描的方式，直至铺满整幅图像。其两者之间的度量距离为：

$$
\mathbf { d } ^ { i d e a l } ( Y _ { X R , } Y _ { X } ) = { \frac { \left\| Y _ { _ { X R } } - Y _ { _ { X } } \right\| _ { 2 } ^ { 2 } } { ( N _ { 1 } ^ { \mathrm { h t } } ) ^ { 2 } } }
$$

同样的，对于有噪声图像 $z$ ，其块之间的匹配误差为：

$$
d \left( Z _ { _ { X R } } , Z _ { _ X } \right) = \frac { \left\| \gamma ^ { ^ { } } ( \Upsilon _ { 2 D } ^ { h t } ( Z _ { _ { X R } } ) ) - \gamma ^ { ^ { } } ( \Upsilon _ { 2 D } ^ { h t } ( Z _ { _ X } ) ) \right\| _ { 2 } ^ { 2 } } { \left( N _ { 1 } ^ { h t } \right) ^ { 2 } }
$$

$\gamma ^ { ' }$ 和 $\Upsilon _ { 2 D } ^ { h t }$ 分别表示硬阈值和二维正交变换。接着根据经验选择相似块之间的最大误差阈值 $\tau _ { m a t c h } ^ { h t }$ ，可得到一定大小的坐标块集合：

$$
S _ { X R } ^ { h t } = \Bigl \{ x \in X : d ( Z _ { _ { X R } , } Z _ { _ X } ) \leq \tau _ { _ { m a t c h } } ^ { h t } \Bigr \}
$$

将这些坐标块集合进行堆叠即可得到 $N _ { 1 } ^ { \mathrm { h t } } \times N _ { 1 } ^ { \mathrm { h t } } \times \left| S _ { X R } ^ { h t } \right|$ 的 3D 数组，将其二维部分进行离散余弦变换，第三维进行小波变换如 Haar 等，可得到块匹配后的估计值为：

$$
\hat { Y } _ { S _ { X R } ^ { h t } } ^ { h t } = \gamma _ { 3 D } ^ { h t - 1 } ( \Upsilon ( \gamma _ { 3 D } ^ { h t } ( Z _ { S _ { X R } ^ { h t } } ) ) )
$$

其中， $\gamma _ { 3 D } ^ { h t - 1 }$ 和 $\gamma _ { 3 D } ^ { h t }$ 分别表示正反三维变换， $\Upsilon$ 表示硬阈值滤波。记硬阈值处理后的系数个数为 $N _ { \mathrm { h a r d } } ^ { X R }$ ，噪声标准差为 $\sigma$ ，则有阈值后输出的权重系数：

$$
w _ { X R } ^ { h t } = \left\{ \begin{array} { l l } { \displaystyle { \frac { 1 } { \sigma ^ { 2 } N _ { h a r d } ^ { X R } } } , i f ~ N _ { h a r d } ^ { X R } \geq 1 } \\ { 1 . \quad } & { \mathrm { o t h e r s } } \end{array} \right.
$$

接着经过K 均值聚类算法聚类，得到最后的基础估计值，主要是对某个像素点的参考块及相似块做加权平均可得基础估计为：

$$
\mathbf { y } _ { b a s i c } ( x ) = \frac { \displaystyle \sum _ { x _ { R } \in X } \sum _ { x _ { n } \in s _ { X R } ^ { h t } } w _ { X R } ^ { h t } \hat { Y } _ { x _ { n } } ^ { h t , X R _ { ( X ) } } } { \displaystyle \sum _ { x _ { R } \in X } \sum _ { x _ { n } \in s _ { X R } ^ { h t } } w _ { X R } ^ { h t } \mathcal { X } _ { x _ { n } } } , \forall x \in X
$$

$\chi _ { x _ { n } }$ 为匹配函数，判断 $x$ 是否在 $x _ { n }$ 上。

Step2 阶段的计算过程与 Step1 相似，不同之处在于其输入同时包括了噪声和基础估计图像。随后对上述三维图像矩阵进行一维和二维变换，并通过维纳滤波的方式对三维矩阵进行系数放缩。最后，维纳滤波的系数和噪声强度则共同来决定最终估计图中的加权权重值。

# 2.2.6  印章图像二值化

图像的二值化实质上就是最简单的图像分割[35]，但与其不同的是，它是通过设定一定的阈值 T（ $\mathrm { \Phi } \cdot \mathrm { T } { = } 1 8 0$ ）来对背景与待分割的区域进行分离的，并且将图像上的像素置为 0 或 255 两种，从而使图像具备明显的非黑即白的视觉感受。本文中二值化后的图像背景用 1(白色)，印章轮廓用 0(黑色)表示。使用二值化后的印章图像一方面能减少数据的维度，另一方面可消除噪声干扰，凸显有效区域的特征。它的定义公式如下所示：

$$
\mathbf { g } ( x , y ) = { \left\{ \begin{array} { l l } { 2 5 5 , i f f ( x , y ) \geq T } \\ { 0 , \quad { \mathrm { e l s e } } } \end{array} \right. }
$$

其中T 为超参数，可根据实际情况设定， $f ( x , y )$ 表示图像的像素点。由此

公式可见，阈值的选取非常重要，在此场景下，印章与背景颜色差异明显，故而本文采取全局阈值的方法对印章进行了二值化处理，最终提取的效果如下图2.8 所示：

![](images/7f4063bf95c4e59f4de29ca06f51d815393585f33adf03483c3e5b2d3627aa61.jpg)  
图 2.8  二值化处理后的印章图像

# 2.2.7  Canny 边缘检测

为了进一步确定印章轮廓的边缘位置，本文采用的方法是 John Canny 在1986年提出的一种基于 Canny 算子的边缘检测算法[36]，分别是以下四个步骤：高斯滤波降噪、计算图像梯度、非极大值抑制、双阈值筛选。下面对这几个步骤分别介绍：

# （1）高斯滤波

通常图像边缘易收到噪声干扰，因此，为消除一些椒盐噪声以及高斯噪声，同时检测出正确的边缘信息。在实践过程中，通常采用高斯滤波的方式对图像中的噪声进行去除，通过构建合适的滤波器对图像的像素点附近的像素作加权平均，从而获得最有效的滤波结构。一般来说，滤波器的大小可以针对不同的对象有针对性的选取。同时，高斯内核大小的选取对于去噪效果也起到关键性的作用，核越大，噪声对边缘信息的敏感度就越小。对于本文来说，高斯核分别有 $\mathbf { x }$ 和 $\mathsf { y }$ 两个维度，两个函数的标准差相等，核的大小为 $7 ^ { * } 7$ 。公式如下所示：

$$
G \big ( x , y \big ) = \frac { 1 } { 2 \pi \sigma ^ { 2 } } \exp ( - \frac { x ^ { 2 } + y ^ { 2 } } { 2 \sigma ^ { 2 } } )
$$

（2）图像梯度计算

Sobel算子为两个 $3 ^ { * } 3$ 的矩阵元素，分别用 $S _ { x }$ 和 $S _ { y }$ 表示。 $S _ { x }$ 用来计算图像 $x$ 方向上的梯度矩阵 $G _ { x }$ ， $S _ { y }$ 用来计算图像 $y$ 方向上的梯度矩阵 $G _ { _ y }$ 。具体可表示为：

$$
G _ { x } = S _ { x } * I { \left| \begin{array} { l l l } { - 1 } & { 0 } & { + 1 } \\ { - 2 } & { 0 } & { + 2 } \\ { - 1 } & { 0 } & { + 1 } \end{array} \right| } * I
$$

$$
G _ { y } = S _ { y } * I \left| \begin{array} { r r r } { { - 1 } } & { { - 2 } } & { { - 1 } } \\ { { 0 } } & { { 0 } } & { { 0 } } \\ { { + 1 } } & { { + 2 } } & { { + 1 } } \end{array} \right| * I
$$

其中，I 表示灰度图像矩阵，图像矩阵坐标系原点在左上方， $\mathbf { x }$ ，y 正方向一 $G _ { x y }$ 同直角坐标系从左往右。则由式 2.18 计算可得梯度矩阵

$$
g _ { x y } ( i , j ) = \sqrt { g _ { x } ( i , j ) ^ { 2 } + g _ { y } ( i , j ) ^ { 2 } }
$$

# （3）非极大值抑制

在求取图像的梯度矩阵及方向后，需要通过梯度幅值与方向对边缘轮廓进行非极大值抑制操作，其目的主要是消除边缘检测带来的杂散效应，主要实施方法是将当前梯度强度值与垂直方向上的相邻像素间的梯度强度相比较，如果是极大值，就保留；反之，将其抑制。

# （4）双阈值筛选

双阈值筛选可理解为通过定义两个高低阈值，当梯度强度高于高阈值的像素点被定义为强边缘，保留下来并将像素值置为 255，低于低阈值的像素点设置为 0；而梯度强度高于低阈值低于高阈值的点，通过判断其邻域是否有大于高阈值的点，若存在，则将其像素点保留并置为 255，反之则舍弃置为 0。

# 2.3 深度学习与孪生神经网络

在深度学习[37]领域，神经网络起到了极其重要的作用。但传统的神经网络模型训练需要依靠大量的数据样本作为依靠和支撑，而在印章鉴别中，涉及到一些样本和隐私问题，使其不得不采用其它的神经网络模型来训练和测试。本文主要采用基于孪生神经网络的印章鉴伪算法对印章图像做鉴别，详细介绍其网络结构、损失函数以及数据集的构建，同时为后续研究铺垫理论基础。

# 2.3.1  卷积神经网络

在介绍孪生神经网络之前，首先对卷积神经网络[38]展开介绍。卷积神经网络是通过模拟人类神经元并在此基础上搭建的一种数学计算模型，由偏置常量的神经元和可学习的权重组成。常见的卷积神经网络大多由卷积、池化、全连接层构成，下面以字符识别为例介绍卷积神经网络，从而在此基础上搭建孪生神经网络。

![](images/90b5e1c3090fcad0c13193833ee69f9adf08578ac9e257ac35c3605ef2ae0abb.jpg)  
图 2.9  卷积神经网络结构示意图

（1）输入层

输入层可以用来处理多维数据，此处，还可用来接收平面上的二维像素点或者 RGB 图像。一般的，该层通过对原始图像进行去均值、归一化操作，以此提升后续训练过程的学习效率。

# （2）卷积层

卷积层的作用是对输入图片中的信息进行提取，这些信息和特征主要是由每个像素间不同的组合方式来体现，如常见的一些纹理、颜色特征。在实际处理过程中，常用到矩阵卷积来提取图像的特征，通常矩阵卷积可以分为全卷积和有效值卷积两种，其表达式如下：

全卷积：

$$
z ( u , \nu ) = \sum _ { i = - \infty } ^ { \infty } \sum _ { j = - \infty } ^ { \infty } x _ { i , j } \ast k _ { u - i , \nu - j }
$$

若 $K$ 是 $n ^ { * } n$ 阶矩阵， $X$ 是 $m ^ { * } m$ 阶矩阵， Krot是由K 旋转180o得到，有效值卷积可定义为：

$$
z \big ( u , \nu \big ) = \sum _ { i = - \infty } ^ { \infty } \sum _ { j = - \infty } ^ { \infty } x _ { i + u , j + \nu } { ^ { * } k _ { r o t } } _ { i , j } { ^ { * } \chi ( i , j ) }
$$

$$
\chi ( i , j ) = \left\{ \begin{array} { l l } { 1 , 0 \leq i , j \leq n } \\ { 0 , o t h e r s } \end{array} \right.
$$

其中， $x$ 为被卷积矩阵， $k$ 为卷积核， $z$ 代表最后的卷积结果。

下面以单通道图像为例，对矩阵卷积运算进行描述：

![](images/70585bbe21ca60d11e878333a4ce554bb120772447f307324227151c5d242167.jpg)  
图2.10  神经网络卷积运算示意图

如上图所示，展示了卷积层中单通道输入时卷积运算的流程，而在实际应用过程中，图像大多是 RGB 三通道，这时候需要对卷积核的通道数相应的进行调整，进而出现对应个数的特征图，每层的图像矩阵都会与其对应的卷积核进行卷积运算，从而生成新的特征图，用公式定义卷积层的输出为：

$$
\boldsymbol { \mathfrak { Z } } _ { u , \nu } ^ { ( l ) } = \sum _ { i = - \infty } ^ { \infty } \sum _ { j = - \infty } ^ { \infty } \boldsymbol { x } _ { i + u , j + \nu } ^ { ( l - 1 ) } \cdot \boldsymbol { k } _ { r o t i . j } ^ { ( l ) } \cdot \chi ( i , j ) + \boldsymbol { b } ^ { ( l ) }
$$

$$
\chi ( i , j ) = \left\{ \begin{array} { l l } { 1 , 0 \leq i , j \leq n } \\ { 0 , o t h e r s } \end{array} \right. , a _ { u , \nu } ^ { ( l ) } = f ( \boldsymbol { z } _ { u , \nu } ^ { ( l ) } )
$$

如公式 2.22-2.23 所示，假定输入层为第 $l - 1$ 层，它的输入特征图为$\boldsymbol X ^ { ( l - 1 ) } ( \boldsymbol m \times \boldsymbol m )$ ，特征对应的卷积核为 ${ K ^ { ( l ) } } ( n \times n )$ ，偏置单元 $\boldsymbol { B } ^ { ( l ) }$ ，输出矩阵为 $z _ { u , \nu } ^ { ( l ) }$ ，下采样后的特征图 $a _ { u , \nu } ^ { ( l ) }$ 。

# （3）池化层

池化层的本质表示一个下采样，通过池化操作，会使卷积过程中产生的越来越高的数据维度降维，也会对数据进行压缩，减少训练过程中的参数量。常用的池化操作可分为两种：平均池化和最大池化，平均池化(mean-pooling)是通过一定的步长对特征图的区域内的像素求均值；最大池化则是通过一定步长对特征图的区域内的像素求最大值。

# （4）全连接层

全连接的位置一般在卷积神经网络的尾部，它的作用是对前面提取到的特征做一个加权求和，同时把结果输入到激活函数，最终实现对目标的分类。其加权求和计算公式如下表示：

$$
y _ { w , b } ( x ) = f \left\{ \sum _ { i = 1 } ^ { n } w _ { i } x _ { i } + b _ { i } \right\}
$$

其中， $w _ { i }$ 表示全连接层的权重系数， $x _ { i }$ 表示上一层第 i 个神经元的值， $b _ { i }$

表示全连接层的偏置量。其结构如下图 2.11 所示：

![](images/025476326255204e43d0e03d9a0f251b5a2cf9e235e8aaf3d30467d8096287bd.jpg)  
图 2.11 全连接层结构图

（5）激活函数

在神经网络中，每层神经网络后面都会使用一个激活函数对输出的结果进行运算，一般来说激活函数分为线性和非线性，如下表2.1 所示为常用的一些激活函数名称和表达式：

表 2.1  激活函数  

<html><body><table><tr><td>激活函数名称</td><td>函数形式</td></tr><tr><td>阈值函数</td><td>f(x) |1,x≥0 [0,x<0 ）=</td></tr><tr><td>线性函数</td><td>f(x)=kx</td></tr><tr><td>对数sigmoid函数</td><td>f(x)= 1 1+e-x</td></tr><tr><td>正切 sigmoid 函数</td><td>f(x)= tanh(x)</td></tr></table></body></html>

# 2.3.2  孪生神经网络

孪生神经网络就是“双生神经网络”，顾名思义就是两个一模一样的神经网络，可以理解为任意两个结构相同，且权重共享的卷积神经网络。它们在面对数据样本少，处理分类任务，评价两个样本之间的相似度时表现优越。具体结构如下图2.12 所示：

![](images/725366b15f4c74046b185dbe356f40039ba605150de326195dd207502ab50e95.jpg)  
图 2.12 孪生神经网络结构示意图

如上图 2.12 所示，孪生神经网络评价两个输入的相似度时，采用的是双通道，共享权值的卷积神经网络对图像进行分类以及相似度判别。在这之中，神经网络可以是任意不同的卷积神经网络，对不同的场景可以构建不同的网络结构。本文构建的孪生网络中，采用的是二元交叉熵损失函数，当两个输入相似度较高时，标签为 1，loss 为1；反之，标签值为0，loss 为0。

# 2.4  本章小结

本章主要介绍了后续章节中印章提取、定位、去噪等各类技术所需的理论方法和概念。其中印章预处理部分，对印章色彩空间模型、形态学方法、图像灰度化、去噪、二值化、Canny 边缘检测做了详细的阐述以及部分实验效果图展示。这一部分为后续多形制印章矫正部分奠定了良好的开端；深度学习与孪生神经网络部分通过卷积神经网络引出深度孪生网络，介绍了孪生神经网络处理相似度差异问题的优越性，同时也将为后续印章鉴伪做好理论基础。

# 第3 章  基于透视变换的多形制印章矫正算法

# 3.1  引言

印章的去噪和矫正技术作为后续鉴伪的基础，清晰有效的识别印章对后续流程至关重要，相关的研究也越来越深入。欧阳欢等[39]提出了一种基于多特征融合的发票印章识别方法，这一算法通过检测图像中的感兴趣区域，可剔除无关目标，同时对剩余的区域进行聚类分析并进行椭圆拟合，实现对椭圆形印章的识别与扶正。该方法识别准确度较高，但是实际应用场景受到一定限制。由于拍摄角度等问题引起的印章图像畸变会影响到后续印章的处理效果，Sargur N等[40]提出了一种基于 Hough 变换的文本图像分析，通过对矩形像空间映射到极坐标中的处理方法，检测文本倾斜角度，但该方法需要对印章进行预先框定，同时只适用于正向垂直拍摄，对畸变印章处理效果一般。刘珍丽等[41]提出了一种基于 Bubble 小波函数的印章鉴别方法，该方法通过傅里叶系数变换得到印章的形状特征从而对印鉴进行自动校正。

基于此，本章将透视变换技术应用于图像矫正，同时选取合适的变换参考点以确定变换参数。针对椭圆和圆形印章图像参考点不易选取的问题，提出了一种简单有效的外接框构造方法。利用最小外接框模拟印章的边框，将问题转化为一个矩形或正方形图像的矫正，从而可将透视变换技术推广到椭圆形和圆形等其它形制图像的矫正处理，同时采用改进的 BM3D 滤波算法以降低噪声的影响。经实验表明，该算法不受印章形状约束，对需要矫正的各类印章能自动扶正，为后续研究印章鉴伪和识别处理提供了良好的基础。

# 3.2  基于改进的 BM3D 去噪算法

# 3.2.1  印章图像的预处理

受噪声或背景遮挡等因素影响，提取到的印章图像效果通常并不理想，由此造成的图像特征模糊等问题将给后续图像姿态识别和矫正处理带来不利影响。BM3D 算法（Block-matching and 3D filtering，3 维块匹配滤波）是图像与视频去噪领域效果较好的算法之一,它结合空间域思想和转换变换的方法来提升图像效果。为了进一步提升滤波的性能，文[42]提出在算法的最终阶段采用 K-means 聚类方法寻找匹配块从而得到去噪图像。此外，之于 BM3D 算法而言，通过基础估计已然可以较好的实现对含噪原图中噪声的去除，很明显，基础估计阶段的滤波性能对于算法的整体性能有着较大影响。为此，本文提出一种改进的

BM3D 权值聚合算法。如图 3.1 所示，原始 BM3D 算法通过硬阈值生成后的权重矩阵，去噪效果会受经验设置的硬阈值大小影响，同时生成的权重矩阵也会增大后续的匹配度。因此，与上述算法不同的是，改进后的 BM3D 算法在进行基础估计时，借助 K 均值聚类在参考块的邻域内搜索匹配块，利用生成的权重矩阵可以提高模块间的匹配度，缩短匹配的时间，一定程度上提高后续聚合的准确度。

![](images/6835c285429910b7cdf55213258864dc8071362c8e660da99ddc6e4a8052cf22.jpg)  
图 3.1  基于改进 K 均值聚类的 BM3D 去噪算法示意图

改进后的 BM3D 算法计算流程与原始 BM3D 算法基本相同。主要差别在于基础估计阶段硬阈值后加了一步聚类操作，本节通过 K-means 聚类算法[43]实现权重聚类，其主要步骤如下：

步骤 1：随机选取 $\sqrt { { \mathrm n } / 2 }$ 个硬阈值输出后的权重矩阵样本点作为每个类的中心；

步骤 2：计算样本点与每个类中心的相似度大小，本文采用余弦相似度作为度量指标，选取相似度最大的样本点分到对应的类别中；

步骤 3：根据现有的权重矩阵样本点，重新计算每个类的类中心；

步骤 4：重复步骤 1-步骤 4，直到目标函数收敛，即类中心不再发生变化，其中U，Z 分别代表每个类以及每个类对应的中心点，目标函数为：

$$
P ( U , Z ) = \sum _ { p = 1 } ^ { k } \sum _ { i = 1 } ^ { n } u _ { i p } \sum _ { j = 1 } ^ { m } ( x _ { i j } - z _ { p j } ) ^ { 2 }
$$

上式服从于约束条件：

$$
\sum _ { p = 1 } ^ { k } u _ { i p } = 1
$$

对 $z _ { p j }$ 求导可得：

$$
\frac { \partial ( U , Z ) } { \partial z _ { p j } } = - 2 \sum _ { i = 2 } ^ { n } u _ { i p } \left( x _ { i j } - z _ { p j } \right)
$$

进一步地，令（3.3）式等于0，可得到类中心矩阵的计算式：

$$
z _ { p j } = \frac { \displaystyle \sum _ { i = 1 } ^ { n } u _ { i p } x _ { i j } } { \displaystyle \sum _ { i = 1 } ^ { n } u _ { i p } }
$$

通过计算每个样本点和中心点之间的差值，再将其归类到距离最小的类中：

$$
u _ { i p } = \left\{ \begin{array} { l l } { 1 , \displaystyle \sum _ { j = 1 } ^ { m } ( x _ { i j } - z _ { p j } ) ^ { 2 } \leq \displaystyle \sum _ { j = 1 } ^ { m } ( x _ { i j } - z _ { t j } ) ^ { 2 } , f o r ~ 1 \leq t \leq k } \\ { 0 , o t h e r w i s e } \end{array} \right.
$$

# 3.2.2  算法去噪效果

为了验证图像的去噪效果，实验选取了大小均为 $2 5 6 ^ { * } 2 5 6$ 的 3 幅不同形制的印章图像以及 $5 1 2 ^ { * } 5 1 2$ 的基础测试图像 Lena 作为测试对象，测试了高斯噪声标准差为 $\sigma { = } 1 5$ 的情况下，并通过峰值信噪比(PSNR)指标比较和评价算法的有效性。表格3.1 和表格 3.2 给出了本文方法和原始 BM3D 算法关于 PSNR 指标以及去噪时间的实验比较结果。

表 3.1 去噪算法的 PSNR 值对比 $( \sigma { = } 1 5 )$ .  

<html><body><table><tr><td></td><td>BM3D</td><td>本文方法</td></tr><tr><td>圆形印章</td><td>27.48</td><td>28.261</td></tr><tr><td>椭圆印章</td><td>26.82</td><td>27.60↑</td></tr><tr><td>矩形印章</td><td>34.52</td><td>33.67↓</td></tr><tr><td>Lena 图像</td><td>23.60</td><td>24.77↑</td></tr></table></body></html>

PSNR 是一种衡量图像质量的指标，一般认为该指标值在 30 到 40dB 范围内，则表示滤波后图像质量是较理想的；当该值低于20dB 时，图像质量则不可接受。如表3.1 所示，对于圆形和椭圆印章，在噪声作用下，本文算法的峰值信噪比相较传统BM3D算法而言,均有小幅度的提高。对于矩形印章，虽然本文方法对应的 PSNR 值略有下降，但该值仍处于一个较理想的区间。对于基础测试图像Lena，PSNR值也有所上升，同时本文算法对图像的还原度也更高，人眼视觉效果也更好。上述实验结果初步验证了本文所提方法具有良好的去噪性能。

表3.2  去噪算法的时间对比 $\scriptstyle ( { \mathrm { t } } = { \mathrm { s } } )$   

<html><body><table><tr><td></td><td>BM3D</td><td>本文方法</td></tr><tr><td>圆形印章</td><td>147s</td><td>139s↓</td></tr><tr><td>椭圆印章</td><td>242s</td><td>238s↓</td></tr><tr><td>矩形印章</td><td>343s</td><td>322s↓</td></tr><tr><td>Lena 图像</td><td>557s</td><td>555s↓</td></tr></table></body></html>

同时，由表 3.2 可以看出，三种形制的印章图像以及 Lena 图像相比原先的算法，在Step1 阶段的去噪时间上均有一定程度的提高，由此可以看出本文算法相比原始BM3D 算法具有一定优越性。

![](images/912edaf07004aeeac0fa0e1c03039f14ff43f3f606fd05c1af3d454ffd05d926.jpg)  
图 $3 . 2 ~ \sigma { = } 1 5$ 时本文与 BM3D 算法去噪效果对比

最后，图 3.2 可以看出，当 $\sigma { = } 1 5$ 时本文算法相比原始 BM3D 算法，处理效果更好，对信息的还原度更高。

![](images/ea9f8a756bb1b1fc27bddf8516c31c3dd287e680aabd041d65485375fb9277a9.jpg)  
图 $3 . 3 ~ \sigma { = } 1 5$ 时本文与 BM3D 算法去噪效果对比(基础测试图片 Lena)

用基础测试图片 Lena 测试时，原始 BM3D 算法还会出现一定的模糊和失真，而本文算法相比原始算法，能更好的保留原始信息。

# 3.3  印章图像姿态矫正

# 3.3.1  姿态畸变程度的判断

对于去噪后的印章图像，经二值化处理后，对其进行轮廓检测，并生成印章轮廓的最小外接矩形旋转框。如图3.4 所示，通过两中垂线的交点以及过交点的四条线段长度，结合印章的形制以及印章的姿态和旋转角度，可以判定印章是否发生了畸变。

![](images/dae009c8b5015edbda4bf18632feed0176b965abbec7efdda57d284c14e3e0a2.jpg)  
图 3.4 圆形和椭圆形印章畸变判断原理图

根据图3.4所示，各个中心点两两相连求得两直线的交点即为该圆形或椭圆印章的重心，首先已知直线方程为 $F ( x , y ) = a x + b y + c = 0$ ,并设条直线上的两个点为 $P _ { 0 } \left( x _ { 0 } , y _ { 0 } \right) , P _ { 1 } \left( x _ { 1 } , y _ { 1 } \right)$ ,可以得到 $a = y _ { 0 } - y _ { 1 } , b = x _ { 1 } - x _ { 0 } , c = x _ { 0 } y _ { 1 } - x _ { 1 } y _ { 0 }$ ，代入直线方程可得， $F _ { 0 } \left( x , y \right) = a _ { 0 } x + b _ { 0 } y + c _ { 0 } = 0$ ,同理可得，另一条直线方程可表示为 $F _ { 1 } ( x , y ) = a _ { 1 } x + b _ { 1 } y + c _ { 1 } = 0$ ，两方程联立求解可得 $D = a _ { 0 } b _ { 1 } - a _ { 1 } b _ { 0 }$ ，当D为0时，两直线平行；否则 $x = \left( b _ { 0 } c _ { 1 } - b _ { 1 } c _ { 0 } \right) / D , y = \left( a _ { 1 } c _ { 0 } - a _ { 0 } c _ { 1 } \right) / D , \left( x , y \right)$ 为所求重心，确定图像的重心点O，并计算 $a _ { 1 } b _ { 1 } \setminus \ c _ { 1 } d _ { 1 }$ 和 $a _ { 2 } b _ { 2 }$ 的长度。对于理想的圆形印章，长度 $a _ { 2 } b _ { 2 }$ 和 $c _ { 1 } d _ { 1 }$ 的比值应为1。椭圆印章主要用于发票以及公司法人印章，根据规定[44]，其长短轴比例有严格限制，分别是1.33和1.5；对于圆形和椭圆形印章，通过测量上述参数的比值并对比标准值，即可判别印章姿态畸变的程度。对于矩形印章，直接对四个直角边的角度进行判定即可知姿态是否正确。

# 3.3.2  姿态矫正

Hough 变换[45]常用于图像倾斜矫正，但当图像畸变程度较严重时，直接采用霍夫变换法处理的效果并不理想。为此，文[46]提出了一种结合透视变换技术的改进Hough 变换图像矫正方法。

将原图像中像素坐标 $( \boldsymbol { x } _ { 0 } , \boldsymbol { y } _ { 0 } )$ ，以及经透视变换后对应的三维空间坐标$( X , Y , Z )$ 之间的映射关系用下式表示：

$$
{ \left[ \begin{array} { l } { X } \\ { Y } \\ { Z } \end{array} \right] } = { \left[ \begin{array} { l l l } { a } & { b } & { c } \\ { d } & { e } & { f } \\ { l } & { m } & { 1 } \end{array} \right] } { \left[ \begin{array} { l } { x _ { 0 } } \\ { y _ { 0 } } \\ { 1 } \end{array} \right] }
$$

上式中， $( a b c d e f l m )$ 为透视变换参数。若将三维的 $Z$ 坐标分量表示为1，则（3.6）式可化为如下等价形式：

$$
\left\{ \begin{array} { l l } { \displaystyle x ^ { \prime } = \frac { X } { Z } = \frac { a x _ { 0 } + b y _ { 0 } + c } { l x _ { 0 } + m y _ { 0 } + 1 } } \\ { \displaystyle y ^ { \prime } = \frac { Y } { Z } = \frac { d x _ { 0 } + e y _ { 0 } + f } { l x _ { 0 } + m y _ { 0 } + 1 } } \\ { \displaystyle z ^ { \prime } = 1 } \end{array} \right.
$$

为了确定上式中的透视变换参数，对于矩形印章，通常将矩形的四个顶点设置成参考点，选取四个顶点变换前后的坐标，建立关于（3.7）式中 $( \mathbf { \boldsymbol { x } } _ { 0 } , \mathbf { \boldsymbol { y } } _ { 0 } )$ 变换前与 $( x ^ { \prime } , y ^ { \prime } , z ^ { \prime } )$ 变换之后图像像素点坐标的等式关系，进而求出其透视变换参数。

显然，上述方法不能直接应用于椭圆形和圆形印章。为此，借助印章轮廓的最小外接框可以较好地解决这一问题。如图3.5 所示，首先，查找封闭轮廓并排除轮廓大小不符合要求的，接着以圆和椭圆形制印章外轮廓为基准，作出外接框，并确定其顶点位置坐标。利用所作外接框，可将上述问题转化为一个矩形或正方形图像的矫正。从而将透视变换技术推广到椭圆形和圆形等其它形制图像的畸变矫正处理。

![](images/9848b037f414ecf2505d2d7c0afed6ec0b267a73d972a6bab30d06503904dd1d.jpg)  
图3.5 透视变换参考点的构造

# 3.3.3  外接框定位

构造出透视变换参考点以后，需要对各类印章进行识别定位，在实际票据或者文件中，可能会出现多个印章轮廓或者干扰轮廓。首先需要对印章图像进行轮廓检测和定位，定义一个轮廓集合并且找到图像中所有轮廓集合；接着对这些轮廓集合进行由大到小排序，初始化 pixelsPerMetric 的值，这里这里的pixelsPerMetric 定义为 pixelpermetric $\ c =$ object_width / know_width，美国四分之一的 know_width 为 0.955 英寸，现在，假设 object_width（以像素为单位）为 100像素宽（基于其关联的边界框），因此，pixelspermetric 表示为：pixelpermetric $\mathbf { \Sigma } =$ $1 0 0 \mathrm { p x } / 0 . 9 5 5 \mathrm { i n } = 1 0 4 \mathrm { p x }$ ，这意味着图像中每 0.955 英寸大约有 104 个像素，使用这个比率，可以计算图像中对象的大小。计算对象大小后逐个筛选，然后求得旋转边接矩形框四个顶点坐标并按照左上，右上，右下，左下顺序排序，通过求得的顶点坐标计算一系列中点，此时求得的中点为外接矩形框四条边的中心点。如下图 3.6 所示为实际定位框出的印章图像。

![](images/40c0323728a9c5b0bdff1a6eef5371a3358bdf7f63229593f677670086fb8a36.jpg)  
图3.6 外接框定位的印章图像

# 3.4  实验结果与分析

本文首先选用长短轴比为 1.33 的标准椭圆印章，该椭圆印章以发票印章为例，按照国家标准尺寸为 $4 0 ^ { * } 3 0 \mathrm { m m }$ ，圆边宽为 $1 \mathrm { m m }$ ，单位或企业名称，自左而右环形，发票专用章名称放下面，自左而右横排。同时设计了三种场景对算法进行了测试，分别为：（1）拍摄时相机俯仰角度保持为 0，仅调整拍摄的水平角度，即所得测试印章图像在水平面内发生倾斜畸变。（2）拍摄时仅改变相机的俯仰角度，此时，所得测试印章图像在竖直平面内发生倾斜畸变。（3）拍摄时相机俯仰角和水平角均做变化。对于每种拍摄场景，分别做了 10 组测试，结果如表3.3 所示。

表 3.3 本文矫正算法的测试结果  

<html><body><table><tr><td rowspan="2">样 本 组 1</td><td colspan="2">拍摄水平角和俯仰角均 变化</td><td colspan="2">拍摄水平角变化</td><td colspan="2">拍摄俯仰角变化</td></tr><tr><td>（水平角， 俯仰角）</td><td>矫正后 倾斜角</td><td>（水平角， 俯仰角）</td><td>矫正后 倾斜角</td><td>（水平角， 俯仰角)</td><td>矫正后 长短轴比</td></tr><tr><td>2 3 4 5 6 7</td><td>(14°，10°) (32°， 15°) (48°, 12°) (60°， 10°) (75°, 12°) (90°， 21) (108°, 31° (121°, 25°</td><td>1° 1° 0° 1° 0° -9° -8° -5° 40) -9°</td><td>(15°，0°) (30°， 0° (45°， 0°） (60°， 0） (75°， 0° (90°, 0° (105°, 0°) (120°, 0°） (135°, 0 (150°, 0</td><td>0° 4° -2° 0.33° -30 0° -1° 3° 1° 2°</td><td>(0°，5°) (0°， 10° (0°， 15° (0°， 20° (0°， 25 (0°， 30°) (0°， 35° (0°， 40°) (0°， 45°) (0°， 50)</td><td>1.33 1.33 1.35 1.36 1.38 1.36 1.39 1.41</td></tr></table></body></html>

对比表3.3 中矫正前后的倾斜角以及长短轴比可知，当拍摄的俯仰角或水平角大于 90 度时，图像的矫正误差值会出现一定的波动。在角度小于 90 度时，矫正结果是令人满意的。另外，仅当发生水平面内畸变或竖直平面内畸变时，图像的矫正效果总体上要优于两者畸变同时发生的情况，这说明原本文方法的矫正效果在一定程度上也将受限于原图像的畸变程度。但总体来说，当由于拍摄姿态变化引起图像畸变时，采用本文的矫正方法可以较好的还原和保留原有图像的特征。

![](images/29fe0e0d3007c621d5e9b729346f300b01ac1dcc623850c20150a27876db2c9c.jpg)  
图3.7 不同印章矫正结果标准差对比  
图 3.8 圆、椭圆以及矩形印章畸变矫正的可视化示意图

如图 3.7 所示，本文分别统计了在场景三下对三种形制印章图像矫正的方差结果。由图可知，对于圆形印章和矩形印章，测试结果的方差趋于 0，说明本文方法在矫正此类印章图像时具有强稳定性。相比之下，在矫正椭圆形印章时，则呈现了一定的性能波动。进一步地，图3.8 分别展示了不同场景下，圆、椭圆以及矩形三种形制印章图像畸变矫正的可视化结果。从上至下，拍摄条件为：水平角和俯仰角同时变化。

天学测武 认做 学测 W  
潭 酒电子信息有 根资信  
8196189012345 123456789012345678  
54567890123 测试专用章1234567890123  
湘潭大学 湘潭大学  
测试用章 测试用章

结合上述测试结果可知，由于本文采用生成的最小外接框来模拟真实的矩形图像，两者之间产生的定位偏移是引起矫正误差的重要因素之一。对于圆形印章，由于其形制特殊，当图像发生畸变时，生成的外接框仍能好的定位印章位置。而矩形印章在矫正过程中不需要借助生成外接框，因此，本文方法对于上述两者形制的印章均取得了较好的矫正效果。相比之下，对于椭圆形印章而言，当图像畸变较严重时，就必须考虑由于生成外接框位置对矫正结果的影响。

结合表 3.3、图 3.8 的部分效果图来分析，对椭圆印章来说，矫正效果有一定影响，这主要由方法本身所限制，外接框不能准确定位印章的畸变位置，因此会造成一定程度的误差，但总体上影响不大。后续考虑结合 IoU[47]进行迭代矫正。对于圆形印章来说，不管是形变还是角度畸变，外接框的方法都能很好的定位印章位置。矩形印章本身就是一个外接框，因此能准确矫正。

# 3.5 本章小结

本节提出了一种多形制的印章姿态矫正算法，在印章提取阶段通过基于改进的 BM3D 权值聚合算法对印章图像进行去噪处理，有效减少背景信息的干扰，对于常见的高斯噪声以及背景干扰的噪声有明显的抑制作用，同时加入 K 均值聚类后，该算法相比之前去噪时间明显缩短。在矫正阶段采用透视变换技术的图像矫正方法，利用最小外接框模拟印章的边框[48]，然后选取模拟边框的顶点作为变换参考点以确定变换参数，该方法对于矩形印章可以很好的进行矫正，对于圆形和椭圆印章，当其发生畸变时，也不仅仅局限于二维平面的矫正，最后的实验结果也表明本文方法能较好的还原印章的姿态。在下一阶段，将重点研究当图像畸变较严重时，如何提高生成外接框定位精度，以进一步提升算法的矫正效果问题。

# 第4 章  基于注意力机制的孪生网络印章鉴伪算法

# 4.1  引言

第 3 章提出了基于透视变换的多形制印章姿态矫正算法。该算法首先对待提取印章做了预处理，接着对因背景干扰或噪声污染的印章图片做了去噪处理，最后，当印章发生畸变时，运用透视变换的方法，引入外接框对印章做了矫正操作，以便后续鉴伪工作的顺利进行。本节的主要研究内容在于通过印章在金融行业和司法行业的应用和地位，借助当前深度学习的方法，辅助或替代人工对印章图像进行真伪鉴别，大大提高了印章鉴定的准确度。基于此，研究工作对象主要是通过第三章矫正后的印章样本以及印章生成软件生成的标准印章数据集，以高仿真光敏印章为例，当前印章鉴伪过程中存在的一个突破口就是印鉴图文布局特征易与真实印文出现差异，例如：印章图案的位置，角度和大小。因此，本文结合真假印鉴的差异，制作了印章数据集，通过孪生网络算法解决了因样本少导致训练不佳的问题，并替换了当下的主流特征提取网络同时结合注意力机制更好的提取特征，相比传统的印章图像处理方法，适用面广，前景广阔，大大提高了验伪效率和准确度。

总的来说，本章的主要贡献如下：

（1）自制了印章数据集，并引入迁移学习解决了因样本不足导致训练不佳的问题。（2）引入了注意力机制，加强了网络对细微特征的提取能力，使输出的相似度差值更贴近真实值。（3）为验证不同网络模型的特征提取能力，搭建了基于不同backbone的孪生神经网络。

# 4.2  融合注意力机制的孪生网络印章鉴伪算法

融合注意力机制的孪生网络印章鉴伪算法具体步骤如下:

（1）导入预处理后的印章图像并将其作为训练数据集；（2）搭建基于不同 backbone 的孪生神经网络，包括 vgg16、mobilenet、  
resnet50；（3）在模型中引入代表性的注意力机制，分别比对并且输出相似度对比结  
果；（4）按照平均相似度比对结果作为最终的评价指标判别模型的优劣；

（5）输出最优模型结果同时判别印章真伪。融合注意力机制的孪生网络印章鉴伪算法流程图如图 4.1 所示。

![](images/57ddee8acab22cb1b6f95c258054dedd5264af79905aec5afcde5827a75f00f1.jpg)  
图 4.1  融合注意力机制的孪生网络印章鉴伪算法流程图

# 4.3  主干网络模型

在第二节中，详细阐述了卷积神经网络的原理，接下来介绍本节中使用的一些具有代表性的网络结构(VggNet,MobileNet,ResNet)，这些代表性的结构在本节中发挥了举足轻重的作用，故而首先对这三种模型进行介绍。

# 4.3.1  VGGNet 网络

VGGNet[49]于 2014 年牛津大学提出，并于同年的 ILSVRC 比赛在 Top-5 中取得 $92 . 3 \%$ 的准确率。一般常用的网络深度为VGG16和VGG19，后续被广泛用于计算机视觉任务中的特征提取部分，本文所用的网络结构为 VGG16，故而主要对其进行介绍，如下图 4.2 所示为VGG16 的网络架构图。

![](images/c0cdc53bbfaab2fdd072669a7fc3d87061873f7056c4d99cb6750497e9ebb158.jpg)  
图 4.2  VGG16 的网络架构图

如上图4.2 所示，VGG16 网络的主体结构由5 个卷积块，每两层中间存在的步长为 2 的池化矩阵，三个全连接层以及最后的 soft-max 层组成。其中卷积层和池化操作主要是对图像进行特征提取以及降维，全连接层将数据平拉成向量以方便最后soft-max 输出分类结果。

表 4.1  VGG16 网络层级图  

<html><body><table><tr><td>卷积层名称</td><td>模型配置</td><td>输出特征图大小</td></tr><tr><td>输入层</td><td></td><td>256× 256×3</td></tr><tr><td>Convl-2</td><td>3×3/1</td><td>256× 256× 64</td></tr><tr><td>max pool</td><td>2×2/2</td><td>128×128×64</td></tr><tr><td>Conv3-4</td><td>3×3/1</td><td>128×128×128</td></tr><tr><td>max pool</td><td>2×2/2</td><td>64×64×128</td></tr><tr><td>Conv5-7</td><td>3×3/1</td><td>64× 64× 256</td></tr><tr><td>max pool</td><td>2×2/2</td><td>32×32×256</td></tr><tr><td>Conv8 -10</td><td>3×3/1</td><td>32×32×512</td></tr><tr><td>max pool</td><td>2×2/2</td><td>16×16×512</td></tr><tr><td>Convl1-13</td><td>3×3/1</td><td>16×16×512</td></tr><tr><td>max pool</td><td>2×2/2</td><td>8×8×512</td></tr><tr><td>FC14-15</td><td>[1x1×4096]×2</td><td></td></tr><tr><td>输出层（soft max）</td><td>1000</td><td>---</td></tr></table></body></html>

如上表 4.1 所示为 VGG16 的网络层级图，由此可以看出其在当时的优越性，无论是卷积核大小还是网络深度，它的拟合能力都是超前的。但也具有因深度较广而造成参数量大，训练时间较长等问题。

# 4.3.2  MobileNet 网络

MobileNet[50]是 2017 年 Google 针对嵌入式以及手机等设备提出的轻量级网络模型。相比一些传统的 CNN 网络结构其参数量庞大的特点，MobileNet 重点凸显在轻量级上面，主要体现在卷积核上面，其主要采用深度可分离卷积代替原来的标准卷积，这种操作可以有效减少计算量，降低模型的复杂度。经过多年的发展，目前MobileNet系列已经发展了三个版本，本节用到的是最初的版本MobileNet V1，其基本单元为深度可分离卷积(Depthwise Separable Convolution)，具体可分为两种形式：Depthwise Convolution 和 Pointwise Convolution，第一种与标准的卷积不同，标准卷积主要作用在每个输入通道，而 DepthwiseConvolution 卷积面对不同的输入通道时通常采用不同的卷积核；第二种就是普通的采用 $1 { \times } 1$ 大小的卷积核。

首先假定输入图片大小为 $D _ { { \scriptscriptstyle F } } \times D _ { { \scriptscriptstyle F } } \times M$ ,输出特征图大小为 $D _ { \scriptscriptstyle F } \times D _ { \scriptscriptstyle F } \times N$ ，其中 $D _ { { \scriptscriptstyle F } }$ 为特征图的宽和高，同时假定通道数和图片大小一致，对于标准的卷积$D _ { { \scriptscriptstyle K } } \times D _ { { \scriptscriptstyle K } }$ ，其计算量为：

$$
D _ { \kappa } { \times } D _ { \kappa } { \times } M { \times } N { \times } D _ { \kappa } { \times } D _ { \cal F }
$$

而 Depthwise Separable Convolution 计算量等于 Depthwise Convolution 与Pointwise Convolution 之和：

$$
D _ { K } \times D _ { K } \times M \times D _ { F } \times D _ { F } + M \times N \times D _ { F } \times D _ { F }
$$

两者计算量之比为：

$$
\frac { D _ { \scriptscriptstyle K } \times D _ { \scriptscriptstyle K } \times M \times D _ { \scriptscriptstyle F } \times D _ { \scriptscriptstyle F } + M \times N \times D _ { \scriptscriptstyle F } \times D _ { \scriptscriptstyle F } } { D _ { \scriptscriptstyle K } \times D _ { \scriptscriptstyle K } \times M \times N \times D _ { \scriptscriptstyle F } \times D _ { \scriptscriptstyle F } } = \frac { 1 } { N } + \frac { 1 } { D _ { \scriptscriptstyle K } ^ { 2 } }
$$

由 4.1-4.3 可以看出，若都采用 $3 { \times } 3$ 的卷积核，后者计算量可以降低 9 倍。在其应用中会加入 Batch Norm 正则化以提高模型的泛化能力，并且使用 ReLU激活函数。如下图 4.3 所示为 Depthwise Separable Convolution 基本结构示意图。

![](images/a17c2d1d25d44ea579f61b92b41cdd2263e3808b9844b624b0701ceb7c49f581.jpg)  
图 4.3  深度可分离卷积结构图

如上图可知，深度可分离卷积相比普通卷积，实际上就是将一层的卷积分为两步来做，同时 BN 和 ReLU 激活层也要做两次。其网络结构与 VGG 类似，都是一条主线，如下表 4.2 所示为MobileNetV1 网络层级图。

表 4.2  MobileNetV1 网络层级图  

<html><body><table><tr><td>卷积类型/步长</td><td>模型配置</td><td>输入特征图大小</td></tr><tr><td>Conv / s2</td><td>3x3×3×32</td><td>256×256×3</td></tr><tr><td>Conv dw / s1</td><td>3×3×32 dw</td><td>128×128×32</td></tr><tr><td>Conv / s1</td><td>1x1x32×64</td><td>128×128×32</td></tr><tr><td>Conv dw / s2</td><td>3x3×64 dw</td><td>128×128×64</td></tr><tr><td>Conv / s1</td><td>1x1×64×128</td><td>64× 64×64</td></tr><tr><td>Conv dw / s1</td><td>3x3x128 dw</td><td>64×64×128</td></tr><tr><td>Conv / s1</td><td>1x1x128×128</td><td>64×64×128</td></tr><tr><td>Conv dw / s2</td><td>3x3x128 dw</td><td>64× 64×128</td></tr><tr><td>Conv / s1</td><td>1x1×128×256</td><td>32×32x128</td></tr><tr><td>Conv dw / s1</td><td>3×3×256 dw</td><td>32×32×256</td></tr><tr><td>Conv / s1</td><td>1x1× 256×256</td><td>32×32×256</td></tr><tr><td>Conv dw / s2</td><td>3×3× 256 dw</td><td>32×32×256</td></tr><tr><td>Conv / s1</td><td>1x1× 256×512</td><td>16×16× 256</td></tr><tr><td>Conv dw / s1 5x</td><td>3×3×512 dw</td><td>16×16×512</td></tr><tr><td>[Conv / s1</td><td>1x1×512×512</td><td>16×16×512</td></tr><tr><td>Conv dw / s2</td><td>3x3×512 dw</td><td>16×16×512</td></tr><tr><td>Conv / s1</td><td>1x1×512×1024</td><td>8×8×512</td></tr><tr><td>Conv dw / s2</td><td>3x3×1024 dw</td><td>8×8×1024</td></tr><tr><td>Conv / s1</td><td>1x1×1024×1024</td><td>8x8×1024</td></tr><tr><td>Avg Pool/s1</td><td>Pool 7×7</td><td>8×8×1024</td></tr><tr><td>FC/s1</td><td>1024×1000</td><td>1×1×1024</td></tr><tr><td>Softmax/s1</td><td>Classifier</td><td>1x1x10O0</td></tr></table></body></html>

MobileNetV1 一共有28 层，虽然层数上相比VGG16 大幅增加，但是参数减少了30 多倍，准确率也只低了 $0 . 9 \%$ ，足以见其强大。同时MobileNetV1 还分别设置了宽度超参数和分辨率超参数，用来平衡准确率和延时性。

# 4.3.3 ECA-ResNet 网络

ECA-ResNet[51]最早出现于 ECA-Net 论文中，但在本章节中首次被搭建为孪生神经网络的backbone，该网络兼顾了性能和复杂度，融合了网络深度和信息关注度从而更好的提取特征，下面分别对各部分进行介绍。

# （1）ResNet

残差网络(ResNet)[52]是 2015 年由微软公司的何恺明等提出的，并且于同年获得 ILSVRC 的冠军。ResNet 的主要创新是直接解决了模型退化的问题，正是由于其解决了模型退化的问题，之后的网络深度也越来越深，其代表性的有ResNet50，ResNet101，ResNet152 等，而解决该问题的方法就是其在两个网络层级之间加入了一个跳跃连接，随后将信息绕路传到输出，从而保护信息完整，同时也使得整个网络只需要学习有差别的部分，大大简化了训练难度。如下图4.4 所示表示ResNet50 的一个残差学习模块。

![](images/df7d3d34b18a3301027ef7c1f161cbfb9f77a310f38728b160ebece8db2cf175.jpg)  
图 4.4  ResNet 的残差学习模块

如图 4.4 所示可以知道该模块的工作机制，假设网络提取到的特征为 $H ( X )$ ，输入为 $X$ ，则可得到网络的数学表达式为 $H ( X ) = F ( X ) + X$ ，恒等变形可得残差表达式为 $F ( X ) = H ( X ) - X$ 。当网络很深的时候，理想情况下只需要让 $F ( X )$ 等于 0 即可，即网络提取到的特征与输入相等时，表明该层网络达到一个最优的状态，同时有效解决退化问题，但实际情况下，要达到此种情况很困难，所以只需让它无限接近于0，这也是ResNet 设计的巧妙之处。

本文所使用的 ResNet50 网络在其中第三个和第四个 block 后加入了 ECA 模块，其余和原先一样，输入图片大小为 $2 5 6 \times 2 5 6$ ，其网络层次图如下表4.3所示。

表 4.3  ECA-ResNet50 网络层级图  

<html><body><table><tr><td>卷积层名称</td><td colspan="2">模型配置</td><td>输出特征图大小</td></tr><tr><td>Conv1</td><td colspan="3">7×7，64，stride 2 128 ×128 3×3，max pool,stride 2</td></tr><tr><td>Conv2_x</td><td>[1×1，64 3×3, 64 [1×1，256」</td><td>×3</td><td>64 × 64</td></tr><tr><td>Conv3_x</td><td>[1×1，128 3×3，128 [1×1，512] ECA block</td><td>×4</td><td>32 ×32</td></tr><tr><td>Conv4_x</td><td>[1×1，256] 3×3，256 [1×1，1024」 ECA block</td><td>×6</td><td>16×16</td></tr><tr><td>Conv5_x</td><td>「1×1，512 3×3，512 [1×1，2048</td><td>×3 8×8</td><td></td></tr></table></body></html>

average pool,1000_d,fc,soft max

（2）ECA 注意力机制模块

![](images/4d512206c9565fb679399ace39774467112ee8e1ccfa1eb1d4831a45e18ec741.jpg)  
图 4.5  ECA 注意力模块

ECA 注意力机制 实现流程如上图4.5 所示，将特征图经过全局平均池化后变成[1，1， $| C ]$ 的向量，接着通过自适应函数K值用于1D卷积中，得到特征图的每个通道的权值，其中最重要的是自适应卷积核 K 值的大小，它的结果主要由 $\gamma = 2$ $b = 1$ 决定，表达式为 $K = \left| \log _ { 2 } c / \gamma + b / \gamma \right|$ ，最后将 后的权重与输入的特征图进行通道相乘得到输出的特征图。

# 4.4  实验流程与对比分析

# 4.4.1  环境配置

在本节中，将介绍实验所需的细节和软硬件支持。本节所用软件平台为

PyCharm2020.1.5 版本，它是一整套基于 Python 语言的集成开发环境，由JetBrains 打造的一款 Python IDE。选用的训练框架为 torch1.2.0，其能对 GPU 进行训练加速同时支持神经网络动态训练。

硬件实验环境：GPU 为两张 8G 显存的 NVIDIA GTX1080TI，CPU 为Inter(R)Core(R)i5-9300H，内存为 16G。Open CV 库为 3.4.2，Python版本为 3.6，操作系统环境为 Windows10。

# 4.4.2  数据准备

本文采用的数据集为自制数据集，除了生成的真伪印章图像，另外实际采集了一些真实盖印数据占总数的百分之 10，将其随机排列以后放入总的数据集中，同时按照 9：1 的比例划分训练集和测试集，目前印章伪造通常集中在内部文字，图案等具体参数的差异，基于此本节通过印章生成软件，严格按照标准印章规格，生成了模拟现实情况的印章图片，但同时，印章图像通常受到文字等背景遮挡，故而首先对生成的印章样本进行了随机加噪处理，同时对图像图像样本进行数据增强处理，将其进行旋转、偏移等操作，扩展数据集至 110 组，220 类共计 2200 张图像。其中训练集 1980 张，测试集 220 张，部分数据集样本如下图4.6 所示。

PRTT GR 限 ！ 干 华   
FTTE 有限公 女★

根据实际中的印章伪造案例以及参考相关文献，真假印章大多发生在字符间距、字体大小以及中间标志不规范等情况中，故此，本节设置了真假样本的参数并严格按照标准规格生成，具体参数设置如下表 4.4 所示：

表4.4 样本参数设置  

<html><body><table><tr><td>类别</td><td>编码字间距</td><td>环边距</td><td>五角星缩放</td><td>旋转</td><td>汉字字号</td></tr><tr><td>正样本</td><td>10</td><td>3</td><td>0</td><td>0</td><td>24</td></tr><tr><td>负样本</td><td>8</td><td>2</td><td>95</td><td>1</td><td>23</td></tr></table></body></html>

# 4.4.3  模型训练

本章中对模型训练时所用到的一些参数进行了实际上的调优，主要的参数包括 Batch size，Learning rate，Init epoch，Final epoch 等，其主要参数设置如下表 4.5 所示：

表4.5  主要参数设置表  

<html><body><table><tr><td>参数名</td><td>大小/方法</td></tr><tr><td>Batch size</td><td>32</td></tr><tr><td>Init Learning rate</td><td>0.0001</td></tr><tr><td>Final Learning rate</td><td>0.00001</td></tr><tr><td>Init epoch</td><td>100</td></tr><tr><td>Final epoch</td><td>200</td></tr><tr><td>Optimizer</td><td>Adam</td></tr></table></body></html>

如表 4.5 所示，Batch size 表示训练时所选取的批处理大小，即一次训练所选取的样本个数。其大小的设置会直接影响到整个模型的训练速度以及优化的效率，若每次训练都一次性的把整个数据输入网络中，然后计算梯度大小并反向传播，对于大型的数据库来说，很容易造成内存爆炸，而且不同的梯度值之间差别很大，不容易全局收敛，学习率难以确定。故而引入了 Batch size 的概念，本节中实际的设置大小为 32。

Init Learning rate 以及 Final Learning rate 表示初始学习率以及最终学习率，是训练中需要用到的一种重要的超参数，其决定着函数能否收敛以及何时收敛到局部最值。若学习率设置太小，收敛过程会变得及其艰难从而导致速率下降。若学习率设置太大，会导致梯度来回震荡，甚至最终无法收敛。本文根据实际的情况，设置了 Init Learning rate(初始学习率)以及 Final Learning rate(最终学习率)，前 100 个 epoch 时设置为 0.001，后 100 个 epoch 设置为初始学习率的 0.1倍，同时还根据学习率动态调整方法，每经过一个步长，将此前的学习率乘以0.96。

Init epoch 和 Final epoch 表示为初始和最终训练次数，它表示网络完成一次计算和反向传播的过程，一般来说，训练次数越多，网络优化的结果越好。经过多次的尝试发现，前 100 个 epoch 训练还达不到所需的效果，因此设置了 200个 epoch 进行训练。

Optimizer 表示为优化器，其作用是使各个超参数更快更优的更新，从而让目标函数收敛。本文所使用的优化器为 Adaptive Moment Estimation(自适应矩估计)，AdaGrad 算法能够自适应的调节学习率，其主要是利用了一阶矩和二阶矩的惯性保持和环境感知能力，既可以适应不同的目标函数同时为各个参数产生适宜的学习速率。本文所使用的 AdaGrad 优化器一阶和二阶矩的震荡衰减率分别为 0.9 和 0.999。

# 4.4.4  训练结果对比分析

为了验证结果的有效性，本文比较了目前几种主流的特征提取网络，从网络深度，卷积类型进行综合分析，分别训练了 200 个epoch。

![](images/bbb5c505f3f96abf3dbc578ccb1d9f48eb4b864cd7248ae69b3dbd1b100e459b.jpg)

![](images/b6650df855f64d790ac6ecffcbe707ef041e51087ebd82d133311affb0b590f0.jpg)  
图 4.7  各网络结构训练过程 LOSS 曲线图

如上图 4.7 所示为各个网络模型训练时的 LOSS 下降曲线图，由图可知，本文方法的下降曲线最低，若仅以Resnet50作为特征提取网络来训练，LOSS下降最少，同时曲线下降速度也最慢，由此可以看出加入了 ECA 作为注意力机制可有效提取关键信息，防止无关信息冗余堆叠造成训练速度较慢，LOSS 下降相比其它网络较少的情况。Mobilenetv2 采用深度可分离卷积，一定程度上使网络结构更加轻量化，与 Resnet50 正好相反的是，其采用的是先扩张再压缩式的卷积结构，在当前的应用场景中，可能会导致一些细节特征丢失。

![](images/c911fe37de6c7e80faaecb188690bb1089e4dbe88602b6f47dda8fd88a9a4624.jpg)  
图 4.8  各网络结构训练过程 ACC 曲线

图 4.8 表示了上述四个网络结构训练时训练集准确率的曲线图，如图可以看出，VGG-16 和 Mobilenet-V1 准确率只能趋近 0.9，Resnet-50 和本文都能达到相近的准确度，但 Resnet-50 训练时波动较大，容易造成结果出现误差,而本文则更趋于稳定。

为进一步验证训练的有效性，本文对训练后的部分样本数据进行了对比测试，其可视化结果如下图 4.9.1-4.9.4 所示

Similarity:0.011 Similarity:0.354 0 工程项公 公工柱 程项目公限 和田 酒 机 利 酒 福   
150 150 150 150 新   
200 200 200 测试专用维 200 250 0 100 200 0 100 200 100 200 0 100 200

![](images/82e8f0278943bb05963fa006525e3c259194ee8465c7fc5ffd6d9c5540ef21c4.jpg)  
图 4.9.1 Resnet50 测试结果

![](images/67d31a309e9b62f224aedacb8fb5e6b3abdad27bab65da610b9b59e6b500ede0.jpg)  
图 4.9.2  VGGNet 测试结果  
图 4.9.3  Mobilenet 测试结果

本文对比了几种模型测试后印章在不同姿态下的真伪辨别情况，图 4.9.1 到图 4.9.3 分别表示两个真假印章样本在不同网络权重测试以后的结果，每组测试结果左边表示一正一负两个样本，两个样本在字间距、文字大小、中心标志大小上都有一定区别，右边表示两个真实参数样本，参数设置上完全一致只是在位置上发生了偏转，由以上测试结果可以看出，Simaese-VGG 网络和 Simaese-MobileNet 网络的测试结果在计算相似度差异时基本上为零，误差基本上可以忽略，其余网络结构测试结果均有细微的偏差，但不明显。总的来看，几种网络在分辨真伪印章时表现效果都较为良好，但对右边两幅真实样本测试时，各个网络表现的准确率却有较大差别，这可能与各网络关注的有用信息程度有关。

![](images/ad42b6cc1c565649cd031e658d3683d8b5a82a61f8fb3ee999923af15c272e3f.jpg)  
图 4.9.4 本文算法测试结果

由图 4.9.4 可知，本文算法测试两幅正负样本时所得结果与其他网络相比总体虽差别不大，但更重要的是误检率更低。而其余网络相比差异较大。若以Simaese-ResNet 与本文结果对比可知，ECA 注意力机制可使单幅图像提升结果可达 0.6，平均准确率可达 0.28，和其余网络相比，平均准确率也均有较大提升，其中本文的差异性判别间隔最大，效果最好。

![](images/a32bdf206b42eef9b27c1cb0b1315fdc0cf824404975108d4c01c4b6b0064dcd.jpg)  
图4.9.5  像素点方差对比结果

最后，如图 4.9.5 所示，本文对两两正负以及真实印章图像的测试结果做了像素点方差比对，由此可知，两正样本在角度发生改变时，若通过传统图像处理方法做真伪检验时，相比深度学习方法，准确度会有较大的差异。尤其对特定场景下的印章图像而言，深度学习方法不需要考虑印章垂直角度下的印章姿态，而单纯使用传统方法来鉴别所应用的场景也会受到限制。

表 4.6  各网络结构测试集识别准确率和误检率  

<html><body><table><tr><td>网络结构</td><td>识别准确率</td><td>识别误检率</td></tr><tr><td>Siamese vgg</td><td>0.83←</td><td>0.41↓</td></tr><tr><td>Siamese mobilenet</td><td>0.87←</td><td>0.23↓</td></tr><tr><td>Siamese resnet50</td><td>0.82↓</td><td>0.32←</td></tr><tr><td>本文</td><td>0.91 ↑</td><td>0.14 ↑</td></tr></table></body></html>

如表4.6 所示是在对比几种网络结构下，得到的最终的平均准确率结果，由表可知，各网络在鉴别真假印章样本情况下效果差别不大，本文相比其它网络结果略高，对结果影响不大。同时在两真印章样本下的误检率相比 VGG 以及原本的 resnet50 网络都有很大改进，引入的注意力机制在提取相同的特征的基础上效果明显，同时对印章真假判别准确率上也略有提高，由此可以看出，本文的算法结果是更优的。

# 4.4.5  基于迁移学习的算法性能分析

为了充分利用有限的数据样本，解决训练过程中样本不足的问题，本节在训练过程中引入了迁移学习进行介绍。

迁移学习是机器学习方法的一种，通常用于模型的迁移。对于某些复杂场景，从零开始训练一般来说都很困难，样本量相较于一些公开数据集也较少，从而导致模型的泛化能力不理想，因此这时就需要借助迁移学习的思想来解决此类问题。Fine-Tune(微调)属于迁移学习的一种，其实现流程就是利用已训练好的网络模型来微调从而达到预期的一种方法，本文主要采用 Fine-Tune 的方法来对模型进行迁移学习。

在训练过程中，由于数据量相对较少，数据之间的样本相似度较低，需要冻结预训练模型的前 N 层，将冻结的前 N 层用来替换目标模型的前 N 层，再对目标模型进行训练。通过 Fine-Tune 的方法，可以更快的使网络收敛，节约训练时间，对样本量不足的问题也能解决。本文主要通过数据集中极具代表性的ImageNet[54]数据训练以后得到参数和权重来进行迁移学习。

如图 4.9 所示为加入预训练权重以后的各网络 ACC 曲线图，由图可知，通过Fine-Tune 以后得到的效果相比之前准确率都有所上升，网络收敛速度加快。

由下表4.7 可以看出，经迁移学习优化后各网络模型的识别准确率有了一定程度的升高，同时误检率也有所下降，进一步证明了方法的可行性和有效性。

表4.7 经迁移学习优化后的识别准确率和误检率  

<html><body><table><tr><td>网络结构</td><td>识别准确率</td><td>识别误检率</td></tr><tr><td>Siamese vgg</td><td>0.84↓</td><td>0.32←</td></tr><tr><td>Siamese mobilenet</td><td>0.82←</td><td>0.18↓</td></tr><tr><td>Siamese resnet50</td><td>0.88←</td><td>0.24↓</td></tr><tr><td>本文</td><td>0.92 →</td><td>0.11 ↑</td></tr></table></body></html>

![](images/60c93ca1ba1931f85e0b5e482135e77b97a9899565c4a88479d28a26470013f5.jpg)  
图 4.9 迁移学习优化后的ACC 曲线  
如下图 4.10.1 所示为部分样本矫正前的鉴伪可视化结果示意图：  
图 4.10.1  样本矫正前鉴伪可视化结果示意图

# 4.4.6  印章图像矫正对鉴伪性能的比较分析

第3 章对印章图像进行了去噪以及矫正操作，而畸变较大的印章进行姿态还原以后或多或少会影响鉴伪的结果，因此本节主要将自制数据集作为实验样本，将其进行畸变处理后再进行鉴伪以证明本文方法的可行性。

Similarity:0.086 Similarity:0.784 0 0 0 0 50 50 50 50   
100 酒 100 和 酒 100 酒 100 和   
200 南 250 南 150 南 250 城 131313113131 21313131131 131313113131 131313113131   
250 250 250 250 0 100 200 0 100 200 0 100 200 0 100 200 Similarity:0.855 Similarity:0.002 0 0 0 田   
100 源 源 到   
150 红 200 1313131131313 30 1313131131313 250 1111311 100 0 100 0 100 200 0 100 200

如上图所示，对比图 4.10.2 的测试结果可以得到，矫正后印章图像不仅在真伪鉴别上准确率相比矫正前的结果有所提高，同时对于右边两幅真实样本的鉴别误检率也降低了。由此可见，矫正这一步骤对于畸变印章的印章鉴伪是必不可少的。

本文收集了 20 组矫正前后的不同印章图像，将这些印章分别进行鉴伪测试，由表4.8 中可以看出，矫正后的印章鉴别准确率以及误检率都有较大提升。

表 4.8 矫正前后的印章鉴别准确率和误检率  

<html><body><table><tr><td>是否进行印章矫正操作</td><td>识别准确率</td><td>识别误检率</td></tr><tr><td>矫正前</td><td>0.72 ←</td><td>0.42 ↑</td></tr><tr><td>矫正后</td><td>0.87 ↑</td><td>0.18↓</td></tr></table></body></html>

# 4.5  本章小结

针对印章鉴伪中遇到的数据不足以及准确率和误检率的问题，本章提出了一种基于注意力机制的孪生网络印章鉴伪算法，该算法首先通过数据增强的方法对自制的印章数据集进行了扩充，并采用迁移学习的方法进行了训练，解决了样本不足的问题，同时也加快了网络的收敛速度，然后通过ECA-ResNet 网络，进一步提高了网络提取细节特征的能力，最后将几种网络训练以后得到的权重对验证集做了测试对比。得出以下结论：

（1）各孪生网络对印章特征信息的提取能力总体来说相差不大，相较于原本的ResNet 网络，加入了注意力机制的网络，准确率更高，误检率更低。（2）使用了迁移训练以后，对各网络模型的收敛能力都有一定程度的加强，同时可以有效节约训练时间。（3）针对矫正前后因特征丢失或改变的印章图像，虽然总体准确率降低，但仅考虑矫正前后的印章鉴伪准确率可知，矫正这一步骤对于特定情况下的畸变印章图像来说还是有必要的。

# 第5 章  总结与展望

# 5.1  总结

对于当下印章识别技术在金融行业的应用广泛，本文从印章提取、畸变矫正、到最后的鉴伪等几个方面展开了深入的研究。研究对象是处于复杂背景下的各类印章图案，研究目的是实现各类印章的去噪、矫正操作，同时对圆形印章因字体大小、字符间距、印章边框缺损、或因盖印力度和拍摄角度等情况产生的干扰印章图像进行准确的鉴伪和识别。最后在实验测试环节，本文采用 9比 1 的比例模拟实际样本拍摄采集后的印章图像制作了圆形印章数据集，取得了较佳的效果，由此证明了本文方法的可行性和适用性。

下面对全文中的研究内容进行总结，主要如下：

（1）介绍了传统图像处理相关的基础理论知识。首先对印章图像进行了色彩分割和轮廓检测，接着对印章图案进行了初步提取，针对印章图像在盖印时出现的盖印不均导致印章图像出现色彩不均的问题，采用灰度均衡化的方法对印章图像进行均衡。接着介绍了改进的 BM3D 算法基本原理和公式，最后介绍了用于印章图像轮廓定位的 Canny 边缘检测算法。

（2）针对当前印章提取过程中遇到的噪声以及畸变问题，本文对不同形制的印章图像畸变矫正以及常见的噪声污染分别给出了解决方案。当印章因背景遮挡以及提取时造成印章图像出现噪声时，通过改进的 BM3D 去噪算法对印章图像进行去噪；当拍摄时角度变化造成印章图像出现畸变时，采用透视变换的方式同时结合外接框的方法对印章图像进行矫正。本文分别对圆形、矩形、椭圆以及基础图像 Lena 进行了去噪测试，对比原始方法，不仅去噪时间缩短，去噪效果也有较大改善。另外本文创造性的引入了外接框的方式，对 10 组椭圆印章图像进行畸变矫正，矫正后的标准差也稳定在可控范围内。

（3）针对使用的数据集来源不足问题，本文按照严格的印章规格在网站自制了印章样本数据集以及经第三章去噪、矫正处理后的印章样本共计 2200 张图像。接着介绍了印章鉴伪的现状以及本文中鉴伪算法的实现流程。接着介绍了本文使用的 VGGNet、MobileNet 以及加入了注意力机制的 ECA-ResNet 三种典型网络结构，并且分别进行了训练和测试，最后经训练测试以后的结果可知ECA-ResNet 为最佳。最后为进一步优化缩短模型的收敛速度，引入了基于迁移学习的方法对各个网络进行了优化。最后结果表明，经迁移学习优化后的网络，识别效率进一步提高。

# 5.2  展望

本文针对印章提取识别到鉴伪整个流程展开研究，从传统图像处理角度引入到深度学习层面，丰富了整个印章识别的检验流程和方法，通过实际采集的数据集以及自制数据进行测试，验证了方法的可行性和适用性。但值得注意的是，本文所提的方法还有一些需要进行完善的地方。主要有以下几点：

（1）第 2 章中对印章图像因盖印条件的不同导致的差异性影响提出了解决办法，但是提取到的印章图像不止会受到盖印压力、角度等因素影响，例如同样的印章盖印在不同的纸张上，有的施胶量少的纸张容易渗出导致印章图像周围出现毛刺或者色彩重叠，这些问题的出现都会加大后续印章图像的识别。因此，如何探讨在多种不利因素加重的情况下，准确提取识别印章是后续需要研究的重点。

（2）第 3 章中在对多形制印章做畸变矫正时，虽然对于矩形以及圆形印章都能借助外接框的方法很好的矫正，但是对于椭圆形印章图像，当印章图像畸变较大时，直接采用透视变换的方法进行矫正也会出现一定的误差，因此，下一步如何结合 IoU 的方法同时对矫正图像进行算法迭代进而准确无误的矫正椭圆印章也是一个研究方向。

（3）第 4 章中使用的印章数据集仅仅针对印章常见的字符间距，字体大小边框缺损以及印章中间五角星标志大小等情况做出了鉴伪，而在现实情况中，例如经常出现在古文书画中的印章，此类印章字体可能出现大篆、小篆、方篆还包括隶书、行草书等字体文字[55]。这些字体间的结构差别较大，如何针对不同的字体特点设计适宜的网络来训练也是值得研究的方向。

# 参考文献

[1] 许爱东.印章印文鉴定理论与实务研究[M].北京:法律出版社,2015:2.   
[2] 王闯.根据印文特征分析印章的材质与制作方法[J].警学研究,2014(04):70-73.   
[3] 梁斯琪.解析印章识别对书画鉴定的作用[J].文物鉴定与鉴赏,2021(23):96-98.   
[4] 解华,赵震刚.人防技防相得益‘章’[N].中国城乡金融报,2019-12-13(A04).   
[5] 刘建华,戌志仙.掀起伪造印章的面纱来[J].贵州警官职业学院学报,2007(3):91-93.   
[6] 杨进友,吕梦婷.光敏印章印文盖印变化研究[J].中国司法鉴定,2017(06):68-74.   
[7] Ueda K. Automatic Seal Imprint Verification System with Imprint Quality Assessment Functi on and Its Performance Evaluation.IE-ICE Transactions on Information and Systems[J]. Fourt eenth International Conference on Pattern Recognition .1994,08:885-894.   
[8] Fan, Ting-Jun and Wen-Hsiang Tsai. Automatic Chinese seal identification[J].Comput. Vis. G raph. Image Process. 25 (1984): 311-330.   
[9] Chang, Shih-Hsu et al. Automatic seal identification by using point matching and fake detecti on[J]. Pattern Recognit. Lett. 20 (1999): 1545-1552.   
[10] 胡庆,杨静宇.基于知识的印鉴鉴别方法[J].自动化学报,1991,17(6):696-703.   
[11] 姚敏,牟雪儿,陈鹏等.图像中印章的检测定位与识别研究[J].信息技术与信息 化,2018(12):148-150.   
[12] 张巍.印鉴矫正系统的设计与实现[D].吉林:吉林大学,2016.   
[13] Liang, Ji Sheng et al. The Circular Seal Identification Method Based on Average Relative Err or[C]. Applied Mechanics and Materials 513-517 (2014): 4338 - 4341.   
[14] 刘丰威,潘炜,韩丽丽.稽查中印章真伪识别智能算法[J].中国高新科技,2020,13:130-131.   
[15] 杨新军,王肇圻,刘唯一等.基于环投影模版匹配的印鉴鉴别方法[J].光电子激 光,2001,11:1176-1181.   
[16] 张先盟,罗安玉,王翔等.用矩不变量实现印鉴自动识别[J].1994,04:100-103.   
[17] 孙红岩,印鉴识别系统的研究.沈阳:辽宁科技大学,2008.   
[18] 张淼.基于矩不变量的印章鉴别技术的研究[D].西安:西安电子科技大学,2005:35-44.   
[19] 朱根胜.基于ARM 的印章识别系统研究[D].天津:河北工业大学,2018.   
[20] 朱根胜,赵红东,杨志明等.基于 Krawtchouk 矩和支持向量机的印鉴真伪识别[J].光学技 术,2018,44(3):354-358.   
[21] Bromley, Jane et al. Signature Verification Using A "Siamese" Time Delay Neural Network [D]. International journal of pattern recognition and artificial intelligence (1993).   
[22] S. Chopra, R. Hadsell and Y. LeCun, Learning a similarity metric discriminatively, with appli cation to face verification[C], 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05), San Diego, CA, USA, 2005, pp. 539-546 vol. 1, doi: 10. 1109/CVPR.2005.202.   
[23] Vinod Nair, Geoffrey E. Hinton. Rectified linear units improve restricted boltzmann machines [C]. ICML'10: Proceedings of the 27th International Conference on International Conference on Machine Learning.Haifa,Israel,2010.   
[24] S. Zagoruyko and N. Komodakis, Learning to compare image patches via convolutional neura l networks[C], 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Boston, MA, USA, 2015, pp. 4353-4361, doi: 10.1109/CVPR.2015.7299064.   
[25] Horiuchi T,Rioux M,Haruki R,et al.Three-dimensional approach to thresholding seal impressi ons[J].Pattern recognition,1996,29(5):719-724.   
[26] 陈运文,王逸飞.基于几何统计特征的印鉴自动识别算法[J].计算机工程与应 用,2005(27):4-6.   
[27] Zhu Y,Cheng S,Stankovic V,et al.Image registration using BP-SIFT[J].Journal of Visual Communication and Image Representation,2013,24(4):448-457.   
[28] 余彪,万水龙,刘进等.基于 Krawtchouk-RBF 的印章图像分类识别[J].微型机与应 用,2014,33(06):44-47.   
[29] 宋禹廷.基于机器视觉的印章识别系统设计与实现[D].四川:电子科技大学,2015.   
[30] 张娜.印章的自动匹配与文字识别[D].西安:西安电子科技大学,2020.   
[31] 拉斐尔·C.冈萨雷斯.数字图像处理(第四版) [M].电子工业出版社.2020.05.   
[32] 章毓晋.图像处理和分析基础[M].北京:高等教育出版社,2002.   
[33] 张铮,倪红霞,苑春苗等.精通Matlab 数字图像处理与识别[M].北京:人民邮电出版社,2013.   
[34] Feng Yin,JiaHao Pan,JiaZhi Yin. Multiform Stamp Image Pose Correction Algorithm Based o n Perspective Transformation[C]. International Conference on Image,Signal Processing and P attern Recognition. 2023.02.   
[35] Dabov K, Foi A, Katkovnik V, et al. Image denoising by sparse 3-D transform-domain collab orative filtering[J]. IEEE Transactions on image processing, 2007, 16(8): 2080-2095.   
[36] Canny J.A computational approach to edge detection[J].IEEE Transactions on Pattern Analysi s and Machine Intelligence.1986(6):679-698.   
[37] Goodfellow I,Bengio Y,Courville A,et al.Deep learning[M].Cambridge:MIT press,2016.   
[38] Y. LeCun et al., Backpropagation Applied to Handwritten Zip Code Recognition[J],in Neural Computation, vol. 1, no. 4, Dec. 1989, pp. 541-551.   
[39] 欧阳欢,大昭,李东子.多特征融合决策的发票印章识别[J].计算机工程与设计. 2018,39(09), 2842-2847.   
[40] Sargur N. Srihari; Venugopal Govindaraju. Analysis of textual images using the Hough transf orm[J]. Machine Vision and Applications. 1989. Volume 2, Issue 3. PP 141-153.   
[41] 刘珍丽,傅德胜.基于 Bubble 小波函数的印鉴鉴别[J].大气科学学报,2002,25(5):698-701.   
[42] 崔 程 程,周 先 春,昝 明 远 等.基 于 自 适 应 滤 波 的 BM3D 算 法[J].电 子 测 量 技 术. 2021,44(12),97-101.   
[43] Shokri Z. Selim, M. A. Ismail. K-Means-Type Algorithms: A Generalized Convergence Theor em and Characterization of Local Optimality[J]. IEEE Transactions on Pattern Analysis and M achine Intelligence, Jan.1984. Volume: PAMI-6, Issue: 1,PP 81-87.   
[44] 国务院关于国家行政机关和企业事业单位社会团体印章管理的规定[EB/OL]. http://www.gov.cn/xxgk/pub/govpublic/mrlm/201011/t20101115_62739. html.2010.   
[45] Ballard, Dana H.. Generalizing the Hough transform to detect arbitrary shapes[J]. Pattern Rec ognit. 13 (1981): 111-122.   
[46] 代勤,王延杰,韩广良.基于改进 Hough 变换和透视变换的透视图像矫正[J].液晶与显示. 2012,27(04): 552-556.   
[47] Yu, Jiahui et al. UnitBox: An Advanced Object Detection Network[C]. Proceedings of the 24th ACM international conference on Multimedia. 2016.   
[48] 胡海鸥,祝建中.基于弧段组合的直接最小二乘椭圆拟合[J].杭州师范大学学报(自然科学 版),2011,10(6):556-560.   
[49] Simonyan K,Zisserman A.Very deep convolutional networks for large-scale image recognitio n[J].arXiv preprint arXiv:1409.1556,2014.   
[50] Howard, Andrew G. et al. MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications[J]. ArXiv abs/1704.04861 ,2017.   
[51] Q. Wang, B. Wu, P. Zhu, P. Li, W. Zuo and Q. Hu, ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks[C], 2020 IEEE/CVF Conference on Computer Vision a nd Pattern Recognition (CVPR), Seattle, WA, USA, 2020, pp. 11531-11539, doi: 10.1109/CV PR42600.2020.01155.   
[52] He, Kaiming et al. Deep Residual Learning for Image Recognition[C]. 2016 IEEE Conferenc e on Computer Vision and Pattern Recognition (CVPR) (2015): 770-778.   
[53] Q. Wang, B. Wu, P. Zhu, P. Li, W. Zuo and Q. Hu, ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks[C], 2020 IEEE/CVF Conference on Computer Vision a nd Pattern Recognition (CVPR), Seattle, WA, USA, 2020, pp. 11531-11539, doi: 10.1109/CV PR42600.2020.01155.   
[54] 李彦枝.基于神经网络的极光图像及极光序列分类研究[D].江苏:南京邮电大学,2020.   
[55] 陈娅娅,刘全香,王凯丽,易骁华.基于ResNet和迁移学习的古印章文本识别[J].计算机工程 与应用.2022,58(10).125-131.