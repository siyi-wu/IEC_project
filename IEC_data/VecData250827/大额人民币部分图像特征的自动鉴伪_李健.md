# 硕士学位论文

# 大额人民币部分图像特征的自动鉴伪

（题名和副题名）

# 李健

（作者姓名）

指导教师姓名 娄震 副教授学位类别 学术硕士学科名称 计算机应用技术研究方向 图形图像处理论文提交时间 2015.01

# 摘要

随着我国经济的快速发展，市场流通的纸币数量在不断增长。但是假币的存在和蔓延严重干扰了国家的经济秩序。面对新型的造假手段，利用图像处理技术对纸币进行鉴伪越来越受到重视。通过图像处理技术可以对纸币进行准确的识别和分类，保证纸币流通过程的安全性。

本文以人民币一百元为研究对象，结合图像处理和模式识别的相关算法，探讨了纸币的透射图像和红外图像下的真假识别问题，分别介绍了透射光下的白水印和变色油墨图像鉴伪、CIS采集的纸币红外图像的鉴伪问题。具体工作包括以下几个部分：

首先介绍了在CMOS图像传感器下获取变色油墨图像和白水印区域图像的步骤，包括透射图像的鱼眼校正等预处理过程。

其次，根据定位信息切割出白水印和变色油墨图像。对白水印图像特征进行提取的时候，采用了基于投影差分的归一化积算法、基于白水印连通域的鉴别算法和八方向特征提取算法，并进行了算法的分析比较；在提取变色油墨图像特征的时候，引入了色温和色差的概念，并提取变色油墨图像的色差作为特征的一部分，形成三维特征，然后利用K最近邻分类算法和感知器分类算法对特征进行识别和分类，从而实现真假鉴伪。

最后，介绍了在CIS图像传感器下采集的纸币的红外图像的鉴伪过程，包括纸币面额、方向和版本等信息的获取和图像鉴伪。在提取红外图像特征时，提出采用相邻区域对比式策略提取灰度信息作为特征进行判断的鉴伪方法和利用红外安全线信息进行鉴伪的方法。

大量的实验证实，利用白水印特征和变色油墨特征可以达到的抓假率分别超过 $9 0 \%$ 和 $8 0 \%$ ；在CIS红外图像下本文的算法也获得了很好的鉴伪效果。

关键字：纸币图像鉴伪，透射图像，白水印，变色油墨，CIS，安全线，红外鉴伪

# Abstract

With the rapid development of economy in our country, the number of the market circulation of paper currency is growing. But the existence and spread of counterfeit banknotes seriously interfere the country's economic order. In the face of the new fraud means and technology, using image processing technology to identify the counterfeit banknotes draws more and more atention. Through the image processing technology, the paper currency can be accurately identified and classfied, so it can guarantee the safety of paper currency in the circulation process.

Based on the algorithm of the image processing and pattern recognition, in this paper， a research on the identification and recognition problems under the transmission light image and infrared image of' the $\yen 100$ has been studied. It respectively introduces the authentication on the white watermark image and the transmission light image of optically variable ink(OVI) acquired by CMOS,and on the infrared image acquired by the Contact Image Sensor(CIS). The specific tasks include the following sections.

This article firstly introduces how to obtain the white watermark region image and OVI region image, including the pretreatment process such as the barrel distortion correction.

Secondly, cut out white watermark image and OVI image according to the positioning information. In order to extract features from the white watermark image, three algorithms have been adopted, including a new NCC algorithm based on the projection difference、an algorithm based on the connected domain and eight-directions feature extraction algorithm. The analysis and comparison to these three algorithms also have been carried on. In order to extract features of the OVI image, the concept of color temperature and color aberration have been introduced. The color aberration is taken as a part of features,and finally a three-dimensional feature is obtained. Then the KNN and Perceptron algorithm are designed as classifiers and realize the authentication function.

Finally, it introduces the counterfeit detection process on the infrared image acquired by the CIS, including the acquisition of the basic information and authentication of banknotes. In order to extract features,a new method through extracting the relative gray level information from the feature areas comparing to the adjacent areas as features is put forward. And the information of security thread in the infrared image can also be used to authenticate the banknotes.

A lot of experiments confirmed that the respective rate of identifying the counterfeit banknotes of using the features of white watermark and OVI image can be more than $90 \%$ and $80 \%$ ,and a very good result also has been achieved by the algorithm under the infrared images.

Key Words: banknote image authentication; transmission image; white watermark; optically invariable ink; CIS; security thread; infrared authentication

# 目录

摘要.  
Abstract. 11  
1.绪论 1  
1.1．研究的背景和意义  
1.1.1．纸币防伪技术的特点与发展趋势  
1.1.2．基于图像特征的假币鉴别 2  
1.2．国内外研究现状及存在的问题  
1.3．论文主要研究内容.  
2.人民币图像预处理. 5  
2.1. 图像增强， 5  
2.2. 图像几何变换， .6  
2.3. 图像平滑去噪. ....3  
2.4. 图像边缘检测. ...14  
2.5．人民币图像桶形失真校正. ...15  
2.6．人民币版面信息的识别 .17  
2.6.1．纸币的方向判定 ...18  
2.6.2．纸币的版本判定 ..20  
2.6.3．白水印和变色油墨区域图像的定位.. .22  
2.7．本章小结， ..22  
3.人民币白水印特征提取和识别.. 24  
3.1．人民币白水印防伪特征的重要意义 ..24  
3.2．白水印面额数字图像的切割. ...25  
3.3．白水印面额数字的特征提取 .25  
3.3.1．模板匹配法， ...26  
3.3.2．八方向特征提取算法， .28  
3.3.3．基于连通域个数的特征提取方法， ..30  
3.4实验结果分析. ...33  
3.5本章小结. ....3.4  
4.变色油墨面额数字的特征提取和识别. .35  
4.1．图像的获取， ...35

II

4.2. 变色油墨数字与背景的分离 .36  
4.3. 变色油墨数字特征提取 .37  
4.4. 变色油墨特征识别判定真假 ..39  
4.4.1．K最近邻分类器(KNN)真假分类 ..39  
4.4.2．感知器神经网络 ..39  
4.4.3．基于感知器神经网络的真假分类 .41  
4.5．本章小结 .43  
5.人民币纸币红外图像鉴伪方法 44  
5.1. 红外图像边缘检测 .44  
5.2. 纸币基本信息的获取 ..47  
5.3. 红外图像特征 .48  
5.4. 红外特征鉴别方法 .50  
5.5. 红外安全线鉴伪 .53  
5.6．本章小结 .55  
6总结与展望 .56  
6.1总结 .56  
6.2展望 ..56  
致谢 .58  
参考文献 . 59  
附录 62

# 1.绪论

# 1.1.研究的背景和意义

纸币作为货币的主要流通方式，也作为社会经济活动的载体和财富的象征，在国民经济生活中起着不可替代的重要作用。随着我国经济持续、快速而又稳定的增长，人民币的需求和流通急剧增加，并且随着人民币国际化进程的加快，人民币在世界经济发展中发挥的作用也越来越大。但是假币的存在和蔓延严重却干扰了国家的经济秩序和人民的正常生活，给社会的稳定带来极大的威胁。假币是指伪造或变造的货币，简称伪造币或变造币。伪造币是指仿照真币的纸张、形状、图案特征等，采用彩色印刷等二次加工手段制作的假币。变造币是指在真币的基础上，利用挖补、涂改、拼凑、移位等多种方法制作的改变真币币值的假币。

随着科技水平的发展和进步，伪造货币手段不断变化，假币种类也不断增多，欺骗性增强，识别难度也越来越大，因此防假反假的任务也将越来越艰巨，世界各国货币发行机构和反假部门也为此付出了大量的社会成本。因此，对人民币在流通过程中的检测和鉴伪就显得十分重要。纸币的鉴伪工作，注定是一项长期且极具社会重大责任的任务。

# 1.1.1．纸币防伪技术的特点与发展趋势

为了防范和遏制假币，在货币印制过程中各国都会精心设计和采用各种先进的防伪措施和手段，钞票的质量逐步提高，防伪技术也日新月异。人民币的设计、制作也不例外，无论是从印刷技术的创新、纸张材质的选用还是其他防伪技术的应用，在国际货币体系中都已属于较为先进的币种之一。现在我们结合主要的几种外币，特别是美元、欧元、日元、港币、英镑等货币的防伪技术，以下我们探讨一下纸币防伪技术的特点和发展趋势，有利于提高我国钞票的防伪制造水平。

# 1) 纸张防伪技术

各国都有独特的纸币的纸张用纸配方，这样使得专用印钞纸难以被伪造和仿制。比如，人民币纸张的主要原料是棉、麻纤维等，纸张坚韧；美元的纸张采用的是棉麻布纹纸；日元纸张采用的是原产地的含有日本特有植物三娅皮纤维成分的纸张。纸张防伪技术的最新进展当属聚酯钞票，聚酯钞票是以特种塑料为承印物的塑料钞票。澳大利亚在国庆200周年纪念日之际发行了第一款以聚酯为承印物的塑料钞票，开创了钞票印刷的新纪元。聚酯钞票不是普通的塑料，而是一种高分子聚合物，能防止复印。目前已经发行塑料钞票的国家和地区包括加拿大、澳大利亚和中国香港等。2000年，我国也曾发行过“迎接新世纪”的聚酯纪念钞。

# 2）水印防伪技术

水印是纸张在生产过程中通过改变纸浆纤维密度的方法而制成的，它是在造纸过程中形成的，是“夹”在纸中而不是印在钞票纸表面上的。在迎光透视时可以清晰看到有明暗纹理的图案。固定水印在各国钞纸中用的最多。固定水印多采用特指的伟人肖像或者面额数字等。随着应用的增多，水印的质量包括水印的立体感也越来越好。人民币上含有毛泽东头像和花卉固定水印，特别是第五套人民币2005版纸币还使用了先进的白水印技术用于防伪。

# 3）安全线技术

安全线就是在造纸过程中采用特殊技术在纸张的特定位置嵌人一条薄的聚酯类塑料线、缩微印刷线、金属线或荧光线。有埋入式安全线和局部裸露的开窗式安全线。开窗式安全线采用等距外露和潜埋的形式来安放箔材，还有的纸币在箔材安全线还印上面额。开窗式安全线断续的外露，如果是用复印机复印，那么暴露的箔材就会被复印成断续的黑线，故达到了防复印效果，并且也很容易直观识别。微缩文字安全线我国人民币也采用了目前国际上技术最新的防伪性能最好的全息磁性开窗式安全线，迎光可以看到“RMB100"的缩微文字。。

# 4）彩色纤维和无色荧光纤维技术

彩色纤维是预先将一些特殊纤维染上颜色，在造纸过程中将这些纤维按照一定的比例加到纸张中。钞票上采用彩色纤维的国家如美国，纸张中都加有红蓝彩色纤维。无色荧光纤维是指在钞纸内部分布有不易察觉的纤维，在紫外光照射下有荧光反应。采用这种做法伪的造假难度大，效果好。

# 5）防伪油墨技术

从上世纪末起，世界各国在印刷钞票上的彩色图案时，开始采用在印刷油墨中加入特殊物质的油墨来替代普通油墨，这就是防伪印刷油墨技术。防伪油墨的防伪功能由油墨中具有特殊性能的防伪材料来实现的，即在不同的外界条件下会引起油墨的色彩变化，常见的有光敏变色油墨等。防伪印刷油墨具有防伪技术实施方便、隐蔽性好、色彩鲜艳等特点，在诸多防伪印刷领域应用广泛，目前在各种票证、商标和纸币的防伪印刷上被广泛使用。我国第五套人民币就采用了光变油墨面额数字用于鉴伪。

# 1.1.2．基于图像特征的假币鉴别

纸币的鉴伪处理技术，按照技术的发展演化，可分为以下阶段：紫外光下的荧光纸质检验技术、磁性油墨和安全线检测技术以及图像鉴伪等新一代的鉴伪技术[1I2]。总结起来就是磁性和光学特性检测两类。数字图像处理技术作为纸币识别和防伪的技术，就是新一代防伪技术[3]。通过图像传感器采集到图像，然后再利用数字图像处理技术，把这类图像特征量化表达，作为鉴别真伪的依据，从而识别出假币。

常见的图像传感器包括CCD、CMOS和CIS。CMOS图像传感器具有功耗小、成本低，易于实现与其他系统的集成等优点，CIS图像传感器具有结构简单、体积小、应用方便等优点，是新代的图像传感器。本文将探讨在CMOS和CIS 红外光源下采集到的纸币图像的鉴伪技术。

前面提到，新版人民币上含有多种图像防伪特征[4I5I，除了上面提到的毛泽东头像固定水印或者花卉固定水印、光变油墨数字和安全线等之外，还包含有臼水印、阴阳互补对印图案和隐形面额数字等。山于白水印和光变油墨数字的造假难度大，本文选取在CMOS图像传感器MT9T001下采集到的白水印和变色油墨透射图像和CIS图像传感器下采集的红外光图像特征作为鉴别伪钞的依据，实现真伪鉴别。白水印和变色油墨位置如图1中所示。

![](images/b2a801224cf834c017a20142dad93a9acc4fc9acbcf17d42d957d6397dcfc17c.jpg)  
图1白水印和变色油墨区域图像

# 1.2.国内外研究现状及存在的问题

目前，在纸币鉴伪技术的应用和鉴别方面，国外像德、白、美等发达国家走在了世界的前列，他们推出的针对美元、欧元和英镑的点钞机系统，已经广泛应用于金融行业中。但是这些设备识别速度比较慢，价格也非常昂贵。我国在纸币鉴伪识别领域刚刚起步，不过有一批国内企业也取得了一定的成果，都相继研制出并已投放市场的基于图像处理的点钞鉴别仪。其中沈阳中钞信达和古螯等多家公司生产的点钞机都分别具备多种图像和磁性鉴伪功能，比如红外图像鉴伪功能，磁性油墨鉴伪，还有纸张的穿透性等，但是都没有发现采用变色油墨或者白水印来进行鉴伪的功能。南京理工 SPEED 科技股份有限公司也研制出了多个型号带有图像自动鉴伪功能的智能点钞机系统，其中CMOS型点钞机包含白水印和变色油墨图像鉴伪，CIS型点钞机包含红外图像鉴伪等，其图像鉴伪能力已经达到国内先进水平，目前产品已销往国内外的多个市场。

# 1.3.论文主要研究内容

本文主要描述的是对图像传感器CMOS采集的人民币透射图像和利用CIS采集的人民币纸币红外图像加以处理，完成对纸币的鉴伪的目的。根据实际要求，本文主要完成以下几个方面的工作：

(1）利用CMOS卧式点钞机，采集人民币的透射图像;(2）利用CIS图像传感器，采集人民币的红外图像；(3）实现基于白水印和变色油墨的透射图像的鉴伪和基于红外图像特征的鉴伪。本文的结构安排如下：

本文为了详细介绍人民币纸币图像的鉴伪技术，在结构上分成六章来讲述，每一章的内容具体的安排如下：

第一章介绍了本论文研究的背景和意义，并探讨了目前国内外的研究现状和发展趋势，最后对本文的研究工作和各章节内容作简要介绍。

第二章介绍了图像的预处理过程、对人民币图像因广角镜头采集引起的桶形失真进行校正、如何准确切割白水印和变色油墨区域图像等方法。

第三章介绍了纸币白水印透射图像鉴伪特征的提取和匹配的过程。

第四章首先介绍了色温和色差的概念，并提出一种提取人民币变色油墨数字透射图像特征的过程，并分别采用最近邻分类器和感知器分类算法对纸币真假进行鉴别。

第五章介绍了人民币的CIS红外图像的鉴伪过程，此处采用基于相邻区域的灰度信息特征提取算法。

第六章总结了本文的研究内容和对未来的展望。

# 2.人民币图像预处理

在对图像进行处理和识別之前，都需要对图像进行预处理，包括图像的平滑，图像增强，图像旋转和图像的边缘检测等，以便后续对图像的进一步处理。同样，对于本文的人民币纸币图像而言，首先，山于是在点钞机等高速设备下采集的图像，图像上会出现大量的黑白噪音点；其次，纸币本身票面上也会经常有污渍；再次，山于纸币在进钞和走钞过程中难免会出现倾斜甚至变形等，正如本文山CMOS广角镜头采集到的透射图像的桶形失真等问题，就更需要我们在进行人民币图像特征提取和识别之前，进行充分的预处理操作，这样才能使后续的试验得以顺利的进行。

# 2.1.图像增强

图像增强是一个重要的图像预处理过程。图像增强是指对图像的某些我们感兴趣的特征进行加强，其目的是使得图像中有利于识別的信息得到增强，同时抑制无用的干扰信息，这样就增大了不同目标之间的特征上的差别，为信息的提取和识别奠定了基础。图像增强分为基于空域和频域的增强方法。

基于空域的方法分为点运算和邻域运算。点运算是对图像的灰度级进行变换，是“种点到点的变换，也被称为灰度变换。常见的点增强运算包括(分段)线性变换、非线性变换、直方图均衡化等。

灰度拉伸是线性变换的一种，是常用的图像增强方法。其数学表达式如下：

$$
G = f ( g ) = k ^ { * } g + b
$$

式中 $\mathfrak { g }$ 表示原始图像的灰度级， $\mathrm { \Delta k }$ 和 $b$ 为拉伸系数，当 $k { > } 1$ 时，输出图像的对比度增大；当 $k { < } 1$ 时，输出图像的对比度降低，b是用来调节图像的亮度的，其效果是使图像整体上变得更亮或者更暗，。如下图2.1所示为白水印区域图像灰度被拉伸到灰度级0-255上的图像增强效果。

J6Q7374083

J6Q7374083

# 2.2.图像几何变换

图像的几何变换是一种点运算。图像的几何变换，是指建立原始图像上各点与其变换后的图像中各点之间映射关系的函数映射，包括图像的平移和旋转等。数学上表示为：

$$
[ \mathrm { x } , \mathrm { y } ] { = } [ \mathrm { X } ( \mathrm { u } , \mathrm { v } ) , \mathrm { Y } ( \mathrm { u } , \mathrm { v } ) ]
$$

或

$$
[ \mathrm { u , v } ] { = } \smash { \stackrel { \textstyle \Gamma } { \scriptscriptstyle \downarrow } } \mathrm { U } \bigl ( \mathrm { x , y } \bigr ) , \mathrm { V } \bigl ( \mathrm { x , y } \bigr ) \bigr ]
$$

![](images/460029046597a3a29d9de3e2012a57594214390ecdc6ac36fe683529a749d311.jpg)  
(b)灰度拉伸后的图图2.1灰度拉伸前后对比图

其中，[u.v表示输入的原始图像中的像素坐标，x.y表示经过儿何变换后得到的输出图像中相应像素的坐标。X、Y、U、V分别唯一的定义了原始输入图像和变换输出图像中像素点之间的几何对应关系。函数×、Y将输入坐标映射到输出坐标，故称式(2.2)为向前映射；而函数U、V是将输出图像坐标映射到原始输入图像上的相应坐标，因此称式(2.3)为逆向映射。向前映射是将原始输入图像的像素映射到出函数×、Y确定的输出图像的坐标位置上。输入像素在空间映射函数×、Y的作用下，映射到了新的坐标位置。

# 1.图像旋转

图像旋转的公式如式(2.4)所示，旋转示意图如下图2.2所示，

设旋转前坐标为 $( \mathbf { x } 0 , \mathbf { y } 0 )$ ，到原点的距离为 $r$ ，与 $\boldsymbol { \chi }$ 轴夹角为 $\theta$ ，现在旋转角度 $\alpha$ ，旋转后与 $\scriptstyle x$ 轴夹角为 $\alpha + \theta$ ，旋转后坐标为 $( x _ { 1 } , y _ { 1 } )$ ，则 $( x _ { 1 } , y _ { 1 } )$ 与原点的距离依然为 $r$ ，旋转前有(2.4)式成立：

$$
\left\{ { \begin{array} { l } { x _ { 0 } = r \cos \alpha } \\ { y _ { 0 } = r \sin \alpha } \end{array} } \right.
$$

同理，旋转以后，式(2.5)也成立：

$$
\left\{ \begin{array} { l l } { x _ { 1 } = r \cos ( \alpha + \theta ) } \\ { y _ { 1 } = r \sin ( \alpha + \theta ) } \end{array} \right.
$$

对式(2.5)按照三角公式展开得：

$$
\begin{array} { c } { { x _ { 1 } = r \cos \alpha \cos \theta - r \sin \alpha \sin \theta = x _ { 0 } \cos \theta - y _ { 0 } \sin \theta } } \\ { { y _ { 1 } = r \sin \alpha \cos \theta + r \cos \alpha \sin \theta = x _ { 0 } \sin \theta + y _ { 0 } \cos \theta } } \end{array}
$$

写成矩阵形式就是：

$$
[ x _ { 1 } , y _ { 1 } , 1 ] = [ x _ { 0 } , y _ { 0 } , 1 ] { \left[ \begin{array} { l l l } { \cos \theta } & { \ \sin \theta } & { \ 0 } \\ { - \sin \theta } & { \ \cos \theta } & { \ 0 } \\ { \ 0 } & { \ 0 } & { \ 1 } \end{array} \right] }
$$

系统采集的人民币纸币图像是在纸币高速运动下得到的，纸币在一定程度上会出现几何变形甚至扭曲。出现这种情况的原因有多种。比如说，由于是轮子带动纸币高速的运动，当纸币和轮子之间出现打滑的时候，就会造成采集的图像出现倾斜或扭曲现象。这就需要对图像进行旋转，然后再进行下一步的处理。同时，系统在对不同进钞方向的纸币图像进行处理的时候，包括在建立模板库等很多时候，出于节省处理时间，节约系统存储空间等方面的处理，其样本都是进过旋转等处理成一个方向，然后存储起来，那么在实时处理的过程中，也是需要根据方向的逻辑关系对图像进行不同角度的旋转操作。

# 2.图像平移

平移变换应该是几何变换中最简单的一种变换了。图像平移也非常简单。如下图所示，初始矩形图像A，其左上角坐标是 $( x _ { 0 } , y _ { 0 } )$ ，经过平移以后得到的图像为B，其左上角坐标是 $( x _ { 1 } , y _ { 1 } )$ ，平移向量是 $( a , b )$ □

![](images/8a58d664080804addf481bf20343ceaaa81e38cb929563c7545af50c4620d5bc.jpg)  
图2.3图像平移简略图

$$
\left\{ \begin{array} { l } { { x _ { \uparrow } = x _ { \uparrow } + a } } \\ { { y _ { \uparrow } = y _ { \uparrow } + b } } \end{array} \right.
$$

同样，把它写成矩阵形式：

$$
[ x _ { 1 } , y _ { 1 } , 1 ] = [ x _ { 0 } , y _ { 0 } , 1 ] { \left[ \begin{array} { l l l } { 1 } & { \ 0 } & { \ 0 } \\ { 0 } & { 1 } & { \ 0 } \\ { a } & { b } & { 1 } \end{array} \right] }
$$

3基于旋转和平移变换的局部区域图像快速获取方法刚刚介绍了图像的旋转和平移操作，下而看看如何解决这个问题。

如下图2.4所示，为一幅使用CIS采集到的一百元人民币纸币图像的标准正面图像，所谓标准图像是指图像没有倾斜和扭曲，没有破损，图像中的各部分区域的位置和大小可作为在该平台下采集的百元纸币的标准。例如，以左上角为原点，图中左上角国徽的位置是(48.30)。

![](images/9affd69100f02ba24f47ba424f0d773a605d9c1a4712a4ca2b36318f9c81c274.jpg)  
图2.4正面标准图像

下图是随机采集的纸币正面图像，此图像有倾斜和平移。

![](images/9f94caf26924dfdbdd5b651c54967a13878158c466629b7d9e064bee1ac0334e.jpg)  
图2.5随机采集的正面图像

接下来要讨论的问题是如何才能在发生倾斜和平移的图像中（图2.5)直接截取出所需要的区域，比如说如何才能截取出无倾斜的“拐角“，如下图所示，作为要处理的对象。

![](images/3770717c90bf6f703fe80d260c16e2c6d587c61750cf225dfc721d0084566181.jpg)  
图2.6待匹配的“拐角

其实该问题可以抽象简化成以下数学问题，如图2.7所示，即如何将当前图像B的红色区域截取出来。本文通过对其数学模型的坐标变换的推导过程，最终利用得到的公式快速实现特定目标区域的切割，切割后的图像是已经进过倾斜和平移校正的。

![](images/d5dd0b0f941f256ece04a6e5c9d0db84d01e874c4c7e725126e7e643b26641c7.jpg)  
图2.7数学模型

如图所示，因为图像的保存是依图像从左到右，从上到下存储的，前面也说过，标准图像上的每一个点的位置都算作是标准位置，其位置就可以看成是以标准图像的左上角为原点，以右向为X轴正向、向下为Y轴正向的坐标系下的位置。既然如此，本文就将标准图像的左上角作为坐标原点，做出一个以向右和向下分别为X、Y轴正向的坐标系，左上角的矩形区域看成是标准图像A，随机采集的非标准图像可看成是有旋转和平移的当前图像B，那么问题就转化成如何在B中快速截取出如标准图像A中相应位置的已经经过倾斜和平移校正的图像。

前面介绍过，几何变换根据坐标的映射可以分为向前映射和逆向映射，因为我们需要在非标准图像上截取出标准图像上相应坐标的像素，因此，需要先知道标准图像的坐标，然后根据坐标变换，再在当前输入图像上找到对应的点，再取出来。故而根据定义，该处理过程是属于向前映射的一种。

解决这个问题之前，我们首先需要一个数据结构来保存一些值，以便我们后续的处理。该数据结构如下所示：

typedef struct{

int cx; //保存当前获取到的纸币图像中心的横坐标int cy; //保存当前获取到的纸币图像中心的纵坐标int dx; //保存标准纸币图像中心的横坐标int dy; //保存标准纸币图像中心的纵坐标double $\pmb { \alpha }$ ： //保存当前纸币图像的倾斜角度}tagCenterAngle;

每一幅采集的图像都拥有这样一个数据结构，用于系统对自身的处理过程中。下面以标准图像上坐标 $( x , y )$ 详细说明每一步的坐标变换，为便于数学上的推导，坐标变换的最终形式都写成是矩阵的形式。同时，为了简洁起见，结构体成员可直接使用，此处省去定义结构体变量和使用.来调用结构体成员。

dx 和dy为标准图像的中心点坐标。cx、cy和Sita的值需要根据纸币图像的四个角点坐标来计算。关于角点坐标的计算，首先要检测到图像的四条边缘线，然后根据四条边缘线两两相交，得到四个角点坐标，这涉及到图像边缘检测的知识，我们将在下一节中介绍，此处先假设四个角点已知，根据四点横、纵坐标的平均值得到中心点坐标cx和cy，然后根据三角函数算出水平方向的倾斜角，即为 $\alpha$ 。整个推导步骤如下：

1）计算相关的值，填充结构体；dx = StdW / 2;  
$\mathsf { d } \mathsf { y } = \mathsf { S } \mathsf { t d } \mathsf { H } \mathrm { ~ / ~ } 2 ;$ （20  
$\begin{array} { r l r } {  { \mathbf { c x } = \frac { \displaystyle \sum _ { i = 0 } ^ { 3 } x _ { i } } { 4 } ; } } \\ & { } & { \displaystyle \mathbf { c x } = \frac { \displaystyle \sum _ { i = 0 } ^ { 3 } y _ { i } } { 4 } ; } \end{array}$   
$\alpha = a r c \tan ( \frac { y _ { 3 } - y _ { 0 } } { x _ { 3 } - x _ { 0 } } )$   
令 $\scriptstyle \theta ^ { = ( - 1 ) ^ { * } }$ $\alpha$ 。

2）转换坐标系，以标准图像中心点为原点，向上为 $\textbf { y }$ 轴正方向，向右为 $\textbf { x }$ 轴正方向，设转换后的坐标为 $( x _ { 0 } , y _ { 0 } )$ ，则根据平移公式有：

$$
\left\{ { \begin{array} { l } { x _ { 0 } = x - d x } \\ { y _ { 0 } = d y - y } \end{array} } \right.
$$

写成矩阵形式为：

$$
[ x _ { 0 } , y _ { 0 } , 1 ] = [ x , y , 1 ] { \left[ \begin{array} { l l l } { ~ 1 } & { ~ 0 } & { ~ 0 } \\ { ~ 0 } & { 1 } & { ~ 0 } \\ { - d x } & { d y } & { ~ 1 } \end{array} \right] }
$$

3）根据图像旋转公式，将标准图像旋转 $\pmb \theta$ 角度，假设得到坐标 $( x _ { 1 } , y _ { 1 } )$ ，如(2.7)式，接下来将(2.12)式代入得到(2.13):

$$
\left[ x _ { 1 } , y _ { 1 } , 1 \right] = \left[ x , y , 1 \right] \left[ \begin{array} { c c c } { { \cos \theta } } & { { \sin \theta } } & { { 0 } } \\ { { \sin \theta } } & { { \cos \theta } } & { { 0 } } \\ { { - \mathrm { d } \mathrm { x } \cos \theta - d y \mathrm { s i n } \theta } } & { { - \mathrm { d } \mathrm { x } \sin \theta + d y \mathrm { c o s } \theta } } & { { 1 } } \end{array} \right]
$$

4）接下来变换坐标系，重新以左上角为原点，得到坐标(x2,y2)：

$$
 { } _ { 2 } , y _ { 2 } , 1 ] = [ x _ { 1 } , y _ { 1 } , 1 ] { \left[ \begin{array} { l l l } { 1 } & { 0 } & { 0 } \\ { 0 } & { - 1 } & { 0 } \\ { d x } & { d y } & { 1 } \end{array} \right] } = [ x , y , 1 ] { \left[ \begin{array} { c c c } { \cos \theta } & { - \sin \theta } & { - \sin \theta } \\ { \sin \theta } & { \cos \theta } & { \cos \theta } \\ { \operatorname { d x - d x } \cos \theta - d y \sin \theta } & { d y + \dim \theta - d y \cos \theta } & { - \sin \theta } \end{array} \right] } .
$$

此时得到的坐标，是按中心点旋转过后的在原始坐标系下的坐标。

5）平移，将处于当前状态的标准图像平移至B所在的位置，平移向量是$( c x - d x , c y - d y )$ ，假设平移后的坐标是 $( x _ { 3 } , y _ { 3 } )$ ，则有：

$$
\begin{array} { c } { { [ x _ { 3 } , y _ { 3 } , 1 ] = [ x _ { 2 } , y _ { 2 } , 1 ] \left[ \begin{array} { c c c } { { 1 } } & { { 0 } } & { { 0 } } \\ { { 0 } } & { { 1 } } & { { 0 } } \\ { { c x - d x } } & { { c y - d y } } & { { 1 } } \end{array} \right] } } \\ { { = [ x , y , 1 ] \left[ \begin{array} { c c c } { { \cos \theta } } & { { - \sin \theta } } & { { 0 } } \\ { { \sin \theta } } & { { \cos \theta } } & { { 0 } } \\ { { \cos \theta - d y \sin \theta } } & { { c y + \mathrm { d x } \sin \theta - d y \cos \theta } } & { { 1 } } \end{array} \right] } } \end{array}
$$

到此，我们就得到了经过旋转平移后的图像坐标 $( x _ { 3 } , y _ { 3 } )$ ，展开式(2.15)后就能得到标准图像上任一点 $( x , y )$ 到 $( x _ { 3 } , y _ { 3 } )$ 的映射函数。

如果现在需要截取图像上为[left,top,right,botom]的一块矩形区域，按上面的方法必然可以求出该区域内每个像素点在随机图像的坐标，并取出对应的像素填充到要保存的内存区域中。也就是说要保存的第一个内存区域地址是top\*StdW+left，而不是0，并且存储的时候地址计算的宽度应该是是right-left，而不是StdW。

因此，这个问题又是一个平移问题，只是在映射 $( x , y )$ 之前，先做一次平移，平移量其实就是要截取的小图像的左上角坐标，假设为 $( l , t )$ ，则有：

$$
\left\{ { \begin{array} { l } { x = x _ { s } + l } \\ { y = y _ { s } + t } \end{array} } \right.
$$

我们只需将坐标 $( x , y )$ 看成是平移后的以切割区域左上角为原点的坐标，若 $( x _ { s } , y _ { s } )$ 为真正的标准图像上的原始坐标， $( x _ { D } , y _ { D } )$ 为最终映射到随即图像上的坐标，旋转角度 $\theta$ 换成 $\alpha$ ，一同代入式(2.14）得到：

$$
y _ { D } , 1 ] = [ x _ { s } , y _ { s } , 1 ] \left[ \begin{array} { c c c } { { \cos \alpha } } & { { \sin \alpha } } & { { \sin \alpha } } \\ { { - \sin \alpha } } & { { \cos \alpha } } & { { \sin \alpha } } \\ { { 1 \cos \alpha - t \sin \alpha + \mathrm { c x - d x } \cos \alpha + d y \sin \alpha } } & { { 1 \sin \alpha + t \cos \alpha + \sigma y - \mathrm { d x } \sin \alpha - d y \cos \alpha } } & { { \sin \alpha } } \end{array} \right] ,
$$

最终，根据公式(2.17)，根据展开之后得到的映射函数就能快速得到随机采集的图像上的任何位置和任何大小的标准图像。实际上计算得到的结果的坐标值往往不是整数。这时候我们就要采取必要的措施来确保每个坐标处都能取到值，比如采用双线性插值、均值滤波等。而且由于整个运算过程都是浮点数运算，考虑到系统的实时性，可以采取移位等方法将浮点运算转化成定点运算，以节省处理时间。

下图是给出了标准图像上区域为[1070,552,1166,596]的大小为 $9 6 ^ { * } 4 4$ 的“拐角“图像以及用介绍的方法在图2.5上面截取到的”拐角“图像。

![](images/05046cd860101fbdacf501638878318d328a7c32cb1a2d7664afec2aab1aa3b2.jpg)  
图2.8标准图像和利用式（2.16在图2.5上切割下来的图像对比

可以看到，目标区域图像整体被切割下来了，虽然由于此处采用了双线性插值，图像边缘没有标准图像上那么清晰，但总体上效果还是不错的。针对“拐角”整体位置在区域图像中有点偏下或者超出边界的问题，解决的方法很多，其实只要在选择切割区域的时候，将切割区域的宽度和高度都适当向两边放宽一点，还是可以比较完整的切割下目标区域的。

# 2.3.图像平滑去噪

噪声无处不在，只是强弱不同而已。图像平滑是指用于突出图像的主干部分，抑制原始图像中的噪声和干扰成分，使得图像亮度平缓渐变的一种预处理方法。图像平滑的方法包括线性平滑、插值和卷积等。平滑处理的方法因图像噪声的不同而不同。最常用的平滑处理包括均值滤波、中值滤波、极值滤波和高斯滤波等。

由于流通中的纸币受磨损、残破等影响，加上票面的污渍等，纸币图像难免出现噪声，这个时候在提取局部图像进行处理时就必须先平滑去噪。本文中使用的滤波算法主要有极值滤波和高斯滤波。

下图所示为最小值滤波：

![](images/527b55458a3f474600d4ed8ef311c86c44cfe6d4abc2afbe9d783b82063b1ea0.jpg)  
图2.9最小值滤波对比图

下图所示为最大值滤波：

![](images/528a800b555d71c1a0e302156801c95ff8530f62a2120b468fe4e2853a60f819.jpg)  
图2.10最大值滤波对比图

高斯滤波就是对图像的像素值取加权平均值，即由其一定邻域内的所用像素值经加权平均后计算得到。高斯滤波的具体操作是：用事先定义的模板去扫描原始图像，计算出模板所确定的邻域内的所有像素的加权平均值，然后再去替代模板中心点的像素值。高斯滤波的模板是使用正态分布函数计算得到的。在二维空间中，高斯模板的计算公式如（2.18）所示，其中 $( x _ { 0 } , y _ { 0 } )$ 为当前滤波窗口的中心坐标， $\sigma$ 决定着滤波窗口的大小， $\sigma$ 越大，滤波窗口尺寸越大，平滑程度越好，但同时模糊也越严重。

$$
G \left( x , y , \sigma \right) = \frac { 1 } { \sqrt { 2 \pi \sigma ^ { 2 } } } e ^ { \frac { - \left( \left( x - x _ { 0 } \right) ^ { 2 } + \left( y - y _ { 0 } \right) ^ { 2 } \right) } { 2 \sigma ^ { 2 } } }
$$

如图2.11所示的是按公式2.18生成的等高线曲面，它是一组以点 $( x _ { 0 } , y _ { 0 } )$ 为中心呈正态分布的同心圆。

![](images/ec46cdff1c548d9f7c3efb94dc66d0ee460ec9925219d278cb36039cdf40fad6.jpg)  
图2.11 二维高斯曲面

一般来说，高斯模板内各点的权值，以中心点 $( x _ { 0 } , y _ { 0 } )$ 处像素的权值最大，邻域像素的权值随着距离中心像素距离越来越远而越米越小，与原始图像做卷积运算后生成的模糊图像更多地保留了图像边缘效果。在实际工程图像处理中，高斯滤波得到了广泛应用。下图是不同 $\sigma$ 下的高斯滤波的效果图。

![](images/9e457020d5e4ed13723a840895b9a10b635dfb497b0086c29876ba9808513fd9.jpg)  
图2.4不同 $\sigma$ 值时的高斯滤波效果对比图

# 2.4.图像边缘检测

边缘检测是图像处理的一个基本问题。边缘点是指其周围像素的灰度有剧烈变化的像素点，常存在于目标与背景之间、I标与影子之间或者是目标与目标之间。边缘检测的目的是标识图像中亮度变化明显的点。

边缘检测的方法有很多，大致可分为两类：基于搜索和基于零交叉。基于搜索的算法首先是计算边缘强度，通常用一阶导数或梯度表示，最经典的检测算法有梯度算子、Sobel算子和Roberts算子等。基于零交叉的方法是找到由图像中二阶导数为零的点来定位边缘。常见的检测算子包括拉普拉斯算子和LoG算子等。

本文中处理CIS红外图像时，首先就要获取纸币图像的边缘。出于采集到的图像的背景是黑色的，纸币图像是一个近似矩形的图像，如图2.5所示，本文通过最小二乘法对边缘点进行拟合，从而得到边缘直线。本文中对边缘点的检测是从采集的图像的上下左右四个边缘逐步的往内侧检测，当遇到不为零的像素时，我们称为候选边缘点，然后运用某种策略来判断当前是不是真正的边缘点，检测到边缘点（图中绿色十字架表示）以后，保存到一个坐标数组中，运用最小二乘法拟合出k和b，就可以求出直线方程$\mathbf { \Psi } _ { \cdot } \mathbf { \Psi } ^ { \cdot } = k ^ { \ast } \mathbf { \Psi } _ { \cdot } \mathbf { \Psi } _ { \cdot } \mathbf { \Psi } + b$ (图中红线所示为纸币的垂直边缘线)。

![](images/bb0a0269a66b3c16fed580b797666edc936f8d6ef84609c00576efd2d6925baa.jpg)  
图2.5最小二乘法对边缘点进行拟合得到的边缘直线

# 2.5.人民币图像桶形失真校正

本文中采用的透射图像是利用广角镜头采集的人民币纸币图像。出于系统硬件的限制，导致镜头距离纸币走钞平面大约只有3厘米左右的距离，在镜头与目标实物距离--定的条件下，为了尽可能的加大摄像头拍摄的范围以获取大视场的目标实物信息，系统采用了短焦距的广角镜头获取图像，而广角镜头却带来了成像的畸变，最主要的便是桶形畸变，即采集的图像出现“鱼眼”现象。这种畸变如果不加以消除或者减弱，对后续图像的处理影响很大。所以在对白水印和变色油墨图像进行预处理的时候，桶形失真校正处理是很重要的一环。

本文中采用逆向映射的思想，通过遍历标准图像中的像素点来求取畸变图像中的对应像素点并进行相应校正。具体采用的地址映射方法是基于同心圆模板的多项式地址修正法[8]。

假设基准图像上标准像素点 $\left( u , v \right)$ ，畸变图像上对应像素点 $( x , y )$ ，则 $\left( \boldsymbol { \imath } \boldsymbol { \imath } . \boldsymbol { \nu } \right)$ 与 $( x , y ; )$ 之间存在着一定的对应关系，假设简化对应关系式如下所式：

$$
\left\{ \begin{array} { l } { u = x + \delta _ { x } ( x , y ) } \\ { \nu = y + \delta _ { y } ( x , y ) } \end{array} \right.
$$

式中 $\delta _ { x } ( x , y )$ 与 $\delta _ { _ { \cdot } } ( x _ { \cdot } \ y )$ 表示对应的像素点坐标间的畸变。径向畸变[9是引起桶形失真的主要原因。这种畸变会引起像素点的径向移动，即离光心越远，其变形越大，并且关于光心对称，如图2.6所示为畸变率随距离光心的远近的变化图：

![](images/005cbf6aa690a6882adf640ccc50d0fb5562fc204b3f2134ea91696e02932870.jpg)  
图2.6畸变率随距离光心的远近的曲线示意图

其表达式如式(2.20):

$$
\left\{ \begin{array} { l } { \displaystyle \delta _ { x , r } = x ( k _ { 1 } r ^ { 2 } + k _ { 2 } r ^ { 4 } + . . . ) } \\ { \displaystyle \delta _ { y , r } = y ( k _ { 1 } r ^ { 2 } + k _ { 2 } r ^ { 4 } + . . . ) } \end{array} \right.
$$

其中， $r ^ { 2 } = x ^ { 2 } + y ^ { 2 }$ ， $k _ { 1 }$ 、 $k _ { 2 }$ 等为畸变系数。

由Tsai证明，在对摄像机进行非线性畸变校正时，引入过多的非线性参数，不仅不能提高精度，反而会引起不稳定性[10]。实验表明，公式中仅保留 $k _ { 1 }$ 项便可以很好的胜任一般的桶形畸变校正[9]。因此有：

$$
\left\{ { \begin{array} { l } { u = x ( 1 + k _ { 1 } r ^ { 2 } ) } \\ { \nu = y ( 1 + k _ { 1 } r ^ { 2 } ) } \end{array} } \right.
$$

调节 $k _ { 1 }$ 的值，当 $k _ { 1 } \in ( - 0 . 0 0 0 0 0 1 2 , - 0 . 0 0 0 0 0 0 8 )$ 取值时，可得到如下比较理想的校正效果：

![](images/d901faa075ca2b026ff0be6831cfcc6f4eb6fc007afb54a49c9f153e3833b0fa.jpg)  
图2.7桶形畸变的图像

![](images/c02fd49ee1c8ee2b5c150711e892b26d3495a285be80f8613f28232146551d19.jpg)  
图2.8桶形畸变校正后的图像

# 2.6.人民币版面信息的识别

人民币版面信息的识别包括识别人民币的方向（正面正立、正面倒立、背面正立和背面倒立四种姿态）、人民币的面额识别、版本识别等基本信息9。本系统中的面额是根据纸币的宽度来获取的，是通过内部的测长部件来完成的，这样我们就先得到了纸币的

面额信息。

# 2.6.1.纸币的方向判定

由于点钞机机械结构的限制，留给图像传感器的安装空间很有限，镜头平面距离纸币走钞通道平面只有3厘米左右。镜头距离限制使得无法用一个镜头拍摄到整个纸面图像信息，本系统使用了等距排布的两个MT9T001型COMS图像传感器分别捕捉纸币左、右两部分图像，其中一个拍摄左上角、左下角2幅图像，另一个拍摄右上角和右下角纸币图像，接下来需要利用这4幅图像来得到人民币图像的版本和方向信息，纸币的面额我们已经得到。为了保证处理的实时性，我们对原始图像进行抽样，在原来的四分之一图像上处理得到纸币的版本和方向。

![](images/744cfbf485f0422c3ba92946add2b92b5f074d07db1c2245912bc10cf2f178c5.jpg)  
图2.9左上角透射图像

![](images/913bfdf465dd6a8ad2a41520969fe2b678ee8b5bdd440a871071059619c9cffc.jpg)  
图2.10左下角透射图像

![](images/581589f0808a81a5c08ce7e5de18054c44484b09cbc84e18834897cf5faf19f8.jpg)  
图2.11右上角透射图像

![](images/e8cc876a4290d41c37b32b62989b301573cb884e08da524559346a1b33e41ec6.jpg)  
图2.12右上角透射图像

上面4幅图分别是采集的100元人民币四个角上的图像的四分之一图像。通过观察这四幅图像的绿通道图像(如下图所示)，我们发现白水印和变色油墨所在的纸币一侧区域的图像亮度大(如图2.9和2.10)，另一侧绿通道图像亮度总体上明显偏小。为了避免边缘干扰造成的误判，我们选取绿通道正中间 $1 1 2 ^ { * } 8 0$ （图中红色方框所示）大小的图像作为处理对象，统计这块区域的灰度平均值，由此我们得到平均值最大的那一幅图像，或者是图2.9或者是2.10，它们均属于纸币的同一侧。

![](images/dd2a87519590736b655b3b741f174edb6fb49e894a403c3414aa77370d65fa69.jpg)  
图2.13左上角透射图绿通道图像

![](images/f7b8b099a182db435f7ff620a29975dbb5bcd771b5298db8cc422ed764a0a98c.jpg)  
图2.15右上角透射图绿通道图像

![](images/3829c0eb41cb9fe97d3a48e6542a05827b1c061a69ac50d5c1e61fa97f3bcbca.jpg)  
图2.14左下角透射图绿通道图像

心8

下面我们根据2.9和2.10判断纸币的准确方向，步骤如下：

（1）桶形失真校正，校正后结果如下；

![](images/2b4984d2ff71ca1796884c82b33769f82b3e243ab0daaf731f70722cf5ce691c.jpg)  
图2.16右下角透射图绿通道图像

![](images/9dd540572c70b221cb9a4d1548177a4f40f6d60532a00c9585defc92a1e2c80d.jpg)  
图2.17图2.9桶形失真和校正后的图像对比图

![](images/945108730a989d70659cccbc1e33f4b97f2ee364d629379878d4a80fcbb8645d.jpg)  
图2.18 图2.10桶形失真和校正后的图像对比图

(2）对校正后的图像求取水平方向投影，并计算投影的差分，并根据投影的最大值和最小值之间的差值大小，结合最大最小值在垂直方向的位置的高度差(即字符的高度），可以判断白水印和变色油墨区域在图2.9上，图中红色线标注的是冠字号码的上下位置；

![](images/9628e5c840d4877c5856c809add8523df78349e450401512384774eb04614394.jpg)  
图2.19图2.9水平方向投影的差分和极值位置

![](images/f53b8e8d930a5fb9e803917132e2581629fa57cb009947fed6ed6cfad8ea5154.jpg)  
图2.20 图2.10水平方向投影的差分和极值位置

这样我们根据冠字号码所在的区域可以得到纸币的方向。同时也确定了白水印和冠字号码的大致位置，如图2.9。

# 2.6.2.纸币的版本判定

目前我国市场上流通的是第五套人民币，目前为止一共发行了两种版别：1999版和2005版，这两种版别的不同之处主要就在于2005版的防伪技术是最好的。1999年发行的我们简称为99版，2005年发行的我们简称为05版。05版人民币进一步增强钱币的防伪技术，在保持纸币总体规格不变的前提下，对纸币的细节方面进行了一些调整。其中05版人民币光变油墨面额数字左移至原胶印对印图案处，此外也增加了白水印等防伪特征，增加的白水印就位于正面冠字号码的下方。如下图所示，左边为99版纸币正面左边部分，右侧是05版人民币的相应部分，可以明显的看到变色油墨的位置和白水印的差别。

![](images/99d7b4dbf6eed7285e43a869369a46d5cea085a4666f413824020c90ce2ac703.jpg)  
图2.2199版和05版冠字号码区域图像的区别

因此我们在得到变色油墨图像的位置坐标的时候，需要根据版本的不同来定位。并且由于99版是没有白水印防伪特征的，在鉴伪的时候，也需要版本来指导，所以本节将根据变色油墨的位置得到纸币的版本。

我们选取和2.5.1节中得到的同一方向的99版图像作为依据，详细说明版本的判定，其他方向以此类推，同样可以得到版本。

![](images/1736eaf9f0242dde1d3c30fe93d816c4f4733601904023871b87c945ecd6c0cf.jpg)  
图2.22 99版含变色油墨区域图像

由于冠字号码与白水印和变色油墨的相对位置是固定的，根据纸币的方向信息和已经确定的冠字号码位置，很容易确定白水印和变色油墨的大致位置，在本例中我们取图2.9中冠字号码以上的区域，如图2.23所示；

L对图2.22进行2.5.1节同样的步骤处理，得到图2.24：

![](images/bd014f604711b69e29ba4220ee683c27224332c6785e7fc65b6d254db335b24f.jpg)  
图2.23 05版含白水印和变色油墨区域的图像  
图2.24 99版含变色油墨区域的图像

将图2.23和图2.24划分成左右相同大小的两部分，其分别标记为Image_Left、Image_Right、Image_Left1、Image_Right1，并分别计算得到左右两部分的灰度平均值，ave_Left,ave_Right、ave_Left1、ave_Right1，如下图所示：

区域：Image_Left 5O0 中 区域：Image_Right 灰度均值：aveLeft 灰度均值：aveRight 图2.25 图2.23区域划分后的图 区域：Image_Left1 EPESE 区域：Image_Right1 灰度均值：aveLeft1 图2.26 图2.24区域划分后的图 灰度均值：aveRight1

通过比较灰度平均值就可以得到版本信息。如上图所示，纸币在该方向下，如果ave_Left大于ave_Right，则可以判断是O5版，如果ave_Left1大于ave_Right1，则可以判断是99版。

# 2.6.3.白水印和变色油墨区域图像的定位

在获得纸币的版本信息以后，下面对白水印和变色油墨区域图像进行定位。对图2.25进行最小值滤波，如图2.27所示；

然后在水平方向和垂直方向分别做投影和差分，可以进一步确定变色油墨和白水印的位置，从而准确的切割下白水印和变色油墨，如图所示。

![](images/4c66c87189695eb1e57babe646dddc39e3b35dbdd11406a4518ba43497dfffbe.jpg)  
图2.27最小值滤波后的图像  
图2.28定位白水印和变色油墨的投影信息和坐标位置信息

对于99版图像，通过同样的算法，可以得到变色油墨的准确位置信息。

# 2.7.本章小结

在本章中，我们着重介绍了图像预处理的相关知识，说明了人民币纸币图像的预处理步骤和定位了白水印区域与变色油墨区域图像，同时也对CIS红外图像的预处理和快

速获取指定区域的图像的方法进行了推导，为后续对白水印和变色油墨图像的特征提取和识别奠定了基础，也为CIS红外图像的处理提供了理论依据。

# 3．人民币白水印特征提取和识别

作为新版人民币中新加入的防伪特征点，本文将介绍如何对人民币白水印透射图像进行特征提取，并利用该特征来识别真假纸币[]。

# 3.1.人民币白水印防伪特征的重要意义

在纸币的防伪特征中，水印防伪是非常重要的一种防伪手段。现实生活中，为了快速鉴别人民币的真伪，通常的做法是将纸币迎着光源，这时候就会发现纸币中某些特定部位会显现出清晰的图像，这就是水印防伪技术。它是一种肉眼很难看见的印记，必须置于某种特定环境下才能被看到，比如在特定波长的光谱下显现。水印在人民币中使用也比较普遍。比如，在人民币正面的左侧的位置，冠字号码的上方有一片白色区域，这部分区域其实就是含有毛泽东头像的水印区域。而且，相对于99版人民币，05版人民币还增加了白水印防伪特征点。05版人民币的白水印就是纸币的面额数字。由于白水印需要在迎光时才能显示出来，故本文利用采集的是白水印的透射图像，如下图所示，分别为05版100元和50元的白水印面额数字透射图像，我们发现能够很清楚的看到透射图像区域的面额数字水印。

100 50

下图3.2就是我们利用本系统采集到的一百元的透射图像，其中最左图是真币的透射图像，右边两幅是假币的图像。对比两幅图像，我们可以看出，真币的白水印非常清晰，而假币几乎看不到白水印。所以，只要能够准确的切割出白水印图像，并提取图像的特征，就可以根据特征进行鉴伪。

![](images/d460a4b84c368168d391ee79c1579b0d56679bcd751b24bab3a79adb8f589de7.jpg)  
图3.1白水印面额数字  
图3.2真币（左一）和假币(右）的透射图像

# 3.2.白水印面额数字图像的切割

根据第二章2.5.3中对白水印区域的定位信息，就可以得到白水印面额数字区域的图像。然后需要在该图上切割下白水印。为了使白水印图像信息更加丰富和边缘信息更加明显，以便后续更好的提取特征，再对白水印图像进行灰度拉伸处理，具体步骤如下：

1）最大值滤波；  
2) 对最大值滤波后的图像沿着垂直方向作投影，计算出白水印的垂直方向的左右边缘；  
3）对滤波后图像沿着水平方向作投影，计算出白水印的水平方向的上下边缘；  
4) 根据边缘位置切割出白水印小图像；  
5）对切割的白水印图像进行灰度拉伸。

如下图3.3所示为得到的白水印面额数字区域的图像：

00L

图3.4所示为根据投影结果而切割下来的白水印面额数字图像：

0O图3.5所示是灰度拉伸后的白水印图像：

000

# 3.3.白水印面额数字的特征提取

白水印区域总体亮度比较高，为了使白水印图像信息更加丰富和边缘信息更加明显，以便后续更好的提取特征，本文首先对白水印图像进行灰度拉伸处理，

目前模式识别常用的方法主要有两种：一是模板匹配法，该方法是将大小归一化后的待识别图像和已经建好的标准模板图像库中的每个标准图像逐个进行点对点的比较，在建立好的图像库中，取相似度最高的模板图像作为识别的结果，并给出相似性度量。该方法简单，但是抗干扰性差；二是特征匹配法，该方法是通过分析目标图像的结构特征或统计特征，并设计出合适的分类器识别出结果。该方法在近年来得到了广泛的应用，同时也是模式识别未来发展的一大趋势。

# 3.3.1．模板匹配法

模板匹配[12是图像匹配中最基本的方法，它不用提取图像的任何特征，而是直接利用图像自身的像素值信息，即是让当前待匹配图像与标准模板库里的图像逐个进行匹配，并按某种策略计算它们之间的相似度，最大的相似度为最终的识别结果。待匹配图像和模板图像之间的相似度计算有多种，有MAD(平均绝对差)算法、归一化积相关(NCC)算法[13][14]、序贯相似性检测(SSDA)算法[15]等。

假设待匹配图像S的尺寸为 $\mathbf { M } ^ { * } \mathbf { M }$ ，模板图像 $\boldsymbol { \Upsilon }$ 的大小为 $\mathrm { N } ^ { * } \mathrm { N } ( \mathrm { M } > > \mathrm { N } )$ ，当模板在S上滑动搜索的时候，当前窗口所覆盖的子图记为 $S ^ { i , j }$ ， $( i , j )$ 为子图的左上角顶点在S上的坐标，通过对S的遍历搜索，在每个搜索位置处计算子图与模板的灰度相关性相关性最大的位置即为匹配位置，传统的归一化积匹配算法定义如下：

$$
R ( i , j ) = \frac { \displaystyle \sum _ { m = 1 } ^ { M } \sum _ { n = 1 } ^ { N } [ S ^ { i , j } ( m , n ) - \overline { { S ^ { ( i , j ) } } } ] ^ { * } [ T ( m , n ) - \overline { { T } } ] } { \displaystyle \sqrt { \sum _ { m = 1 } ^ { M } \sum _ { n = 1 } ^ { N } [ S ^ { i , j } ( m , n ) - \overline { { S ^ { ( i , j ) } } } ] ^ { 2 } } \ * \sqrt { \sum _ { m = 1 } ^ { M } \sum _ { n = 1 } ^ { N } [ T ( m , n ) - \overline { { T } } ] ^ { 2 } } }
$$

该方法的好处是抗干扰能力强，但该方法匹配速度较慢。很多文献都提出了改进匹配速度的方法，如文献[12][13]，但它们都是从改进式(3.1)的计算方法的角度提高其实时性的，本文提出一种针对图像投影的相关性匹配算法[1]，称为投影归一化积算法。

由于白水印区域图像颜色比较简单，背景也不复杂，因此白水印区域图像的水平和垂直方向的投影曲线能够反映出其在对应方向上的灰度分布特征，因此以投影为特征进行图像匹配可以取得良好的匹配效果。

投影归一化积算法的基本思想是：首先针对选定的白水印特征区域，求取该区域的水平和垂直方向的投影，分别求出投影的差分。然后，将该投影差分序列与模板库进行归一化积计算，求出相关值。实际上这种算法就是在计算相关性的时候，是针对投影的差分序列的每一个位置做相关性检测，而不是传统的归一化积算法针对每一个像素位置都计算相关性。投影差分序列相关系数 $\mathtt { R }$ 表示为：

$$
R = [ \sum _ { i = 0 } ^ { M - 1 } ( S ( i ) - \overline { { S } } ) ^ { * } ( T ( i ) - \overline { { T } } ) ] / [ \sqrt { \sum _ { i = 0 } ^ { M - 1 } ( S ( i ) - \overline { { S } } ) ^ { 2 } * \sum _ { i = 0 } ^ { M - 1 } ( T ( i ) - \overline { { T } } ) ^ { 2 } } ]
$$

$\boldsymbol { \mathscr { S } } ( i )$ 表示待匹配图在 $i$ 点处的投影特征差分值， $\boldsymbol { T } ( i )$ 为模板的投影差分值，S为待匹配图的投影平均差分值， $\overline { { \boldsymbol { \tau } } }$ 为模板的投影的平均差分值，然后求出水平和垂直方向的投影特征相关系数。为了减少特征区域定位的误差带来的影响和提高算法的健壮性，本文采用滑动匹配策略，即将标准模板投影在当前区域的投影曲线上进行滑动，包括水平和垂直方向，对于滑动经过的每一个位置都计算出相关系数R，这样就得到了两个相关系数数组 $H [ i ]$ 和 $V [ j ]$ ，然后分别求取最大值 $R _ { h \operatorname* { m a x } }$ 和 $R _ { \nu \operatorname* { m a x } }$ ，将这两个值分别与水平和垂直方向的判决阈值相比较，得出是否匹配。具体步骤如下：

1）选择一组比较理想的白水印灰度拉伸图像，按照式3.3进行垂直方向投影，然后根据式3.4对投影向量作差分，其中i取值从0到W-1，然后求出其平均投影差分（假设W和H分别为投影图像的宽和高）；

$$
p r o j [ i ] = \sum _ { j = 0 } ^ { \mathrm { H } } p \mathrm { I m } g [ j ^ { * } \mathrm { W } + \mathrm { i } ]
$$

$$
p r o j [ i ] = p r o j [ i + 1 ] - p r o j [ i ]
$$

其中i取值从0到W-2，并令proj[W-1]=0；

2）同理，可得到水平方向的投影及其差分图像，计算出平均投影差分图像

3）按式(3.2)将前两步提取到的投影向量与模板库中的模板图像投影向量进行逐一匹配，分别计算对应的相似性度量R，求出每个方向的最大值，得到判决结果。

如图3.6所示为垂直方向投影的差分图像：

![](images/1dbeefcc2079910bde490aed4e2eb1e93f81c6010bde34c62a7ade7a3abb7b89.jpg)  
图3.6 垂直方向投影差分图像  
图3.7 水平方向投影差分图像

如图3.7所示为水平方向投影的差分图像：

000

下表3.1的数据是在实验条件为Pentium $\textsuperscript { \textregistered }$ Dual-CoreCPUT4200，主频为2.00GHz的计算机平台上得到的。

表3.1本文算法和传统算法的性能比较  

<html><body><table><tr><td>算法</td><td>图像大小</td><td>模板大小</td><td>时间/s</td><td>位置</td></tr><tr><td rowspan="2">投影归一化积算法</td><td>120*48</td><td>80*28</td><td>0.0002763</td><td>(39,24)</td></tr><tr><td>512*512</td><td>72*56</td><td>0.005164</td><td>(39,24)</td></tr><tr><td rowspan="2">传统归一化积算法</td><td>120*48</td><td>80*28</td><td>0.06754</td><td>(39,24)</td></tr><tr><td>512*512</td><td>72*56</td><td>27.8772</td><td>(39,24)</td></tr></table></body></html>

分析表中数据，可得到如下结论：在图像大小和待匹配模板的大小比较小时，两种算法都耗费的时间都很少；当待匹配图像和模板变大时，传统算法的时间效率急剧降低，

而本文算法在保证匹配的精度情况下，依然能获取比较好的实时性能。但是也要看出，本算法的应用具有局限性。本算法适用于背景颜色比较单一，而且目标图像较背景比较明显，才能取得比较好的匹配结果。

# 3.3.2.八方向特征提取算法

基于特征匹配的识别方法是一种非常重要的匹配方法，近几年来得到飞速发展，该方法在各种识别系统中占有非常重要的地位。它和模板匹配最大的不同点是，它是先提取图像的某些特征，再用提取的特征和模板的特征进行匹配。特征匹配方法中最关键的地方是如何选择稳定而且有效的特征，并设计出合适的分类器识别出结果。本文通过图像的梯度特征来进行匹配。其匹配步骤如下：

1）求大小归一化后的图像分别在水平和垂直方向的梯度。计算图像梯度向量时，选用Sobel算子。X方向和Y方向的Sobel算子如图所示：

品

![](images/25262eaea5d3315f81bd95a0b4dae1691181b1ea550ee389d6f9679744b99121.jpg)  
图3.8水平方向(左)和垂直方向(右)的Sobel算子

则点 $( x , y )$ 处的梯度向量是 $\boldsymbol { g } ( x , y ) = ( g _ { x } , g _ { y } ) ^ { T }$ ，公式计算如下：

$$
\begin{array} { r l } & { g _ { x } ( x , y ) = f ( x + 1 , y - 1 ) + 2 f ( x + 1 , y ) + f ( x + 1 , y + 1 ) } \\ & { \qquad - f ( x - 1 , y - 1 ) - 2 f ( x - 1 , y ) - f ( x - 1 , y + 1 ) } \\ & { g _ { y } ( x , y ) = f ( x - 1 , y - 1 ) + 2 f ( x , y - 1 ) + f ( x + 1 , y - 1 ) } \\ & { \qquad - f ( x - 1 , y + 1 ) - 2 f ( x , y + 1 ) - f ( x + 1 , y + 1 ) } \end{array}
$$

2）将梯度向量 $\pmb { g } ( \pmb { x } , \pmb { y } ) = ( \pmb { g } _ { x } , \pmb { g } _ { y } ) ^ { T }$ 分解到如下图所示的即具有八个方向的坐标系上，每个梯度向量都投影到其相邻的两个坐标系上，分解图像如图3.10所示。

![](images/3688fb7f68b2f475a623faf1240f2e16deede352791a9af73e121726f3f794a9.jpg)

![](images/278effa5c6e732dd7bbd6c9aa21652a99d12eb85f7ef98e2912e7e54d4421ded.jpg)  
图3.9八方向坐标系  
图3.10梯度向量 $\mathbf { g }$ 分解示意图

# 3）模糊网格处理

为了克服微小的位移或倾斜对特征匹配的影响，提升算法的健壮性，本文对图像进行模糊网格处理，生成新的特征。如下图3.11所示为模糊网格的隶属函数，其呈现上窄下宽的形状，模糊网格隶属函数的值作为网格统计的权值，对网格内部数据进行加权累加，使得网格的边界元素同时归属于不同的网格。

![](images/d77ebae7c2e2d69796ca61d54e8776b1a0cee24e66ab622a97025634027ebb47.jpg)  
图3.11隶属度函数

![](images/7606729c75e4daab27466baa2f2b6755a8b7b85152dfb5ce0cfda393bbfcd040.jpg)  
图3.12隶属度函数权值的各部分取值

设网格中心为坐标原点，定义网格大小 $2 \mathrm { n }$ ，模糊大小 $a \in [ 0 . n ]$ ，则有如式(3.6)模糊网格的隶属函数。可以发现，距离网格中心点越近，权值越大，最大为1，对特征统计值的影响越大，距离网格中心越远，权值越小，对特征统计值的影响越小，图3.12是图3.11在XY平面的投影，图中标注的各部分区域代表了不同的权值取值，分别对应于公式(3.6)的各个取值区域。

$$
\begin{array} { r } { P _ { i } ( i , j ) = \displaystyle { \frac { \left( 1 , \qquad \quad a \leq i \leq 2 n - a , a \leq j \leq 2 n - a \right. } { 2 a } } } \\ { \displaystyle { \left[ \frac { 2 n + a - i } { 2 a } , \quad 2 n - a \leq i \leq 2 n + a , a \leq i \leq 2 n - a \right. } } \\ { \displaystyle { \left. \frac { a + i } { 2 a } , \quad - a \leq i \leq a , i \leq j \leq 2 n - i \right. } } \\ { \displaystyle { \left. \frac { 2 n + a - j } { 2 a } , \quad 2 n - a \leq j \leq 2 n + a , 2 n - j \leq i \leq j \right. } } \\ { \displaystyle { \left. \frac { a + j } { 2 a } , \quad - a \leq j \leq a , j \leq i \leq 2 n - j \right. } } \\ { 0 , \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad } \end{array}
$$

4）生成特征向量

经过对八向梯度子图进行模糊网格统计以后，就形成了最后的特征向量。设待匹配子图是 $s$ ，归一化后的大小是 $w \stackrel { * } { } h$ ， $\dot { F _ { \scriptscriptstyle k } } ( i , j )$ 是 $k$ 方向的梯度子图， $k \in [ 0 , 7 ]$ ，网格的大小为 $2 n ^ { * } 2 n$ ，则特征子图网格数是 $g r i d = \frac { \mathfrak { u } ^ { * } } { 2 n } ^ { * } \frac { h } { 2 n }$ ，第 $n$ 个网格第 $k$ 维特征是 $ { \boldsymbol { X } } _ { \boldsymbol { k } } ^ { \prime \eta }$ ，也就是第k个方向的特征子图在当前的网格中所有像素在模糊网格作用下的加权和，可

表示为式3.7所示：

$$
X _ { k } ^ { n } = \sum _ { i = - u } ^ { 2 n + u } \sum _ { j = - a } ^ { 2 n + a } F _ { k } ^ { n } ( i , j ) P _ { s } ( i , j )
$$

其中 $F _ { \boldsymbol { k } } ^ { \prime \prime } ( i . j )$ 表示的是第 $k$ 个方向的特征子图第 $_ { \mathscr { n } }$ 个网格中的像素值。山此我们得到第（20 $n$ 个网格的特征向量为 $\begin{array} { r } {  { \boldsymbol { X } } ^ { n } = [  { \boldsymbol { X } } _ { 0 } ^ { n } .  { \boldsymbol { X } } _ { 1 } ^ { n } ,  { \boldsymbol { X } } _ { 2 } ^ { n } .  { \boldsymbol { X } } _ { 3 } ^ { n } .  { \boldsymbol { X } } _ { 4 } ^ { n } .  { \boldsymbol { X } } _ { 5 } ^ { n } .  { \boldsymbol { X } } _ { 6 } ^ { n } .  { \boldsymbol { X } } _ { 7 } ^ { n } ] } \end{array}$ ，最终生成的特征维数是 ${ } ^ { 8 ^ { * } }$ grid 。

以上就是八向特征17提取的整个算法步骤

在本文中，对白水印图像提取八方向特征，由于白水印特征图像大小为 $8 0 ^ { * } 2 8$ ，故我们首先将白水印特征图像归一化到大小为 ${ 8 0 ^ { * } 2 4 }$ ，每个网格的大小为 $8 ^ { * } 8$ ，模糊大小a取3，则最终一共生成特征 $\frac { 8 0 } { 8 } \ast \frac { 2 4 } { 3 } \ast 8$ 共计 240维，下图3.13 是白水印特征图像计算得到的八方向特征子图：

![](images/d282bbd95aa06661bc70a05741197d7b2adcb8c9ef65936dc1dcae8c9a0e314d.jpg)  
图3.13白水印的八方向特征子图

得到特征之后，一一般情况下是需要设计合适的分类器对匹配结果进行分类。本例山于是图像的鉴伪，即辨别真和假，是简单的二类分类问题，能匹配的上表明白水印为真，否则为假。在度量结果匹配的时候，我们这里选择特征向量的平方和作为判决标准。在与模板库中图像的特征进行逐一匹配时，得到相应的特征向量每一维的差的平方和，作为最终的度量，当大于我们给定的阈值时，结果就判为假，否则可视为匹配上，结果为真。

# 3.3.3.基于连通域个数的特征提取方法

由于白水印区域图像背景简单，只有白水印数字“100”图像清晰，亮度高，因此如果考虑将白水印区域图像二值化，那么二值化以后的每一个数字都可以看成是一个连通域，这样就可以提取出白水印数字，实现真假识别。

在二值化图像中，连通区域标记是十分重要的步骤。连通区域标记是指把一幅图像中连接在一起的像素附上相同标记，没有连接在一起的像素附上不同标记的处理过程。常见的连通区域标记算法主要有像素标记法[18]、游程编码法[19]和区域生长法[20]。像素标记法和区域生长法在扫描图像做标记的时候，往往需要对目标像素点进行8-邻域或4-邻域检测[21]，检测它与近邻象素的连通性，但是当连通区域面积较大时，算法效率会严重下降。游程编码法是将连续扫描线作为连通域检测的基本单元，它首先对二值化图像进行逐行扫描，在当前行中每扫描出一条直线段，就和前一行已标记的直线段进行连通性检查，满足连通性要求的直线段就被赋予相同的连通域标号，该算法利用区域连通性的结构特征，相比而言具有更高的效率。

本文采取的是游程编码法对连通区域进行标记。标记完成后，对每一个连通域计算出它的大小(此处大小用包含的目标点点数来表示)。根据连通域的数目和大小就可以很容易得出是否真假币的信息。文献[22]、[23]中阐述了利用链表来实现连通域检测和保存的方法。每一个连通域直线段都保存在一个链表节点里，然后加入到全局的标记单链表里面，称为游程链表。该方法产生的等价对保存在链表节点结构里，称为等价对链表。首先定义两个结构体，分别表示等价对链表EqualMark和游程链表RunLength，其定义[23]如下：

typedef struct tagRunLength //游程的结构定义  
{int nLabel; //标号int nRow; //游程所在行号int nStart; //游程所在起始列号int nEnd; //游程所在终止列号struct tagRunLength \*next; //指向下一个游码的指针  
}RunLength;  
typedef struct tagEqualMark //等价对的结构定义  
{int nMakeValuel;int nMakeValue2;struct tagEqualMark \*next;  
}EqualMark;

对于扫描过程中得到的等价对节点，令nMakeValue1>nMakeValue2。假设指向保存有检测到的全部游程节点的指针为pRunLength，指向保存有当前行游程的指针为pCur，指向保存有前一行的游程的指针为pPre，指向保存有等价对链表的指针为pEqualMark，以及连通域标号用Label表示，初始值为1。则产生游程链表和等价表的步骤[23]如下：

1）从第一行开始，从上到下按行扫描，获得所在行的所有游程，并一一添加到 pCur指向的游程链表中，转向步骤2)，若pCur为空，转到3)执行；

2）将刚检测到的游程分别与pPre(上一行)指向的游程顺次进行连通性检查。如果当前游程与pPre指向的游程都不连通或者pPre为空，则赋予当前游程新标号；若当前游程与pPre中某一个游程连通，则直接将其游程标号赋予当前游程；若当前游程与pPre中不止一个游程连通，则将最小的标号赋给当前游程，并且记录下最小标号与其余标号作为等价对，并将之插入到等价对链表pEqualMark中；  
3）将pCur插入到pRunLength 指向的链表后面，同时将pCur 赋值给pPre，再将 pCur置为空；  
4）回到1)中继续下一行。  
这样，我们就得到了完整的游程等价对链表，其节点分别记录了同属于一个连通域的两  
个游程标号。下来修正游程的标号，使得相同连通域的游程标号统一。  
标号修正的过程[23]如下：  
1）设游程标号的最大值为max，定义-个大小为max $+ 1$ 的一维数组Equal，并初始化  
为0。为了处理的方便，使下标从1开始的数组元素与每个标号相对应；  
2）根据等价对链表中的节点数据，以nMakeValue1作为下标，nMakeValue2作为值填  
充到数组Equal中，若对某个节点，若有Equal[nMakeValue2]不为零，则以  
Equal[nMakeValue2]作为nMakeValue1，以此为下标继续递归，直到Equal[nMakeValue2]  
为零，停止递归，并填充数组当前下标的值；  
3）若对于标号i有Equal [i] $\scriptstyle = 0$ ，则表示没有比之更小的等价标号，其可以视为与之等  
价的标号所在的连通域的开始；如果Equal[i ${ > } 0$ ，则将当前Equal[i]的值作为下标，再  
去访问数组，此时数组中的值就作为它的标号。因此，从下标1开始扫描Equal数组一  
遍，对于值是零的元素，按从序号1开始的顺序分配标号；对于不为零的元素，直接以  
该值座位数组下标，访问到的对应元素值就是其新的标号，如此这样，到数组扫描结束，  
就能得到经过等价对合并以后的连通域的个数，即就是数组元素的最大值。

则整个白水印数字连通域提取算法步骤如下：

1） 根据OTSUI24]二值化白水印图像；  
2) 根据上述方法标记出连通域的个数；  
3） 根据连通域个数得到判假规则，用于鉴伪。

如下图所示分别为真、假币的白水印区域二值化图像：

OOT uoL

![](images/eec5b97f20af388c9b91f05a526591d46c3b5aca9befa8b7f7617ed69db58e2a.jpg)  
图3.15假币的白水印区域二值化图像

经过大量的实验统计，下表列出的是真假白水印二值图像连通区域数量对比：

表3.2真假白水印连通域个数比较  

<html><body><table><tr><td>类型</td><td>真币白水印</td><td>假币白水印</td></tr><tr><td>连通域个数</td><td><10</td><td>>22</td></tr></table></body></html>

可以清晰的发现，山于假币没有白水印数字，因此其二值化以后的连通域较多而且分散，且随机分布，没有规律性，与真币的有明显的区别。若以此作为特征，可用于鉴别真币和假币。

# 3.4实验结果分析

关于算法的性能评价指标，常用的评价指标l4是误辨率(MDR，mis-discrimination error rate)和漏辨率(UDR，un-discrimination error rate)。误辨率是指真币判断为假币的次 数与实际的真币走钞张数的比率。漏辨率是指未检测出的假币张数与实际的假币走钞张 数的比率。假设正确识别真币的次数为TP，真币识别为假币的次数为FP，正确识别假 币的次数为TN，而假币识别为真币的张数为FN。则有表达式：

$$
\begin{array} { c c c } { { M D R = \displaystyle \frac { T N } { T N + T P } } } \\ { { U D R = \displaystyle \frac { F P } { T N + F P } } } \end{array}
$$

而本文将采用误辨率和抓假率作为算法的评价指标。所谓抓假率就是正确识別的假币数占假币总数的比例，即1-UDR。个好的鉴伪算法，不仅要求抓假率高，同时其误辨率也要求很低。一般来讲，实时的点钞系统严格的要求误辨率至少达到千分级别。否则，再高的抓假率也没用。本文利用这两个指标，就可以更直观的看出算法性能的优劣。下表3.2是本文实验的结果：

表3.2算法性能对比  

<html><body><table><tr><td>算法</td><td>真币(张)</td><td>假币(张)</td><td>抓假率(%)</td><td>误辨率(%)</td></tr><tr><td>投影归一化积算法</td><td rowspan="3">2189</td><td rowspan="3">232</td><td>91.81</td><td>0.1827</td></tr><tr><td>八方向特征提取算法</td><td>85.77</td><td>0.3198</td></tr><tr><td>基于连通域个数的算法</td><td>82.04</td><td>0.3198</td></tr></table></body></html>

出表中可以看出，基于投影的归一化积算法抗干扰能力比较强，在控制低误辨率的情况下，依然能很好的实现抓假能力，八方向特征对图像的倾斜比较敏感，而基于连通域个数的算法对干扰和污渍比较敏感，在保证低误辨率的情况下对抓假性能有所牺牲，但总的来说，这三种算法的效果都比较理想。

# 3.5本章小结

本章详细阐述了白水印透射图像的处理方法，以及特征提取方法，介绍了传统的归一化积像素匹配方法，针对其事实性差的缺点，本文提出了一种改进的以投影差值匹配代替像素匹配的归一化积算法，取得了良好的实验效果。同时介绍了利用图像边缘信息的八向特征提取算法。针对白水印数字的特点，提出了一种以白水印二值图像中提取的连通域个数作为特征的鉴伪算法，同时给出了对算法性能的评价指标，并通过实验对比比较了这三种算法的算法性能，通过实验可以看到，提出的算法抓假的性能得到了保证，同时也满足系统实时性的要求。

# 4.变色油墨面额数字的特征提取和识别

由于光变油墨防伪技术25造假难度大，成本高，所以安全性很高，该技术已被成功应用于多个国家的纸币的防伪[26]。

# 4.1.图像的获取

第二章中最后图2.28中我们得到了变色油墨区域比较准确的左上角坐标。由于第二章处理的图像都是在获取的透射图的四分之一灰度图上得到的，故在原图上根据坐标映射可以得到变色油墨区域的坐标，并同时切割变色油墨数字的图像。如下图所示是在CMOS图像传感器MT9T001下采集到的真、假变色油墨区域的透射图。

![](images/bdc7780aac215af4d5a019d44f3800729d447f5ecee5d31d895e2efa281b40c0.jpg)  
图4.1真币变色油墨区域透射图像

![](images/4efa05c6d3366eebeb9c183a9c7308a082364ce2811a7ff2578272e3b8e12467.jpg)  
图4.2假币变色油墨区域透射图像

图4.1和图4.2分别给出了四张真、假变色油墨区域图像。从中可以看到，真币的变色油墨数字“100”的透射图像整体呈现红底“灰蓝色”，而假的变色油墨的透射图像整体呈现的却是红底绿色。出于一百元人民币整体票面偏红色，所以变色油墨区域图像背景偏红色。而真币的变色油墨垂直方向看呈绿色，倾斜一定角度呈蓝色，而假的变色油墨由于做不到变色这一点，不管什么角度观看都呈现绿色，这就是为什么采集的真、假变色油墨的前景色分别呈现不同颜色的原因。

我们把该变色油墨区域图像中变色油墨数字所在的区域称为前景，其所在的像素点为前景色点，其颜色对应为前景色，除去油墨数字之外其余部分称为背景，其所在的像素点代表背景色点，其颜色对应为背景色。由于干扰等各种原因，获取到的油墨图像中总会有一些像素点（尤其是前景色点和背景色点接壤的那些边缘像素点)颜色比较模糊，甚至当纸币走钞太倾斜时会导致获取到其他干扰像素或获取到不完整的油墨区域图像，称这些模糊或者干扰像素点称为过渡像素点。除去这部分像素点后，通过对该变色油墨图像区域变色油即前景色点和背景色点进行一个统计，然后根据一定的策略对变色油墨区域图像进行二值化，然后在同一色温下，分别对真币和假钞的变色油墨和背景像素之间的色差作为颜色特征，结合其他二维图像特征，通过选取训练样本结合最近邻算法得到判假规则，从而完成鉴伪功能。

# 4.2.变色油墨数字与背景的分离

首先我们通过对采集的大量变色油墨区域图像进行统计，得到过渡像素点占整个区域像素一定的比例（约为 $2 0 \%$ 左右)，该比率用 $K m$ 来表示。为了能够清楚的反映前景色（变色油墨数字的颜色）和背景之间颜色的差异，先假设前景色点和背景色点各自占总像素的比率是 $K f$ 和 $\kappa b$ ，从而有 $K m + K f + K b = 1$ 。

假设变色油墨区域图像是 $p \mathrm { I m } g$ ，宽是W，高是 $H$ ，然后在绿通道 $G$ 下得到图像的直方图，假设直方图是 Histogram[256]，设二值化后的图像是 $B u f 0$ 、Buf1，假设 $g _ { \mathrm { m a x } }$ 是前景色点（变色油墨数字，颜色较暗）所对应的最大灰度级， $g _ { \mathrm { m i n } }$ 是背景色点所对应的最小灰度级，当我们给出 $K f$ 和 $\kappa b$ 的经验值以后，分别根据如下的公式：

$$
\sum _ { i = 0 } ^ { g _ { \mathrm { m i n } } } H i s t o g r a m [ i ] \leq W \ast H \ast K f
$$

以及

$$
\sum _ { i \mathop { = } g _ { \mathrm { m a x } } } ^ { 2 5 5 } H i s t o g r a m \quad [ i ] \leq W \mathrm { ~ ^ * ~ } H \mathrm { ~ ^ * ~ } K b
$$

即可得到 $g _ { \mathrm { m a x } }$ 和 $g _ { \mathrm { m i n } }$ ，然后根据如下公式（4.1）对 $p \mathbf { I m } g$ 进行二值化：

$$
B u f 0 [ i ] = \left\{ \begin{array} { r l } { { 1 ~ , } } & { { G [ i ] < g _ { \mathrm { m i n } } } } \\ { { 0 ~ , } } & { { \sharp _ { \star } ^ { } \nmid \mathrm { t } _ { \star } ^ { } , } } \end{array} \right.
$$

结果保存到 $B u f 0$ 中，然后再根据如下公式（2）对 $p \operatorname { I m } g$ 进行二值化，结果保存到Buf1中：

$$
B u f 1 [ i ] = \left\{ { \begin{array} { r l } { 1 \ , } & { G [ i ] > g _ { \mathrm { m a x } } } \\ { 0 \ , } & { \sharp K { \rlap / { \ p t } \ } } \end{array} } _ { ; } \right.
$$

以上二值化的过程又称之为比例二值化，即二值化阈值的选取是由先前给定的比例决定的。这里要说明的是，虽然前景色点和背景色点的颜色的灰度级并没有明显的界限，甚至相互交叉，但是因为我们给定的比例 $K f$ 和 $K b$ 的和小于1，也就意味着中间一些交叉点或干扰点都作为过度像素点而被忽略，不作处理。这样，我们通过两次比例二值化，根据二值化的结果，就可以在原图上分离得到需要处理的前景图像和背景图像，以进行下一步的处理。

# 4.3.变色油墨数字特征提取

当前有很多有关变色油墨图像鉴伪的研究。不同的鉴伪方法提取的特征不同。其中，王明顺等人利用了变色油墨变色的机理。因为在同一光源不同的照射角度下，光变油墨数字的颜色存在明显的变化，通过分类算法将变色油墨数字本身和油墨所在区域的背景分开，分别得到R、G、B三维均值，然后再通过训练样本集和感知器算法得到判别函数，实现鉴伪的功能。王琦[28等人则利用色敏传感器获得真、假变色油墨的透视图像，根据得到的RGB分量的大小关系建立判别规则来判别真伪。

G.D.Finlayson [29][30]中提供了一种能够很好的去除图像中阴影的方法。在现实生活中，当我们拍照的时候，受到日光的直接照射的事物也会受到阳光的反射、散射等等多重光线的照射，在图片上会是很亮的一块区域，称为非阴影区域，而被遮挡住阳光的事物由于没有受到阳光的直接照射会形成阴影，在图像上这块区域就会很阴暗，称这块区域为阴影区域。这样非阴影区域和阴影区域就会有色差。假设现有坐标系 $\chi \gamma$ ，其中x=log(R/B)，y=log(G/B)。在该坐标系下，我们根据阴影区域和非阴影区域的颜色差异（色差）来得到并消除图像中的阴影。

本文也将利用这一思想来对变色油墨的真假进行判断。从图4.1和图4.2中可以看到，由于透射和反射等原因，加上票面主色偏红色，使得整个变色油墨区域图像偏红色。而且由于前景和背景的透射情况是不同的，这样前景和背景可以看成是受到不同的光照。对于前面得到的前景和背景的二值化图像，知道 $B u f 0 [ i ] = 1$ 表示在原图上 $p \mathbf { f m } g [ i ]$ 为前景点（即变色油墨数字本身的点）， $B u f 1 [ i ] = 1$ 表示在原图上 $p \operatorname { I m } g [ i ]$ 为背景图像点。我们分别得到前景点和背景点的RGB三个颜色分量的平均值，分别作为对其所在部分的像素值的总体估计。

按照前面的思想，对于本文的变色油墨区域图像和坐标系 $\ b { X Y }$ ，我们令$\scriptstyle x = \log ( R / B )$ ， $\scriptstyle y = \log ( G / B )$ 。对于同一幅图像，分别算出前景和背景像素的平均值 $\widehat { R _ { f } }$ 、$\overline { { G _ { f } } } \setminus \overline { { B _ { f } } }$ 以及 $\overline { { R _ { b } } } \setminus \overline { { G _ { b } } } \setminus \overline { { B _ { b } } }$ ，投影到坐标系 $X Y$ 上，得到对应的坐标 $A ( x _ { 1 } , \mathbf { y } _ { 1 } )$ 和 $B ( x _ { 2 } , y _ { 2 } )$ ，那么不同的变色油墨图像形成的线段 $A B$ 将都是平行的。

如下图4.3所示，每一条不带空心圆点的实线段代表的是从真币变色油墨所获取的点A、B对应的线段，而出空心圆点来表示的A、B连接起来的线段则是由假变色油墨得到的。而真币线段的方向实际上就代表了色温的方向。山于现实的情况对假设不是严格成立的，所以这些真币形成的线段也不是严格平行的。但是，我们可以对色温的方向进行一个很好的估计，使得真币样本的线段两端离色温线的距离矢量差的方差最小。

![](images/96e61de9270feb039e2014fc3d06c8f9361ca61ab903f528d858d87c85c1af12.jpg)  
图4.3真、假变色油墨形成的色温线AB

如图4.3所示，图中的虚线的方向就代表用我们最小二乘法估计的色温线的方向。

首先根据上--节的算法得到 $d _ { c o i o r }$ ，该距离作为要提取的特征的主成分。其次，我们发现真币变色油墨数字本身整体有些偏蓝色，而假币的“变色”油墨数字呈现绿色，因此，我们将变色油墨数字本身的B和G分量 $\widehat { B _ { f } }$ 、 $\overline { { G _ { f } } }$ 分别作为特征的另外两维，这样我们就得到了以色差为主成分的三维特征 $( d _ { \it c o i o r } , \overline { { B _ { f } } } , \overline { { G _ { f } } } )$ ，假设三维特征各自的权值分别为 $k _ { c o l o r } \mathrm { ~ , ~ } k _ { b } \mathrm { ~ , ~ } k _ { g }$ 。

那么对于同样的机器，其在正常工作情况下，我们可以假设得到的图像是在色温相对一致的情况下得到的，即色温线的方向是比较固定的。那么我们算出 $A$ 、 $B$ 两点到色温线的距离矢量差，得到的就是前景和背景在相同色温下的色差的大小。假设色温线的斜率是 $k _ { c o l e r }$ ，线段 $\boldsymbol { A B }$ 的斜率是 $k _ { . 4 B }$ ，其所在直线方程是 $y = k _ { _ { \perp B } } \cdot x + b ( \ b = y _ { 1 } - k _ { _ { \perp B } } \cdot x _ { 1 } \ )$ ，那么色差就是：

$$
d _ { c o l o r } = \frac { \left| y _ { 2 } - ( k _ { c o l o r } \cdot x _ { 2 } + b ) \right| } { \sqrt { ( 1 + k _ { c o l o r } \cdot k _ { c o l o r } ) } } = \frac { \left| ( y _ { 2 } - y _ { 1 } ) - k _ { c o l o r } \cdot ( x _ { 2 } - x _ { 1 } ) \right| } { \sqrt { ( 1 + k _ { c o l o r } \cdot k _ { c o l o r } ) } }
$$

接下来对提取的特征应用最近邻算法以判别变色油墨图像的真伪。选取一部分真币和假币样本，提取所有这些样本的三维矢量特征，生成一个包含真和假变色油墨特征的矢量库。通过改变这三维特征所对应的权值，算出样本与库中各矢量的带权值的欧氏距离 $d$ ，根据最近邻算法判断真假，其中 $d$ 计算如下：

$$
d = \sqrt { k _ { o l \alpha } * ( d _ { o l \alpha } - d _ { i } ) ^ { 2 } + k _ { b } * ( \overline { { { B _ { f } } } } - \overline { { { B } } } _ { i } ) ^ { 2 } + k _ { g } * ( \overline { { { G _ { f } } } } - \overline { { { G } } } _ { i } ) ^ { 2 } }
$$

其中 $( d _ { c o l o r } , \overline { { B _ { f } } } , \overline { { G _ { f } } } )$ 即表示从当前图像提取特征形成的三维特征， $( d _ { i } , \overline { { B _ { i } } } , \overline { { G _ { i } } } )$ 表示特征库中所含的每一个特征矢量。

# 4.4.变色油墨特征识别判定真假

得到变色油墨的三维特征以后，接下来就是分类器的选择。本文主要选用最近邻分类器(KNN)和感知器神经网络作为分类器来分出真伪。

# 4.4.1.K最近邻分类器(KNN)真假分类

随机选择该机型的某台机器，我们采集真币变色油墨图像和变色油墨为假的假币该区域图像，从中选取一部分作为训练样本集。先选定特征各分量的权值后，接下来，利用最近邻算法对真币样本和假币样本分别进行训练，确定权值后，对试验样本进行测试，最终试验结果如下表4.1所示（只列出最优的三组实验结果）：

表4.1不同权值向量下的实验结果  

<html><body><table><tr><td>权值向量</td><td>真币训 练样本 （张）</td><td>假币训 练样本 （张）</td><td>真币 （张）</td><td>假币 (张)</td><td>抓假 (张）</td><td>误报 （张）</td><td>抓假 率(%)</td><td>误辨率 (%)</td></tr><tr><td rowspan="2">(0.8,0.1,0.1)</td><td>70</td><td>10</td><td>1300</td><td>45</td><td>30</td><td>1</td><td>66.7</td><td>0.00076</td></tr><tr><td>321</td><td>25</td><td>3000</td><td>125</td><td>92</td><td>1</td><td>73.6</td><td>0.00033</td></tr><tr><td rowspan="2">(0.7,0.15,0.15)</td><td>70</td><td>10</td><td>1300</td><td>45</td><td>34</td><td>0</td><td>75.6</td><td>0.0</td></tr><tr><td>321</td><td>25</td><td>3000</td><td>125</td><td>102</td><td>1</td><td>82.2</td><td>0.00033</td></tr><tr><td rowspan="2">(0.6,0.2,0.2)</td><td>70</td><td>10</td><td>1300</td><td>45</td><td>31</td><td>2</td><td>68.8</td><td>0.00154</td></tr><tr><td>321</td><td>25</td><td>3000</td><td>125</td><td>90</td><td>1</td><td>72.0</td><td>0.00033</td></tr></table></body></html>

# 4.4.2.感知器神经网络

感知器是采用阈值激活函数的前向型神经网络，可以通过对网络权值的训练，使得感知器对外部输入矢量进行识别分类。单层感知器可以对输入矢量完成二类自标输出。下面先简单介绍一下单层感知器神经网络[31][32]。1.图4.4为单层感知器神经元模型。

![](images/1ff5f00e8371862d3eff108f36f64a401d8095535e883a6f0ce1867f1ef432cf.jpg)  
图4.4单层感知器神经元模型

它包括一个线性累加器和二值阀值元件，此处出激活函数 $f$ 实现，同时还有一个外部偏置 $\theta$ 。图中符号的关系如下公式所示：

$$
\begin{array} { l } { \displaystyle a = \sum _ { i = 1 } ^ { r } \omega _ { i } \ d x _ { i } } \\ { \displaystyle y = \ d f ( a + \theta ) } \end{array}
$$

单层感知器的激活函数是符号函数，其定义如卜：

$$
y = \operatorname { s g n } ( x ) = { \Biggl \{ } _ { + 1 , ~ x \geq 0 } ^ { - 1 , ~ x < 0 }
$$

因此有：

$$
y = \left\{ \begin{array} { l l } { - 1 , \mathrm { ~ } ( \displaystyle \sum _ { i = 1 } ^ { r } \omega _ { i } x _ { i } + \theta ) < 0 } \\ { + 1 , \mathrm { ~ } ( \displaystyle \sum _ { i = 1 } ^ { r } \omega _ { i } x _ { i } + \theta ) \geq 0 } \end{array} \right.
$$

假设输入矢量是 $\mathfrak { n }$ 维的向量 $X = ( x _ { 1 } . x _ { 2 } . x _ { 3 } . . . . x _ { n } ) ^ { T }$ ，则这 $\mathfrak { n }$ 个输入分量在几何上就构成了一个n维空间，则节点 $\mathrm { j }$ 的输出为：

$$
O u t p u t _ { j } = \left\{ \begin{array} { l l } { - 1 , \ w _ { _ { 1 j } } x _ { _ { 1 } } + w _ { _ { 2 j } } x _ { _ { 2 } } + w _ { _ { 3 j } } x _ { _ { 3 } } + . . . w _ { _ { n j } } x _ { _ { n } } + \theta _ { _ { j } } < 0 } \\ { + 1 , \ w _ { _ { 1 j } } x _ { _ { 1 } } + w _ { _ { 2 j } } x _ { _ { 2 } } + w _ { _ { 3 j } } x _ { _ { 3 } } + . . . w _ { _ { n j } } x _ { _ { n } } + \theta _ { _ { j } } \geq 0 } \end{array} \right.
$$

并且由方程

$$
w _ { 1 j } x _ { 1 } + w _ { 2 j } x _ { 2 } + w _ { 3 j } x _ { 3 } + . . . w _ { n j } x _ { n } + \theta _ { j } = 0
$$

定义了一个能将输入样本分成两类的 $\mathfrak { n }$ 维空间上的超平面。

2.单层感知器学习算法

单层感知器学习算法是基于迭代的思想的学习算法，通常采用纠错学习规则。

为了方便数学上的描述，将外部偏置 $\theta$ 也作为感知器神经元权值向量的最后一个分量，并且将输入向量的最后一个分量固定为1，这样就可以得到两个增广矩阵分别如下所示：

$$
X \left( m \right) = \left[ x _ { m ! } , x _ { m 2 } , x _ { m 3 } , . . . x _ { m n } , + 1 \right] ^ { T }
$$

$$
\boldsymbol { W } ( m ) = [ w _ { m 1 } , w _ { m 2 } , w _ { m 3 } , . . . w _ { m n } , \theta _ { m } ] ^ { T }
$$

其中，变量 $\mathfrak { n }$ 表示输入特征维数， $\mathbf { m }$ 表示迭代次数，从而可以改写(5)式如下：

$$
\begin{array} { r } { a = \displaystyle \sum _ { i = 1 } ^ { n } \omega _ { i } ( m ) x _ { i } ( m ) = W ^ { T } ( m ) X ( m ) = W ^ { T } X } \end{array}
$$

单层感知器的纠错学习规则，实际上也就是权值调整的过程，步骤如下：

1）初始化所有权值 $w _ { m 1 } , w _ { m 2 } , w _ { m 3 } , . . . w _ { m n }$ 为较小的非零随机数;  
2）设训练样本输入向量为 $X ^ { j }$ ，训练样本对应的期望输出结果为 $\mathtt { e x p ( j ) } ( 0$ 或1);  
3）计算该训练样本的实际输出值： $O u t p u t _ { j } = s g n ( \boldsymbol { W } ^ { T } ( j ) X ( j ) )$ ;  
4）调整个节点对应的权值， $W ( j + 1 ) = W ( j ) + \eta ( \exp ( j ) - O u t p u t _ { j } ) X ( j )$ ，这其中包括了对外部偏置 $\theta _ { j }$ 的调整;  
5）回到步骤(2)，输入下一组训练样本和期望输出。  
当所有样本的实际输出与期望输出相等时，感知器学习结束。

# 3．单层感知器训练

感知器进行训练的步骤如下：

1）确定输入矢量P，期望输出T，并由此确定矢量的维数和神经网络的结构；  
2）网络参数初始化，包括给初始权值向量赋予较小的非0初始值W，最大的迭代次数  
max_epoch，误差设定值err_goal等等；  
3）根据P和当前的矢量W，计算输出矢量V；  
4）检查V是否等于T,若等于或者迭代次数大于max_epoch，则训练结束，否则转向(2);  
5）根据纠错学习规则调整权值向量，返回3)继续迭代。

# 4.4.3.基于感知器神经网络的真假分类

由于纸币的真假鉴别是一个两类分类问题，针对上一节提取的 $( d _ { c o l o r } , \overline { { B _ { f } } } , \overline { { G _ { f } } } )$ 特征,我们知道，真假纸币的变色油墨特征是分布于三维特征空间中的两个不同的区域。为了将两类特征识别开来，需要构造一个三维平面将其分开，针对这一两类分类问题，在此选用上一节介绍的单层感知器神经网络，在对其进行训练过后，得到鉴伪规则[30]。

设样本特征值为 $X _ { i } = [ x _ { 1 i } x _ { 2 i } x _ { 3 i } ] ^ { T } , x _ { 1 i } \mathrm { ~ , ~ } x _ { 2 i }$ 和 $x _ { 3 i }$ 分别为 $\overline { { B _ { f } } }$ 分量、 $\overline { { G _ { f } } }$ 分量和 $d _ { c o l o r }$ 分量。设 $V _ { 1 }$ 为真币样本类特征所在区域， $V _ { 2 }$ 为假币样本类特征所在区域。接下来的任务就是寻找一个三维平面将 $V _ { 1 }$ 和 $V _ { 2 }$ 分开，假设该三维分割平面数学表达式如下：

$$
S e g \dot { P l } a n e ( X ) = w _ { 1 } x _ { 1 } + w _ { 2 } x _ { 2 } + w _ { 3 } x _ { 3 } + w _ { 4 }
$$

对于真币样本点 $X _ { i } \in V _ { 1 }$ ，有 $S e g P l a n e ( X _ { i } ) \geq 0$ ，对于假币样本点 $X _ { i } \in V _ { 2 }$ ，有$S e g P l a n e ( X _ { i } ) < 0$ 。

现选取真币样本320幅，假币样本37幅，得到相应的特征。如图4.5所示为真假样本特征的三维散点图，其中空心圆点代表的是假币特征点，十字形代表的是真币样本特征点。

![](images/c1405dad62302e9665c16577ab10c5192ee5f66f3c34f41ea2b4b7f1a52628bf.jpg)  
图4.5真假币三维特征散点图

设计一个单层感知器，包含三个输入 $( x _ { 1 } , x _ { 2 } , x _ { 3 } )$ ，输出为y，f为符号函数， $( x _ { 1 } , x _ { 2 } , x _ { 3 } , 1 )$ 和 $\left( w _ { 1 } \ w _ { 2 } \ w _ { 3 } \ w _ { 4 } \right)$ 分别为输入和网络权值增广矩阵。

![](images/9ce932234a820d6fd44b223c5ab89f1fbce00ded09d15823245e85c0fca3be6b.jpg)  
图4.6单层三输入单输出的感知器网络

针对一共357个输入样本和相应的期望输出，设置最大迭代次数max_epoch为999，对单层感知器进行训练后，得到了如下图4.7所示的分类平面，其对训练样本的分类效果如图所示。

![](images/3000ff6435647350cb53a23cdbb561109955f1e89bf614377a803eeec7828ff1.jpg)  
图4.7训练后得到的分类平面和分类效果图

另外，程序输出结果如下：

迭代次数：612次，网络权值：0.20330.8620-2.3183 b-0.9617468

表4.2感知器神经网络的参数及其鉴伪效果  

<html><body><table><tr><td>权值向量 (w，W2W3W4）</td><td>真币训 练样本 （张）</td><td>假币训 练样本 （张）</td><td>真币 （张）</td><td>假币 （张）</td><td>抓假 （张）</td><td>误报 （张）</td><td>抓假 率(%)</td><td>误辨率 (%)</td></tr><tr><td>(0.2033,0.8620. -2.3183,0.9617)</td><td>320</td><td>37</td><td>3000</td><td>170</td><td>121</td><td>2</td><td>71.2</td><td>0.00066</td></tr><tr><td>(0.1958, 0.8443. -2.2675, 1.3718)</td><td>1300</td><td>75</td><td>3000</td><td>170</td><td>144</td><td>2</td><td>86.7</td><td>0.00066</td></tr></table></body></html>

比较表4.1和表4.2，可以看出，当训练样本足够多的时候，单层感知器算法的分类效果要优于最近邻算法的效果。并且随着训练样本的增多，感知器算法的分类效果会得到明显的改善。考虑到在实际应用系统中真币的误辨率是有严格限制的，所以在训练的时候，对假币的训练样本选取上就已经做出了一部分牺牲，所以不可能将所有的假币都识别出来[3IJI2]，但本文的算法已满足实际的应用需要。

# 4.5.本章小结

本章详细阐述了变色油墨透射图像的特征提取方法，引入了色温与色差的概念，以色差作为特征的一部分，并通过实验对比比较了最近邻算法和感知器神经网络，得出最近邻算法在本实验中的优势，而且，通过实际在机器上的测试，抓假的性能得到了保证，同时也满足系统实时性的要求。

# 5.人民币纸币红外图像鉴伪方法

随着科技的发展，制造假币的技术和手段也越来越先进，为了不让假币流入市场，要求我们在检伪方面要有多种手段以检测出假币。同时，国家对金融机具应具备的鉴伪能力和手段也提出了新的更高的要求。鉴于此，本文还提出了一种红外图像鉴伪的方法。

传统的红外防伪是指利用红外接收传感器检测纸币的红外反射和透射特性。假币由于在纸张和印刷油墨方面与真币都存在差异，所以在红外反射和透射上与真币的反应也会不一样。但是，由于高端信息技术和印刷技术的快速发展，传统的假币检测方法就难以应对这些技术含量高的假币了。而利用图像鉴伪作为一种新型的防伪技术，越来越受到重视，而且也是大势所趋。本文采用的红外防伪方法是指利用CIS红外光下采集到的红外图像[36][37]。针对红外图像的特点，运用图像处理和模式识别的方法，提取特征并加以匹配识别，从而达到防伪的自的，其效果好，而且稳定。

以下分别是人民币100元纸币05版和99版的红外图像。

![](images/4782aa97b452127f26b7ec3cb5d6b1480d011a55ffb51536d3d5305d9048b3af.jpg)  
图5.1100元人民币05版（左）和99版（右）的正反双面红外图像

# 5.1.红外图像边缘检测

边缘检测的目的就是为了进行图像定位，所谓图像定位就是在原始图像中确定出目标图像的位置。如上图5.1所示，纸币本身是一个标准的矩形，所以，在没有发生严重扭曲的情况下，我们也可以认为纸币的图像是矩形的，这也就意味着纸币的水平和垂直边是近似两两平行的。而且本系统采集的纸币图像和背景区域的灰度值差异非常明显，所以要检测出纸币图像的边缘并非难事，关键是速度要快。下面介绍一种纸巾边缘点检测算法和利用最小二乘法[38拟合纸币边缘所在的直线，并进而求出纸币四个角点的坐标的方法。

# 1.边缘点检测

如图5.1所示，本系统采集的纸币正反面图像(包括黑色背景)是一样大的，只不过上下两幅图像是拼在起的，假设采集的纸币单面图像的宽度和高度分别为W和H(即W是图中宽度，而H正好是图中高度的一半)。本文针对实时性系统对速度的要求，采用间隔搜索拟合边缘的检测方式，可以大幅减少定位边缘的时间。设循环检测边缘点的间隔步长是step，检测到边缘点的像素值阈值为thres。同时，现实生活中，因为纸币往往存在折角或角点位置残破的问题，会导致检测的边缘点不能近似在一条直线上，从而导致拟合的直线不准确，与实际边缘偏差较大。为了尽可能的规避这个问题和提高对此类问题适应性的要求，在边缘点检测时，水平方向和垂直方向都采取从纸币图像的中间位置扫描，还可以根据纸币图像相对边平行的特点降低误差，最终得到的边缘点保存在坐标数组Edge[n]中，具体检测方法如图5.2所示，对于上侧水平边的边缘点检测步骤如下：

![](images/8cc1ed66b3d923e00a12a83f2926bbcb7b143f7da8ee664a8d68559d6c17c75e.jpg)  
图5.2纸币四条边缘线上的的边缘点检测示意图

1）确定水平方向范围。图像中点的横坐标是W/2，向两边放人 $\delta _ { \mathrm { { _ x } } }$ 的横向范围，则得到横向扫描范闱为 $[ \frac { \mathcal { H ^ { ' } } } { 2 } - \delta _ { x } , \frac { \mathcal { W ^ { ' } } } { 2 } + \delta _ { x } ]$ ，初始令 $x = \frac { { \cal W } } { 2 } - \delta _ { x }$

2）固定当前 $\mathrm { ~ x ~ }$ 的值， $\boldsymbol { \underline { { y } } } \boldsymbol { : } = 0$ 开始从上到下递增，依次检测当前位置像素值，若大于阈值thres，则可以认为是边缘像素点，记为 $( x , y )$ ，保存到Edge数组中：

3）横向坐标按照步长 step 递增到 $\mathrm { x } + \mathrm { s t e p }$ 荐 $x \leq \frac { W } { 2 } + \delta _ { x }$ ，回到步骤(2)，如果 $x > \frac { | \mathbf { f } ^ { \prime } } { 2 } + \dot { \mathcal { O } _ { x } }$ ，则结束扫描：4）按照同样的方法，在 $[ \frac { W } { 2 } - \delta _ { x } . \frac { { \cal { W } } ^ { \prime } } { 2 } + \delta _ { x } ]$ 横向范用内，下边沿采取从下到上的扫描，得到边缘点数组；在 $[ \frac { H } { 2 } - \delta _ { _ { ! } } , \frac { H } { 2 } + \delta _ { _ { ! } } ]$ 纵向范围内，左边垂直边缘点采取×从左到石的扫描方式，右边垂直边缘点采取y从石往左的扫描方式，最终每条边得到一个边缘点数组。

# 2.最小二乘法拟合边缘直线

接下来，本文根据得到的四个边缘点坐标的数组，采用最小二乘法拟合出四条边缘直线。假设 $k$ 为拟合后的斜率， $b$ 为拟合后的截距， $k$ 和 $b$ 为未知数。则最小二乘法的回归方程如下：

$$
y = k ^ { * } x + b
$$

其残差的平方和为 $\Delta S$ ，则

$$
\Delta S = \sum _ { i = 1 } ^ { n } \left( y _ { i } - k ^ { * } x _ { i } - b \right) ^ { 2 }
$$

为了使 $\Delta S$ 最小，对式(5.2）对 $k$ 和 $b$ 分别求偏微分，再分别令偏微分为零，联立得到方程组，从而解出 $k$ 和 $b$ ，如公式（5.3）和（5.4）所示：

$$
\left\{ \begin{array} { l l } { \displaystyle { \frac { \partial ^ { 2 } S } { \partial k } } = - 2 \sum _ { i = 1 } ^ { n } \left( y _ { i } - k x _ { i } - b \right) \cdot x _ { i } = 0 } \\ { \displaystyle { \frac { \partial ^ { 2 } S } { \partial b } } = - 2 \sum _ { i = 1 } ^ { n } \left( y _ { i } - k x _ { i } - b \right) = 0 } \end{array} \right.
$$

$$
\left\{ k = { \frac { \displaystyle \sum _ { i = 1 } ^ { n } ( x _ { i } - { \overline { { X } } } ) ( y _ { i } - { \overline { { Y } } } ) } { \displaystyle \sum _ { i = 1 } ^ { n } ( x _ { i } - { \overline { { X } } } ) ^ { 2 } } } \right.
$$

根据坐标数组中保存的样本点，代入式(5.4）求出 $k$ 和 $b$ 。

下图5.3是最小二乘法拟合出的四条边缘直线(图中红线表示)，四条边缘上小的十字架是指扫描到的边缘点。

![](images/6f6bea1d0605bf88508da812adb8143858674f7842ce18acdd2b426cc0877e64.jpg)  
图5.3最小二乘法拟合得到的四条边缘线

得到四条边所在的直线方程之后，根据直线两两相交，可以得到纸币的四个角点坐标，如图中A、B、C、D所示的位置。根据第二章2.2节中结构体tagCenterAngle的定义以及利用式(2.2），得到当前该图像的相关信息，保存在结构体中，为后续对特征图像的处理提供了便利。

# 5.2.纸币基本信息的获取

纸币的基本信息包括纸币的面额、进钞方向和版本。获取到准确的纸币基本信息是后期图像鉴伪和其他处理的最基本保证。不同而额、不同版本的纸币的鉴伪特征是不一样的，不同的进钞方向也会导致在特征区域切割的时候出现问题。所以，判定鉴伪特征的有效性和保证鉴伪的识别率的前提就是保证获取到精确的基本信息。

# 1.纸币面额的获取

本文根据纸币图像的宽度来判别纸币的面额。文献[39]提出了一种利用神经网络作为分类器的一种快速面额识别算法，文献[40]提出了种SIFT角点匹配算法用于识别面额。本文中，由于人民币每一种面额的大小是不一样的，宽度也不一样，故而其图像的宽度也是不一样的。

文献[41]中提出了一种宽度计算方法。它是利用 $( \mathsf { A C } \cdot \mathsf { B D } ) / 2$ 作为图像的宽度。本文提出一种更准确的纸币宽度计算方法。如图5.2中所示，垂直边扫描时，假设左右两边的坐标数组分别为Edge_Left,，Edge_Right，边缘点的个数是Line_n2，则这两个数组的每个坐标点纵坐标是相同的，而横坐标是一一对应的，一个代表左边缘，一个代表右边缘。设宽度用width表示，则有：

$$
w i d t h = ( [ \sum _ { \iota = 0 } ^ { L m e } ( E d g e \_ R i g h t [ i ] . x - E d g e \_ l e f t [ i ] . x ) ] / L i n e \_ n 2 ) ^ { * } \cos \alpha
$$

其中 $\alpha$ 为图像水平方向倾斜角，括号中得到的平均长度是纸币左右边缘在水平方向的距离，最终的宽度width就是宽度。通过对大量图像的宽度统计就可以得到不同面额的纸币宽度的阈值，从而判别出面额。

# 2.纸币进钞方向的判定

从图5.1中可以看出99版和05版一百元纸币红外图像在角点附近的图像特征。正反面共计8个角点，这八个角点只有冠字号码和变色油墨所在区域的角点是有红外反应的，而不管纸币以何种姿态走钞，这块区域只可能出现在上图的左下角、右上角、下图的左下角和右上角位置，所以我们只要固定的截取出这四块区域，而一旦从这四块区域中找到这块区域，根据相关位置的逻辑关系就能立马得到纸币的方向。利用2.2节中公式(2.17)，直接得到这四块区域，然后利用水平方向的投影，根据投影的最大差值，就能定位到冠字号码，从而得到方向信息，如下图5.4所示。

0733 OOL

![](images/9fa7de9152a8a60fdfdd3669eaeb5e48f00745259137de0c868646b941e301b7.jpg)

![](images/edc8bba25aa1c3c48ad35496324fc187cb2575dd2c0ce0454d90995f1ce15499.jpg)

图5.4四个角上截取的相关区域及其投影差值

3.纸币版本的判定

版本的判定有多种方法，根据第二章2.5.2节的描述和图2.4.4，这里直接利用纸币方向判断中切割下的图像。如图5.4所示，含有冠字号码的区域图像也含有变色油墨，根据变色油墨的位置(靠左还是靠右)结合纸币的方向，就能得到纸币的版本了，其处理过程可参考2.5.5节中所述，其效果图如下图所示：

![](images/88054a0044248f3b9a01649c6cb9563c95e5b0988d4cbbc577e47899e0d6085c.jpg)  
图5.505版和99版的变色油墨位置关系图

还可以根据冠字号码的长度来判别版本。05版纸币的冠字号码前四位在红外下是没有反应的，而99版的冠字号码是全都有反应的，如下图所示，可以对冠字号码图像进行最小值滤波，然后垂直投影，可以投影的最大最小值得到号码首位的位置，即可求出长度，大于给定的长度阈值(由实验统计得到)就是99版，否则为05版。

![](images/496c0d67dfa15a55b26077bbf1bbade653b9056b7b06cc148b36cf8b584c12da.jpg)  
图5.605版和99版冠字号码长度比较

# 5.3.红外图像特征

由于纸币的红外防伪一般作为国家机密，不会轻易的公开。但是，通过对大量的人民币真币和假币的红外图像进行对比和分析，会找到一些比较理想和稳定的防伪特征，用于鉴伪。下面先看看真币和常见的一些假币的红外图像，然后根据每一种假币类型提出相应的图像鉴伪算法。

![](images/f6159c4dc549f599cb0aaec7655feeafd02f55fd9537870e6300c488e7d8a2e8.jpg)  
图5.72005版人民币左半部分真币(左一）与假币对比图

![](images/a7945c326206df8395cc7d5830a7950dbbba239f286c4037ec2c5dbb90565149.jpg)  
图5.805版红外图像背面和安全线假的图像  
图5.905版红外图像假的图像

由图5.7和5.8所示，展示的是05版假币的几种常见情况。图5.7中中间的假币红外图像上左下角缺少变色油墨，，右边的假币除了变色油墨不清晰以外，还出现了真币红外图所没有的国徽图案和“中国”等字和图案，还包括许多小圆点。图5.8展示的是背面缺少人民大会堂的图案(参考图5.1)，并且红外光下背面安全线是开窗式的，不是连续的，并且该图中安全线的宽度也比真币的宽度较大。而图5.9展示的就是整个票面几乎都有红外反应的全假纸币图像。这种假币的代表就是曾经轰动全国的冠字号码以“HD90”打头的假币。还有常见的假币是变造币。接下来本文给出一些常见的假币图像，它们就是99版和05版两个不同版本的纸币拼造、挖补出来的变造币红外图像：

![](images/ea60891f944ba563078b20e73933a5aeb3f130382256eab6961526aa2776837d.jpg)  
图5.10部分变造币红外图像

从以上的假币红外图像的图像上可以总结归纳出假币的最大的特征。第一，在不应该有红外反应的区域会有红外反应；第二，在某些有红外反应的区域反而又缺少相应的红外反应。这就是假币在红外图像上表现出来的一大特点，即使它在可见光下跟真币非常的一致。这些图像特征都可以为我们所用，用以防伪鉴伪的用途。

# 5.4.红外特征鉴别方法

传统的纸币图像鉴伪算法在提取灰度特征的时候，主要利用的是均值和方差特征。但是这些特征却存在着很大的问题。首先，在实际应用中，不同CIS图像传感器以及不同新旧程度、含污渍和磨损的纸币在灰度方面存在着很大的差异，所以在计算均值和方差的时候，无法给定一个统一的阈值去适应所有这些情况，如文献[42]、[43]，阈值的选取是个很大的问题。其次，这些灰度特征的区分能力与特征区域选取的合适程度相关性很大。从下面红外图像可以看到，真、假币的不同之处，主要表现在相应的区域是否有或无红外反应，也就是是否有无前景图案。当前景图案比较明显时，其统计特征能够彰显出真、假币之间的差异；但是当前景图案面积较小时或不明显时，其统计特征不能充分的显示出假币之间的差异，从而出现漏抓和误报的情况。

为了解决以上问题，本文提出了一种基于相邻区域对比式策略的灰度信息特征提取算法。针对上一节列出的假币及其图像特征，根据归纳的特点，我们使用相邻区域对比式灰度信息特征提取算法来完成鉴伪工作。

方法一：利用二值化后灰度均值的差作为特征来鉴别真假币。

1）根据公式(2.17)，得到待鉴别图像pImg，大小为 $\mathrm { w ^ { * } H }$   
2）根据公式(4.1)和式(4.3)，对待鉴别图像进行比例二值化，得到如下二值化图像，设二值化图像为pBImg;

3）根据二值化的结果，分别统计目标像素的均值和背景区域的像素均值，分别记为Ave1和Ave2，

$$
\left\{ \begin{array} { l l } { \displaystyle { d \nu e 1 = \sum _ { i = 0 } ^ { \nu * _ { H - 1 } } p \mathrm { I m } g [ i ] , } } & { \quad \displaystyle { p B \mathrm { I m } g [ i ] = 0 } } \\ { \displaystyle { A \nu e 2 = \sum _ { i = 0 } ^ { \nu * _ { H - 1 } } p \mathrm { I m } g [ i ] , } } & { \quad \displaystyle { p B \mathrm { I m } g [ i ] = 2 5 5 } } \end{array} \right.
$$

$$
\left\{ \begin{array} { l } { A \nu e 1 = A \nu e 1 / N } \\ { A \nu e 2 = A \nu e 2 / ( W ^ { * } H - N ) } \end{array} \right.
$$

则我们选取两者之差作为特征：

$$
F e a t u r e = A \nu e 2 - A \nu e 1
$$

4）对大量的真币进行统计，得到一个阈值。将得到的Feature与事先指定的阈值(对大量真币的Feature的一个统计数据得到的数值)相比较，没有变色油墨反应的纸币差值会很小，可以判断小于阈值的就是假币。

以变色油墨区域图像为例，得到变色油墨区域图像pImg，大小为 $\mathrm { W ^ { * } H }$ ，左边一幅为真币变色油墨，其余为假币；

100 100

对上图进行比例二值化，得到结果如下图所示：

![](images/877249330c53cfe0d23edf2715cfe869af861d3ec67877ac894b1dbeea852257.jpg)  
图5.11变色油墨区域图像真假对比图  
图5.12比例二值化后的变色油墨二值化图像

100

分别计算出变色油墨数字的像素均值和白色背景像素的均值，得到结果如下表5.1所示：

表5.1变色油墨阈值选取实验结果  

<html><body><table><tr><td rowspan="2">纸币类型</td><td rowspan="2">真币</td><td colspan="2">假币</td></tr><tr><td>反应模糊</td><td>无反应</td></tr><tr><td>Feature取值范围</td><td>51-84</td><td>17-38</td><td>-7-9</td></tr><tr><td>阈值</td><td></td><td>Threshold=46</td><td></td></tr></table></body></html>

方法二：直接利用邻近区域灰度均值的差作为特征来鉴别真假币。

1）分别切割下目标检测区域图像若干块和其邻近的背景区域图像若干块；   
2）分别求出各区域的灰度均值，让目标区域图像的灰度均值与背景区域的图像灰

度均值作差，得到差值

3）与事先确定的相关阈值作比较，判断真假。

下面以99版100元正面右侧的毛主席头发区域和衣领区域为例，下图是毛主席头像区域的红外大图像，如图所示：

![](images/210b2605ce355ebbd812967552fe95e3682202a7c899a081613ab2d85ebbd10c.jpg)  
图5.1305版（左）和99版（右）毛主席头像区域图像

根据公式(2.17)，得到毛主席头发区域和衣领和背景区域图像；

![](images/9a8031a476c54026cc46367a1a349ab8b62babafde7f3f5c4abc78eb14ec24b9.jpg)  
图5.13真币的毛主席头发、衣领和附近背景区域图像

假设灰度平均值分别为HeadAve、CollarAve、BackgAve，用区域的灰度的相对差值作为特征，如下所示：

$$
\begin{array} { r l } & { F e a t u r e \_ H e a d = B a c k g A \nu e - H e a d A \nu e } \\ & { F e a t u r e \_ c o l l a r = B a c k g A \nu e - C o l l a r A \nu e } \end{array}
$$

下表所示为本文中给出的假币和变造币类型，即针对20005版100元有反应的假币类型(如图5.9、5.10所示)，同时，也给出了针对1999版无反应的假币类型的实验结果。

表5.2特征图像阈值选取实验结果  

<html><body><table><tr><td>版别</td><td>特征项</td><td>真币</td><td>假币</td><td>阈值</td></tr><tr><td rowspan="2">2005版</td><td>Feature_Head取值范围</td><td>-6-8</td><td>19-44</td><td>13</td></tr><tr><td>Feature_collar取值范围</td><td>-4-5</td><td>24-38</td><td>16</td></tr><tr><td rowspan="2">1999版</td><td>Feature_Head取值范围</td><td>16-37</td><td>-12-5</td><td>10</td></tr><tr><td>Feature_collar取值范围</td><td>19-41</td><td>-2-9</td><td>13</td></tr></table></body></html>

根据同样的原理，我们对国徽区域、背面大会堂区域和背面大写的数字100采用相同的处理，最终得到的实验结果如下表所示(99版假币样本比较少，在此不单独列出)，其中如图5.1所示，国徽、“背面 $1 0 0 ^ { \prime \prime } .$ 、头发和衣领都是05版人民币红外图像上不应该有的红外反应区域，在此作为鉴伪特征的作用是：当检测到这些区域有红外反应时，作为假币对待；而对于变色油墨和大会堂区域，则检测到这些区域若无红外反应时，判定为假币。

表5.3相邻区域对比式灰度信息特征提取算法实验结果  

<html><body><table><tr><td>版别</td><td>特征提取 算法</td><td>鉴伪特 征</td><td>真币样本数 （张）</td><td>假币样本数 （张）</td><td>抓假率 (%)</td><td>误辨率 (%)</td><td>最终结 论</td></tr><tr><td rowspan="6">05版</td><td rowspan="6">方法一</td><td>变色油</td><td rowspan="7">3056</td><td>212</td><td>94.35</td><td>0.000</td><td>采用</td></tr><tr><td>墨</td><td></td><td>86.206</td><td>0.000</td><td>不采用</td></tr><tr><td>国徽 大会堂</td><td>232 64</td><td>84.375</td><td>0.0436</td><td>不采用</td></tr><tr><td>背面</td><td></td><td></td><td></td><td></td></tr><tr><td rowspan="3">国徽</td><td>100</td><td>73.000 93.113</td><td>0.000 0.000</td><td>采用</td></tr><tr><td></td><td>232</td><td></td><td>采用 采用</td></tr><tr><td>大会堂 头发</td><td>64</td><td>87.500</td><td>0.0436</td></tr><tr><td colspan="3">衣领</td><td></td><td>100 100</td><td>87.000 82.000</td><td>0.000 0.0436</td><td>采用 采用</td></tr><tr><td colspan="3">总计</td><td>3056</td><td>363</td><td>91.387</td><td>0.0982</td><td></td></tr></table></body></html>

由表中结果可知，当对变色油墨和背面100特征采用第一种算法时，对国徽、大会堂、头发和衣领等图像特征采用第二种算法时，综合的抓假率达到了 $9 1 . 3 8 7 \%$ 。

# 5.5.红外安全线鉴伪

传统的针对安全线的鉴伪主要是指通过检测安全线的磁信号。本文现提出一种根据安全线的宽度和投影值作为红外图像特征，来达到鉴伪的目的。如图5.8和5.10所示其安全线宽度投影明显异于真币。

首先需要检测人民币的安全线是否存在及其位置信息。假设当前图像为pImg，大小为 $\mathtt { W } ^ { * } \mathtt { H }$ ，横向从中间位置W/2向两边各放大 $\delta _ { x }$ ，纵向从中间位置 $\mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi } \mathrm { \Pi }$ 向两边各放大$\delta _ { y }$ ，投影数组为projH，则检测安全线的步骤如下：

1）得到横向扫描范围：x-+ ，为方便表述，另外令起始和终止点分别为sx、ex，同样可以得到，投影从上到下的范围是： $y \in [ \frac { H } { 2 } - \delta _ { y } , \frac { H } { 2 } + \delta _ { y } ]$ $2 \delta _ { y }$ 影范围，另外令起始和终止位置分别为sy、ey;

2）根据图像的倾斜与坐标的关系，可以得到如下投影公式：

$$
p r o j H [ i - s x ] = \sum _ { j = s y } ^ { e y } p \operatorname { I m } g [ j ^ { * } W + i + ( \operatorname { i n t } ) ( ( - k ) ^ { * } j ) ] , i = s x . . . e x - 1
$$

3）对投影做差分，然后做个均值滤波，结果仍放在projH数组中，差分操作如下：

$$
p r o j H [ i ] = p r o j H [ i + 1 ] - p r o j H [ i ] . \quad i = 0 . . . e x - s x - 1
$$

4）根据投影的波峰(最大值)和波谷(最小值)位置确定安全线的终止和起始位置，从而得到安全线的宽度，同时也得到了波峰与波谷的差值。

如下图中数字所示(从上到下显示为安全线的宽度和投影的最大差值)，可以看出，假的安全线宽度比真币的明显要粗，而且真币的安全线在纸币图像的背面是间断的，如同开窗式安全线的效果，而假的安全线则是没有这种效果的，其投影的差值也相对比较大。实验证明，当安全线宽度超过5且该投影差值大于3800的时候，可以判定为假币。经过大量的实验和上机测试，没有发生误报。

![](images/553c7e7040f2967868ac3f2dcf8cf6df2b37fab24984afaa99beab9720afcbbb.jpg)  
图5.14真币安全线宽度及其投影的最大差值

![](images/c0b86940f53c860497643ba7aaf87310202ded24b3994bd4e2c5e8aba6d18dff.jpg)  
图5.15假安全线的宽度和投影的最大差值

# 5.6.本章小结

本章介绍了红外图像处理的整个过程，包括纸币红外图像预处理、基本信息的获取(面额、方向、版本)以及鉴伪工作，介绍了传统的红外算法和本文提出的基于相邻区域对比式策略的灰度特征提取算法，并从多个图像鉴伪实例对本文算法进行了分析和验证。实验表明表明本文算法特征简单，但效果更好，有助于消除光照和新旧的干扰，有效识别出假币。

# 6总结与展望

# 6.1总结

随着我国经济的飞速发展，人民币的国际化进程也日益加快。但是由于造假手段的发展[44，假币种类也不断增多，鉴伪识别难度也越来越大，尤其是传统的一些鉴伪方法，在新型的假币面前开始显得越来越力不从心。利用图像处理技术对纸币进行鉴伪和识别是近些年图像处理[45][4的一个新的研究领域。通过图像处理技术可以可靠的对纸币进行准确的识别和分类，也能很稳定的检测出传统鉴伪方法不能检测出的假币、反宣币、残损币和变造币等，保证纸币流通过程的安全性和可靠性。

本文详细的阐述了纸币图像处理的整个过程，具体包括纸币图像的采集、预处理、基本信息的获取(面额、版本、方向)以及真假鉴别。在充分考虑了真、假纸币的图像的特征以后，针对现有某些算法健壮性不足中的问题进行了详细的分析，并提出了对应的解决方案。主要工作及取得的成果有：

1、针对水印的特点，在透射光下采集白水印图像，通过改进传统的归一化积匹配算法，提出了基于投影差分的归一化积匹配算法，该算法可有效消除对不同光照和新旧的干扰，识别实时性好，效果较传统算法更好，并与八方向特征提取算法和连通域特征提取算法进行了比较。

2、受GD.Finlayson[30]中提出的一种能够去除图像中阴影的算法的启发，引入色温和色差的概念，提出了基于色差的变色油墨三维特征提取算法。引入了监督式的训练学习[47]，通过对感知器进行训练学习，得到的分类器再与最近邻分类器进行比较，通过实验证明，感知器分类效果更加有效。

3、针对CIS传感器自身的缺点，和采集的新旧纸币的红外图像[48特点，提出了一种基于相邻区域对比式灰度信息特征提取算法，有效的消除了对不同CIS亮度校准不完全一致的情况和纸币本身新旧不同的情况带来的误差和阈值的失效的影响，这样的算法更加准确可靠。

虽然本文初步解决了纸币部分图像特征鉴伪的问题，但是，纸币上有多种鉴伪特征，大部分在图像上都能进行真假区分，只不过有些需要在不同光照条件下，需要采取不同的算法来处理，如何对这些图像提取出更有效的特征，是值得进一步研究的问题。

# 6.2展望

近年来，市场上的假币层出不穷，仿制手段越来越高明，可见纸币的反假工作是一项任重而道远的任务。但是，在国内，对纸币图像的鉴伪工作才刚起步不久，图像鉴伪工作需要更多有志于反假打假的有识之士加入进来，共同维护金融货币市场的秩序稳定。虽然本文提出了在透射光以及红外光下对纸币的部分图像的鉴伪方法，但是还远远不够，还有必要对图像鉴伪进行更深入的探索和研究。

1.本文的图像鉴伪只涉及到对部分图像防伪特征进行处理，而且对白水印和变色油墨的防伪实在透射光下进行的，对红外图像的鉴伪只涉及到比较简单的类型的假币，算法相对也比较简单，对红外的鉴伪特征需要更深入的研究。而且本文没有涉及到对可见光(自然光)和紫外光等图像的图像鉴伪工作，有待下一步继续研究。

2.本文只针对100元人民币纸币图像特征进行鉴伪研究。虽然100元人民币的防伪特征最多，尤其是05版，但是其他面额和版本的人民币也都或多或少有一些独特的防伪特征，本文没有加以分析说明，并且本文也只是研究了部分防伪特征，其他诸如阴阳互补图案、胶印微缩文字等特征都没有在本文中得到体现，这在未来是需要引起重视的。

3.假币的种类和数量收集比较困难，样本少，对某些图像特征的描述和处理不到位，即使能控制误辨率在很低的水平，但在实际使用中容易引起对假币的漏抓。这一点有待改进。

# 致谢

在读研究生两年半的时间里，经过自己的刻苦努力，不仅学到了丰富的专业知识，各方面能力也有很大的提高。在此，我要感谢我的导师娄震副教授对我的谆谆教诲。娄老师在平日里学习和研究中会我的悉心指导，以及教会我的很多做人的道理，是我永远难忘和学习的榜样。

感谢南京理工SPEED科技有限公司，感谢刘炜师兄和公司的领导们，是你们让我在公司实习的一年多时间里，受到细心耐心的指导和生活上无微不至的照顾。感谢公司里每一个曾经帮助过我和合作过的人们，感谢你们！

感谢306教研室的每一个师兄师姐以及师弟们，感谢研究生期间你们常伴在我身边，曾经在一起探讨和解决问题，有事情大家互相帮助。相聚在同一个师门下就是缘分，感谢你我之间的相互关怀。

感谢我的同窗和舍友，我们在一起走过了两年多的日日夜夜。感谢你们在我曾经失落的时候，给我的安慰和照顾，愿我们的友谊常在！

在此，也要特别感谢我的父母和家人，你们对我的关心和支持是我最大的动力，愿您们身体健康，长命百岁！

最后，对所有关心和支持我的人再次表示最诚挚的感谢！

# 参考文献

[1]唐春辉．人民币伪钞鉴别仪的鉴伪技术[J]．仪表技术，2005(4)：80-81  
[2]历亦光.RMB纸币检伪技术的简要历程与发展.2007南京反假货币机具论坛.2007：8-9  
[3]石义磊．我国及世界主要国家货币防伪技术特点及发展新趋势[J]．武汉金融,2009(12): 55-59  
[4] 陈继宣，曹良佑．人民币防伪特征与鉴别仪鉴别能力匹配特性研究[J].现代商贸工业，2012(1):160-161  
[5]郭玉峰，胡学娟，阮双琛．红外图像处理在钞票鉴伪中的应用[J].激光与红外，2009(1): 113-115  
[6] Hiroshi Sako， Takafumi Miyatake. Image-Recognition Technologies towards AdvancedAutomated Teller Machines[J]. Proceedings of the Pattern Recognition, 2004(3):282-285.[7] Chien-Chuan Huang, Pei-Yin Chen, Hung-Yu Yang,Chih-Yuan Lien. A Low-ComplexityScaling Scheme for Barrel Distortion Correction[J].2012 Sixth International Conference onGenetic and Evolutionary Computing,2012(20): 356-359.  
[8] 王雷，郭健，陈英革，王小英．图像桶形失真的一种校正方法[J]．常熟理工学院学报(自然科学版),2007(4):104-107  
[9] 冯伟．图像桶形畸变校正的研究与实现[D].北方工业大学.2011  
[10] Tsai. A Versatile Camera Calibration Technique for High-Accuracy 3D Machine VisionMetrology Using Off-the-Shelf TV Cameras and Lenses [J].IEEE 1987(4),323-344  
[11]刘炜．人民币冠字号码识别与图像鉴伪技术研究及应用[D]．南京理工大学.2011[12] 刘锦峰．图像模板匹配快速算法研究[D].中南大学,2007  
[13] 陈松柏．实时的归一化相关匹配算法[J].信息与电子工程,2006(6)：461-463[14]杨通钰，彭国华．基于 NCC 的图像匹配快速算法[J].现代电子技术,2010(22):107-109  
[15] Hongluan Zhao,Zunyi Xu,Guoyong Han, Deqin Xie. The Fast Image Recognition Basedon Gray cale Features[J]. Proceedings of 2012 IEEE International Conference on ComputerScience and Automation Engineering,2012: 730-734  
[16] 曹丹华，刘芮，吴裕斌．投影特征匹配的快速钞币面值识别算法[J]．光电工程,2004(1): 59-61  
[17] Z. L. BAI,and Q. HUO."A Study On the Use of 8-Directional Features For OnlineHandwritten Chinese Character Recognition,". Proc. 8th Int'l Conf. Document Analysis andRecognition .2005  
[18]宋斌.一种新的图像连通区域快速标号算法[J]．电子测量技术，2009,32(9):67-68[19] SonkaM,Hlavac V,BoyleR.图像处理、分析与机器视觉[M].艾海洲，武勃泽第2版，北京：人民邮电出版社，2003‘  
[20]陈柏生．一种二值图像连通区域标记的新方法[J]．计算机工程与应用，2006,42(25):50-51  
[21] Mingwu Ren,Jingyu Yang,Han Sun. Tracing Boundary Contours in a BinaryImage[J].Image and Vision Computing,2001(20): 125-131.  
[22]刘关松．一种新的二值图像标记的快速算法[J]．计算机工程与应用,2012(4)：57-59[23]刘奇琦．一种二值图像连通区域标记的新方法[J]．计算机工程与应用,2012(11):178-180  
[24] 徐遵燕.光学变色防伪油墨的设计原理[J].印刷器材,2011(3):40-42  
[25]刘琳.点钞机鉴别技术探讨[J].电子产品可靠性与环境试验,2012,30(5):115-117[26] Otsu N. A threshold selection method from gray-level histograms[J]. IEEE Transactionson Systems,Man and Cybernetics, 1979,9(1): 62-66.  
[27]王明顺,王俊生.基于DSP的纸币光变油墨自动识别的研究[J].中国图象图形学报，2009(5):950-956.  
[28]王琦．人民币伪钞识别模块的研究与开发[D].重庆大学,2011.  
[29] David A.Forsyth, Jean Ponce. Computer Vision: A Modern Approach[M].电子工业出版社,2012.  
[30] G.D.Finlayson, S.D.Hordley, C.Lu,M.S.Drew, “On the Removal of the Shadows fromImage", in Pattern Analysis and Machine Intelligence, IEEE Transactions,20o6,28(1): 59-68[31]张德丰.MATLAB神经网络应用设计[M].第二版.北京：机械工业出版社，2012[32] 陈明.MATLAB神经网络原理与实例精解[M].北京：清华大学出版社，2013[33]王必强，毕硕本，董学士．基于单层感知器的数据挖掘分类的设计和实现[J]．计算机技术与发展,2010(9)：111-114  
[34]崔乃予.基于核感知器算法的汽车ESP系统故障诊断[D]．吉林大学,2014  
[35]甘井中.基于BP神经网络图像识别的研究[D].大连理工大学,2008  
[36] 刘琳.基于图像和磁技术的人民币鉴别仪一硬件方案设计和实现[D].华南理工大学，2012  
[37]卢龙.基于磁信号与红外图像的纸币鉴别技术研究[D]．哈尔滨工业大学，2009[38]邹乐强.最小二乘法原理及其简单应用[J]．科技信息，2010(23)：282-283  
[39] Takeda F, Omatu S. High speed paper currency recognition by neural networks[J].IEEETrans on Neural Network, 1995,6(1):7377[40]陈杰．关于多国纸币版面和号码识别的研究与应用[D]．南京理工大学.2013[41]蒋天瑜.基于多光谱图像的纸币防伪鉴定技术研究[D].华中科技大学，2013[42] Mikhail H Atallah.Faster Image Template Matching in the Sum of Absolute Value ofDifferences Measure.IEEE on Image Processing,2001,10(4):659---662  
[43]崔博．基于多光谱的假币识别特征分析与研究[D]．昆明理工大学，2012  
[44] John N. Smithin. Controversies in Monetary Economic[M]. The 2nd Revised edition,Edward Elgar Publishing Ltd, 2003  
[45]冯伟兴，唐墨，贺波.Visual $\mathrm { C } { \mathrm { + } } { \mathrm { + } }$ 数字图像模式识别技术详解[M]．北京：机械工业出版社，2011  
[46] Christopher M.Bishop.Pattern Recognition & Machine Learning[M].New York:Springer, 2006  
[47] Rafael C, Gonzalez, Richard E.Woods. Digital Image Processing[M].The Second Edition.Beijing: Publishing House of Electronics Industry,2002  
[48] Jian xun Li, Gang Liu, Guang Zhi Liu, et a1. Real-time system for small target detectionand tracking in infrared image[J]. Laser&Infrared, 2005(6):407409

# 附录

# 攻读硕士学位期间发表的论文和出版著作情况：

[1］李健，娄震．基于光变油墨透射图像的人民币鉴伪技术研究.计算机系统应用（已录用)