# 深度伪造技术滥用及其法律规制

# 刘东亮 黄 安 杨晓科

摘要: 深度伪造技术是生成式人工智能技术的衍生物。基于其 “伪造” ( 合成) 的性质，该技术天然带有异化风险，易导致虚假信息生成和泛滥，不但侵犯公民合法权益，而且侵蚀社会信任体系，甚至冲击政治稳定和国家安全，并对司法审判中的证据审查造成困扰。我国现有法律规范为防范深度伪造技术滥用提供了基本规制方向和路径，但存在较大的完善空间。对此，应当确立规范统一的内容显性标识制度，建立反应迅速、覆盖全面的预警机制，构建责任明确、分级分类的辟谣制度，针对 “深度伪造抗辩”设置抗辩人举证责任规则，以应对深度伪造技术带来的挑战。

关键词: 深度伪造技术; 法律规制; 虚假信息; 辟谣机制; 电子数据DOI:10.16154/j.cnki.cn22-1025/c.2025.01.007

深度伪造技术是使用深度学习方法合成图像、文本和音视频内容的一种人工智能技术的“诨名”，其正式名称为 “深度合成” ( Deep Synthesis) 。2017 年 12 月，在美国知名社交平台红迪网 ( Reddit) 上，一个署名为 “Deepfakes”的用户发布了一系列换脸女明星的色情视频，“深度伪造”一词由此产生。

加的视频会议，骗取该公司转账 2 亿港元，目前该案还没有逮捕到嫌疑人。 $\textcircled{1}$ 其他类似案件不胜枚举。

如何防范深度伪造技术滥用引发的虚假信息泛滥、电信诈骗等给公民人身和财产安全乃至国家安全和政治稳定带来的严峻挑战，成为亟须解决的现实问题。

# 一、深度伪造的技术逻辑及应用

在讨论深度伪造技术滥用的法律规制问题前，首先要了解该技术的原理和应用场景，然后才能提出有针对性的解决方案。

# ( 一) 深度伪造的技术逻辑

深度伪造技术的名称来源于 “深度学习 ( Deep Learning) ” 与 “伪造 ( Fake) ” 的结合，主要依赖深度神经网络实现预设功能。深度学习作为机器学习的一个子领域，是深度伪造的技术基础。1986 年，加拿大科学家辛顿 ( Geoffrey Hinton) 等人提出了反向传播 ( Back Propagation，BP) 算法，用于多层神经网络的优化训练，并证实这种方法对机器学习行之有效。 $\textcircled{2}$ 2006 年，辛顿等人正式提出 “深度学习”概念。 $\textcircled{3}$ 深度学习通过多层神经网络对输入数据自动进行特征提取，可实现对复杂数据结构中非线性关系建模，其优点是能处理海量数据，挖掘数据集中潜藏的规律，解决相关问题，因此被广泛应用于机器翻译、文本分类、语音识别、语音合成和图像合成等多个领域。

在此基础上，2014 年，蒙特利尔大学计算机科学博士生伊恩·古德费洛 ( Ian J. Goodfellow)等提出了一种新的深度学习模型——生成式对抗网络 ( Generative Adversarial Networks，GAN) 。 $\textcircled{4}$ GAN 是一对结合在一起的网络: 生成网络 ( 或称 “生成器”) 和判别网络 ( 或称 “判别器”)的组合。生成网络学习如何欺骗判别网络，判别网络学习如何准确区分真假数据，二者间形成一种 “相互对抗”的博弈关系。 $\textcircled{5}$ 在博弈趋近均衡的状态下，判别网络对样本的判别能力不断上升，生成网络的造假能力随之提升，由此使生成结果更为逼真。随后，GAN 又与卷积神经网络( Convolutional Neural Networks，CNN) 、变分自编码器 ( Variational Auto－Encoders，VAE) 框架下的解码器等技术相结合，大幅提高了合成或伪造的效率。可以预计，随着人工智能技术不断迭代，深度伪造技术将持续取得新的突破。

# ( 二) 深度伪造技术的应用领域

技术进步使深度伪造的门槛不断降低，没有专业背景的普通人也能轻松地接触和使用该技术。2018 年8 月，美国市场上发布了一款名为 “FakeApp”的软件，该程序可以让使用者轻而易举地创造出深度伪造作品，在美国迅速扩展到恶意欺诈、政治操纵等应用场景。2019 年 8 月，中国境内发布了一款名为 “ZAO”的应用程序 ( 已被禁用) ，其最大卖点是 “仅需一张照片，出演天下好戏”。这些应用程序打破了普通人与复杂技术间的壁垒，只需用手指点击一下，即可轻松实现各种想要的 “伪造”。

概括而言，深度伪造技术主要应用于图像、音视频的合成两个方面。 $\textcircled{1}$ 在图像生成方面，深度合成技术具有极高的应用价值，并且可以做到高分辨率 ( 清晰度) 、仿真性与艺术性并存。目前，市场上许多AI 模型都具备 “文生图”功能，即将语言模型和图像生成模型结合，根据用户输入的自然语言生成匹配的图像，包括照片、油画、版画等多种形式，已有用户通过篡改图像进行恶搞，使相关对象的社会评价降低，或者伪造色情图片，用于骚扰、羞辱和勒索等违法犯罪活动。

音视频合成是深度伪造最典型的代表，即众所周知的 “AI 换脸换声”技术。音频深度合成技术目前已经发展到较为成熟的阶段，高效性与逼真性兼备，可应用于音乐生成、语音助手、有声读物等场景，例如，智能音箱 “小爱同学” 的定制声音功能就应用了语音合成技术。此外，在车载机器人、智能手机、智能家居等应用系统中亦可发现其身影。视频的深度合成则多用于视觉效果制作、特效设计、影视剪辑等，涉及娱乐、教育、医疗等诸多领域，如深度合成医疗影像数据，可以帮助医生更准确、更科学地进行诊断。在通常情况下，音视频的合成会结合在一起使用，以使生成内容看起来更具 “真实性”。

# 二、深度伪造技术滥用产生的问题

科学技术通常都有两面性。深度伪造在带来诸多技术红利的同时，其滥用也引发了各种各样的法律问题。

# ( 一) 深度伪造侵害公民合法权益

从技术原理来说，深度伪造技术可以简化为三个核心步骤: 收集数据、训练模型、生成内容。由于深度伪造技术以数据驱动，其中相当多的数据属于个人数据，包括生物识别信息、医疗健康、消费记录、行动轨迹等，若被过度搜集和不当使用，将对公民的财产和人身安全造成极大的威胁。

很多时候，深度伪造技术在未经授权的情形下就将个人数据用于合成人脸图像和音视频，对公民的肖像权、名誉权等权利构成侵害。例如，2021 年， “AI 林俊杰” 在各大经典影视剧中“客串”的视频走红网络，视频中林俊杰的面部形象叠加在剧中角色上，其五官和表情几乎完全融合，真假难辨。 $\textcircled{2}$ 面部形象作为个体独特性的标志，具有可识别性，无论基于何种目的，在未经明确授权的情况下进行替换，都属于侵权行为。

更令人担忧的是，深度伪造技术合成的虚假音视频已被用于诈骗活动。据统计，截至 2023  
年10 月，针对 “AI 换脸”导致群众被欺诈的问题，公安机关发起专项会战，侦破相关案件 79

起，抓获犯罪嫌疑人 515 名。 $\textcircled{1}$ 深度伪造技术为违法犯罪活动提供了新的手段，各种新骗局花样百出，令人防不胜防。

# ( 二) 深度伪造侵蚀社会信任体系

深度伪造技术滥用产生了大量虚假信息，不断消解社会真相。哈佛法学院教授卡斯·R·桑斯坦 ( Cass R． Sunstein) 在研究谣言的传播过程时发现，在现代社会，随着互联网的兴起，谣言会形成 “社会流瀑”( Social cascades) 和 “群体极化”。 $\textcircled{2}$ 也就是说，通过深度伪造生成的虚假信息，在互联网的影响下会放大传播效果，受害者很容易从单一个体扩大为社会公众，进而瓦解现代社会中的信任关系，产生社会信任危机。例如，2018 年 5 月，比利时社会党发布了一段经过深度伪造的时任美国总统特朗普的演讲视频，呼吁比利时退出 《巴黎气候协定》。尽管视频末尾标明了 “非真实”，仍引起社会公众对该事件激烈讨论，最终该党不得不公开澄清视频为伪造。 $\textcircled{3}$ 又如，MIT 高级虚拟中心 ( Center for Advanced Virtuality) 曾经利用深度伪造技术制作了尼克松宣布第一次登月失败的虚假影像，使众多 “阿波罗登月计划阴谋论”的支持者更加坚信“阿波罗登月计划”是美国的 “世纪大骗局”。 $\textcircled{4}$ 可见，深度伪造技术给社会信任体系带来了系统性威胁。当人们意识到某些信息是伪造生成之时，其负面效应往往已经造成难以挽回的损害，而重建社会信任的过程道阻且长。

# ( 三) 深度伪造威胁国家安全和政治稳定

深度伪造技术肆意滥用在国家安全和政治稳定层面的负面影响相继涌现。例如，2018 年加蓬共和国总统阿里·邦戈·翁丁巴 ( Ali Bongo Ondimba) 在沙特阿拉伯参加国际会议后住院，几个月后，他再次出现的画面被认为是深度伪造的音视频，并刺激一些加蓬士兵发动了军事政变。 $\textcircled{5}$ 可以说，深度伪造能够以低成本的方式挑唆社会公众，危害国家安全。

深度伪造对政治活动的干扰作用十分明显。特朗普、奥巴马、拜登、佩洛西等美国政治人物都曾经成为深度伪造的对象。 $\textcircled{6}$ 例如，2024 年 1 月，数万个伪造拜登声音的电话打给美国新罕布什尔州的居民，呼吁不要在总统初选中投票。对此，有专家警告称，2024 年将会是 “深度伪造大选年”。 $\textcircled{1}$ 深度伪造技术滥用产生的虚假信息，无疑会使社会公众对政治人物的形象产生误解和负面看法，损害政治人物的政治声誉，进而影响政治稳定。

# ( 四) 深度伪造增加证据真实性的判别难度

深度伪造技术门槛的降低使任何拥有智能设备的个人都可以进行信息合成，即人人都可以成为虚假内容的制作者，人人都可以成为 “说谎者”。深度伪造技术的存在，不仅使 “说谎者”能够轻易篡改真相，还能让其以一种更简单的方式否认真相。当人们认识到某些图像、文本或者音视频存在伪造的可能性时，别有用心者会试图通过将真实的事物抹黑为 “深度伪造” 的产物，从而逃避对自身行为的问责，收获所谓的 “说谎者红利”。 $\textcircled{2}$ 认知心理学的研究表明，人们对视觉的重视程度超过其他感官感知信息。 $\textcircled{3}$ 然而，深度伪造技术的风行，使得作为一种直观证据的视听资料内容的真实性很容易遭到质疑——无论它事实上的真假。不难理解，如果在纠纷解决程序中处于不利地位的当事人动辄声称 “对方的证据是深度伪造的”，这种所谓的 “深度伪造抗辩”，造成诉讼活动不仅需要 “证伪”，还需要 “证真”，从而大幅增加了法庭证据审查的难度。

# 三、深度伪造技术滥用法律规制的现状

对深度伪造技术滥用滋生的各种问题，各国均表现出高度的警觉和关注，并采取了相应措施进行法律规制，以应对相关的风险和挑战。

# ( 一) 关于深度伪造的规制立法

美国对深度伪造技术采用了直接规制的方式，通过专门立法直面这一新生问题。2019 年 6月，美国国会出台的 《深度伪造责任法》 ( Deepfakes Accountability Act) ，旨在限制深度伪造技术，打击虚假信息传播。美国参议院 2019 年 10 月审议通过的 ${ \langle \langle 2 0 1 9 }$ 年深度伪造报告法案》( Deepfakes Report Act of 2019) 对 “数字内容伪造”的含义作了界定。 $\textcircled{4}$ 同时，各州也先后出台了有针对性的立法。例如，加利福尼亚州 2019 年通过了两项关于深度伪造的立法，其中第AB602 号法案限制深度伪造生成色情信息并规定了私人诉权，以简化个人申诉的程序; 第 AB730号法案对深度伪造影响政治活动的行为进行规制: 在选举前60 日内，传播以政治候选人为主题、旨在损害候选人声誉或欺骗选民投票支持或反对候选人的篡改内容属于违法行为。 $\textcircled{1}$ 从总体上看，美国针对深度伪造的立法涉及的对象范围较窄，主要集中在政治选举和色情制品的规制上，且倾向于采用刑事手段。

欧盟对深度伪造采取直接规制与间接规制相结合的方式，将深度伪造作为人工智能风险规制的一部分，并通过加强对个人数据安全、通信技术的治理来防范风险。2018 年 4 月，欧盟委员会发布了 《应对线上虚假信息: 欧洲方案》 ( Tackling Online Disinformation: a European Ap-proach) ，阐释了治理线上虚假信息需要遵循的基本方针。2018 年 5 月颁布的 《通用数据保护条例》( GDPR) 对个人数据和个人隐私实行了强有力的保护，以此规制深度伪造对个人权利的侵犯。2024 年 5 月 21 日，欧盟理事会正式批准了 《人工智能法》( Artificial Intelligence Act) 。该法第50 条 “特定人工智能系统的提供者和部署者的透明度义务”第 4 款规定: “生成或操纵构成深度伪造的图像、音频或视频内容的人工智能系统的部署者应当披露其内容是人为生成或操纵的。”虽然该法没有详细规定应当如何披露以及如何处罚，但其将深度伪造纳入人工智能监管整体框架的做法，在一定程度上可以为问题的解决提供指引。

我国 《民法典》 《刑法》 《个人信息保护法》等为规制深度伪造技术的滥用提供了法律依据。如 《民法典》第1019 条有 “利用信息技术手段伪造等方式侵害他人的肖像权”的规定，可以解释为包括但不限于深度伪造技术的侵权，在民事基本法层面为应对技术侵权提供了依据。自生成式人工智能技术快速发展以来，中央相关部委陆续颁布了 《网络音视频信息服务管理规定》《网络信息内容生态治理规定》《互联网信息服务深度合成管理规定》等规章和规范性文件，为深度伪造等人工智能技术的应用划定了边界。不过，尽管我国在规制深度伪造技术滥用方面取得了一定进展，但目前缺少一部统一的法律或系统性的人工智能法律框架，以提供全面的规范。此外，我国现有法律对深度伪造技术的规制还比较粗疏，需要进一步明确与细化。

# ( 二) 政府与平台共同承担监管责任

与对传统技术的监管相比，深度伪造技术的监管具有更多特殊性和复杂性，仅靠政府作为单一监管主体的模式很难实现全方位和全过程的有效监管。唯有充分利用政府和平台各自的优势，建立和完善有针对性的监管合作机制，才能弥补各自监管能力的不足，更好地应对深度伪造技术带来的挑战。

# 1. 平台责任不断加强

美国的 《深度伪造责任法》和 ${ \langle \langle 2 0 1 9 }$ 年深度伪造报告法案》均要求平台采用 “定期报告”和 “自我披露”等方式对深度伪造技术合成物进行监管，深度伪造音视频需要带有 “不可删除的数字水印及文本描述”，说明该文件系伪造生成，违反规定者将面临民事或刑事处罚。在 2020年美国总统大选中，特朗普竞选团队在推特上发布了总统候选人拜登的讲话视频，其中含有拜登号召支持其竞选对手特朗普的深度伪造内容。该视频发布 18 个小时后，推特才为其加上 “被操纵的媒体”的标签，此时该视频已获得高达 500 万次的浏览量。 $\textcircled{1}$ 该案例充分说明平台对深度伪造内容的监管责任及反应速度的重要性。然而，被称为互联网平台 “保护伞”的 《通信规范法》( Communications Decency Act) 第 230 条，赋予了互联网公司豁免权，使其免于对第三方在平台上发布的内容承担责任，在一定程度上减轻了平台对深度伪造内容的监管压力。同时，该条款对互联网服务提供商和网站的问责力度不足，使那些具有巨大影响力的平台可以根据自己的偏好来压制和审查言论。因此，很多学者主张要尽快对第 230 条进行修订。 $\textcircled{2}$ 但由于第 230 条款的修改涉及相当复杂的利益调整，在短期内进行具有实质意义的改革的可能性并不是很大。 $\textcircled{3}$

2018 年 10 月，欧盟发布了 《反虚假信息行为准则》 ( Code of Practice on Disinformation，以下简称 《准则》) ，旨在加强互联网企业对其内容的自我审查，从源头上打击虚假信息。这是在世界范围内首次采用自我监管标准 ( self－regulatory standards) 打击虚假信息的尝试。2022 年，欧盟对该 《准则》作了修订，增加了为用户提供识别和标记虚假信息的工具、扩大事实核查等措施。欧盟逐步意识到，从企业和个人的自我监管过渡到统一监管是十分必要的，加强互联网运营商的责任是大势所趋。 $\textcircled{4}$ 欧盟严格的监管要求，促使在其区域内从事互联网服务的平台不得不采取有效措施强化深度伪造内容的监管。

在我国，加强平台内容管理责任的要求由来已久。依据原 2009 年 《侵权责任法》确立的目前在 《民法典》侵权责任编中仍然沿用的 “避风港原则”和 “红旗原则” $\textcircled{5}$ ，平台负有一定的及时阻断侵权和违法内容传播义务。2011 年生效的 《互联网信息服务管理办法》作出了 “互联网信息服务提供者不得制作、复制、发布、传播”特定有害内容的规定。2019 年通过的 《网络信息内容生态治理规定》明确和细化了网络信息内容服务平台的 “信息内容管理主体责任”。前述涉及深度伪造的规章在沿用平台自治思路的前提下，结合技术治理的要求进行了内容补充。例如，《互联网信息服务深度合成管理规定》要求平台积极履行对深度伪造内容的主动管理义务，为其设定了建立健全辟谣机制、显著标识 “非真实音频信息”、为公众设置便捷的投诉举报路径、加强安全管理等一系列义务。

# 2. 政府监管不断加强

美国通过联邦和各州立法，采取直接监管方式规制深度伪造滥用。由于美国奉行 “先发展，后治理”的政策，将激励技术创新放在首位，因此这种规制方式多通过事后惩罚发挥作用，视角集中于深度伪造技术的合成物是否违法 ( 后期阶段) ，以及如何对侵权内容的制作者进行惩戒。 $\textcircled{1}$

欧盟采取直接和间接监管相结合的政策，其最突出的特点为严格依据 GDPR 等法律对个人数据进行保护，视角放在合成物的创作和流通阶段 ( 前期阶段) ，从源头上遏制公民权利被侵害的可能; 以 《人工智能法》为核心，对深度伪造合成的虚假音视频内容的制作者设置相应义务。此外，欧盟还一直十分重视对虚假信息的治理，从 2017 年起，欧洲议会就敦促欧盟执行委员会采取强硬的监管手段处理虚假新闻。2024 年 2 月，欧盟 《数字服务法》( Digital Services Act，DSA) 对所有网络平台全面生效。该法要求在线平台必须提供透明和安全的在线环境，保护用户免受非法内容、商品和服务的侵害，尤其对于有害内容和虚假信息，在线平台必须承担更严格的责任，违规企业将面临高达其全球年营业额 $6 \%$ 的罚款或者被禁止在欧盟区域内运营。同时，欧洲议会的很多决议也强调了培养公民信息素养的重要性，以帮助公民识别网上的虚假信息。 $\textcircled{2}$

与欧盟类似，中国也重视对深度伪造技术滥用的前期监管，并同样将虚假信息治理作为规制重点，针对网络谣言开展定向打击。早在2018 年，中央有关部门就设立了互联网联合辟谣平台，并逐步形成一个较完备的谣言治理法律体系，在主管部门的指导下建立了跨部门、跨领域、跨系统的一体化联动辟谣机制，实现了对网络谣言的联动发现、联动查证、联动清除。在此机制下，中央和地方的辟谣平台还在各社交媒体和内容平台建立账号作为信息分发渠道，以确保辟谣信息能够覆盖更广泛的受众。不过，目前来看，相关账号的整体影响力比较有限。例如，依托微信公众平台的 “互联网联合辟谣平台”公众号所发布的推送信息一般只有几千次的阅读量。其原因可能在于辟谣平台所发布的内容混杂无序，一些紧要程度较低的辟谣内容不仅占用了流量资源，还分散了受众的注意力，从而影响了辟谣的效果。此外，针对网络平台的包容审慎监管原则虽然是具有中国特色的创新策略，但在实践中尚存在政府与平台、公众之间联动不足的缺陷，未能充分发挥多元主体之间的协同治理效能。

# ( 三) 国家安全和政治稳定成为重点防控对象

深度伪造技术的发展，使虚假信息在国家安全和政治领域的散布更为普遍和容易，因此受到各国普遍重视。

美国既是深度伪造技术的发源地，同时也是受其侵害最早、最深的国家。在反虚假信息行动方面，美国有 “全政府”协同、“全社会”配合、“全球性”布局的特点。仅以前者为例，美国多个联邦政府部门如国务院、国土安全部、国防部、情报和安全部门、全球媒体署等均专设机构和团队开展反虚假信息行动，他们的分工各有侧重又相互配合，呈现 “全政府” 协同态势。 $\textcircled{1}$ 特别是政治选举作为国家政治生活中的重要事件，面临着虚假信息影响选民意见的严重威胁，引起社会各界对选举诚信和政治稳定的深切关注。如前所述，美国联邦层面和各州颁布的相关立法，其主要规制对象之一就是政治选举活动，并倾向于以刑事手段进行规制和防范。

深度伪造同样成为影响欧洲国家政治选举的破坏性工具。例如，2018 年，在北马其顿，有人试图使用虚假新闻敦促民众投票反对政府提案，从而破坏公投活动。 $\textcircled{2}$ 2024 年欧洲有包括欧洲议会选举在内的 65 场重大选举活动。对此，欧盟网络与信息安全局 ( ENISA) 制定了深度伪造操纵选举行为的应对方案。该机构认为，发展网络安全基础设施，促进信息的完整性和可用性，是在选举期间解决深度伪造问题的主要途径之一。 $\textcircled{3}$

尽管中国国家安全和政治稳定尚未直接受到深度伪造技术的冲击，但其在互联网上的迅速蔓延和潜在风险，要求我们必须预先加强防范，尤其在以美国为代表的西方国家持续挑动 “大国竞争”的背景下，很难保证深度伪造不会被用于操纵我国舆论、影响我国意识形态安全。目前，我国对深度伪造虚假信息的治理形成了以 《网络安全法》《数据安全法》《个人信息保护法》为核心，以其他部门规章和规范性文件为补充的法律框架。但深度伪造领域的专门立法 《互联网信息服务深度合成管理规定》有关国家安全的条款过于原则化，可操作性不强。 $\textcircled{4}$ 因此，健全相关法律制度并确保其有效执行是当前迫切需要解决的问题。

# ( 四) 对深度伪造证据的法律规制有待加强

深度伪造技术的出现使对证据真实性的判断变得异常复杂。除伪造生成的证据会干扰审判外，当事人及律师的 “深度伪造抗辩”也会使法官对真实的证据究竟是否真实产生怀疑。例如，在2021 年1 月6 日美国国会暴乱案中，被告人盖伊·雷菲特 ( Guy Reffitt) 的辩方律师没有出示任何证据，“控方所有证据系深度伪造”是其向陪审团提出的唯一论点。 $\textcircled{5}$ 而美国现有的证据规则尚无针对深度伪造的相关规定。虽然一些规则为律师和当事人设定了诚信诉讼义务，如 《联邦证据规则》( Federal Rules of Evidence) 第 11 条要求当事人的主张不能毫无根据，禁止拖延诉讼程序; 《美国律师协会专业行为示范规则》 ( ABA Model Rules of Professional Conduct) 中有“禁止明知其为假或罔顾真伪对法官做出虚假陈述”等规范， $\mathcal { P }$ 但是现行的程序规则并未对当事人和律师进行虚假诉讼、虚假辩护设定惩罚性制裁措施。

在我国，证据的三要素是指证据的相关性、客观性和合法性。这意味着凡系深度伪造证据均应当排除适用。我国 《刑法》第 307 条规定 “帮助当事人毁灭、伪造证据，情节严重的，处三年以下有期徒刑或者拘役”，在法律没有专门针对深度伪造证据的情况下，提供了相应的法律根据。此外，《律师执业行为规范》第 63 条规定 “律师不得向司法机关或者仲裁机构提交明知是虚假的证据”，强调了律师的职业道德和执业纪律。这些法规在一定程度上有利于抑制深度伪造的证据进入诉讼程序。但需要注意的是，我国法律目前并无应对 “深度伪造抗辩”的相关规定，对当事人及其律师利用 “深度伪造抗辩”故意拖延诉讼程序、浪费司法资源，甚至消解证据的真实性、干扰法官自由心证的不当行为存在规制空白，亟须有针对性的法律规范。

# 四、深度伪造技术滥用法律规制的完善

为切实解决深度伪造技术滥用带来的问题，中国需要对现有法律进行相应的调整和完善。除了需要尽快出台 《人工智能法》将深度伪造纳入人工智能监管整体框架外，还应当积极探索有效应对深度伪造技术滥用的具体路径和方法。概言之，需要建立规范统一的内容显性标识制度，建立反应迅速、覆盖全面的预警机制，构建责任明确、分级分类的辟谣制度，并针对 “深度伪造抗辩”确立抗辩人的举证责任规则。

# ( 一) 确立规范统一的内容显性标识制度

“内容的显性标识”是为深度伪造的内容加上显著提示，以此来告知受众，其所浏览的内容是深度伪造的产物。显性标识制度旨在使内容的虚假性外显，从而达到使受众产生心理防范的效果。我国 《网络音视频信息服务管理规定》和 《互联网信息服务深度合成管理规定》已明确规定了深度伪造内容的显性标识制度。 $\textcircled{2}$ 相关实践指南和拟出台的推荐性技术标准也对 “如何标识”和可采用的技术手段提供了指引。 $\textcircled{3}$ 然而，当前看似完善的制度仍有较大的改进空间。申言之，虽然大多数内容平台都遵照法律规定实施了内容标识制度，但各自采取的模式和方法杂乱无章，在现实中由深度伪造内容造成的误导也不在少数，亟须对法律作出统一、细化和完善。例如，在标识模式方面，B 站、小红书、抖音等平台采用的是 “作者声明 $^ +$ 平台标识”的 “双轨模式”。具体而言，先有 “作者声明” 在前，当发布者没有按照平台规则对内容作出 “AI 生成”

的声明时，平台会根据检测结果为内容打上 “疑似 AI 生成”的标签。在该模式下，较大比例的内容得到了标识。而快手、微信视频号等平台上的深度伪造内容以 “作者声明”为主，很少见到平台主动检测后所做的标识。相应地，这些平台上的深度伪造内容呈现较低的标识率。

在标识的位置、字体大小、透明度、与其他说明性文字的区分度等标识方法上，这些平台也各有差异。如 B 站和抖音的作者声明和平台标识均位于内容下方的文本区域，字体偏大，透明度不明显，而快手的作者声明位于画面上方，字体较小，且字体透明度偏高，容易被忽略，并且这些平台中都有大量作者声明是以 “关键词”或其他非正式的说明性文字做出的，难以称得上真正的 “作者声明”，从而加剧了标识方式的混乱。此外，还有一些 “数字人”账号只是在主页作出介绍，发布的内容全无标识，这就很容易对未点进主页的受众产生误导。另一个值得关注的问题是，对某些即使用肉眼观察也很容易发现属于虚假的内容，各平台所做的标识也使用 “疑似 AI 生成”的表述，这种提示本身就带有很大的不确定性，难以有效引起受众的防范。

同时，当前的内容显性标识制度未充分体现出保护的针对性。一般来说，年轻人及受教育程度较高的群体不易受到深度伪造内容的误导。如在 B 站、小红书等青年群体聚集的平台，凡疑似深度伪造生成而未标识的内容，其评论区域多有质疑的声音。而在抖音、快手、微信视频号等下沉用户占比较高的平台，存在大量 “一眼为假”的内容，通过引起观看者的强烈共情和信任，相关账号大肆收割流量，并伺机推广产品，其中较多内容虽带有显性标识，但仍然被视为真实内容而备受追捧。 $\textcircled{1}$ 因此，针对不同受众群体的特点，提高保护的针对性刻不容缓。申言之，建立更完善的内容显性标识制度，需要做到以下三点:

首先，深度伪造的内容标识应当规范统一。“作者声明”对内容发布者的自律性要求较高，并且无法应对有意违法的情形，最终仍要依赖平台检测与标识。因而，应当规定内容平台的统一检测与标识义务。这意味着，内容平台应当部署深度伪造内容的检测技术并配备相应的人工团队。在此前提下，应当明确内容标识的表述规则，即对被检测为假的内容做出 “AI 生成”的确定性标识，避免可能产生的误导，只有对无法确定的内容才能做出 “疑似 AI 生成”的标识。

其次，深度伪造的内容标识应当清晰醒目。需对标识的位置进行统一规定，明确标识乃针对每条伪造的内容做出，账号主页的介绍不能作为标识，并将标识放置在受众不易忽视的位置。同时，应当统一标识字号和透明度，以确保所作标识与其他内容说明文字具有显著性区别，禁止透明度较高的无效标识。另外，考虑到前述易受误导群体的特殊性，内容标识的语言应当具有通俗性和直白性。当前所采用的 “AI 生成”的说法有一定的理解门槛，这些人很可能都不知人工智能为何物，遑论其英文缩写的含义，“生成”一词也并非日常语言，因此，应当以较为通俗的表达对 “AI 生成”的说法进行替换，以有效宣示内容的虚假性。

最后，有效的显性标识制度离不开内容检测技术的开发和应用。早前，网络平台的内容审核以人工为主，但随着人工智能生成内容更加便利，审核海量信息的压力迫使平台不得不转向以机器审核为主。当前，由机器实施的深度伪造内容检测技术有两种模式: “被动防御”和 “主动防御”。 $\textcircled{1}$ 前者将深度伪造技术与深度伪造检测技术分开，在深度伪造技术或工具诞生后才有针对性地研究对策，以求各个击破; 后者则未雨绸缪，要求深度伪造技术或工具的开发者与防御者组成 “统一战线”，在研发和形成产品时就为后续深度伪造内容检测创造条件。比较而言，两种模式各有优势和不足，“被动防御”虽然可以有针对性地对特定技术的生成内容进行检测，但易因伪造技术的进步而失效; “主动防御”方法虽然可以实现 “事前防御”，但仍然存在实际应用难题。 $\textcircled{2}$ 因此，应当同时鼓励两种模式的研发和应用，降低平台部署深度伪造检测技术的成本和难度，促进深度伪造内容的有效标识。

# ( 二) 建立反应迅速、覆盖全面的预警机制

深度伪造带来虚假信息泛滥，而且事后补救的效果有限; 完全遏制有害虚假信息的传播又很难实现。因此，建立反应迅速、覆盖全面的预警机制非常必要。运用大数据分析技术，可以提高预警的准确性和效率。以电信诈骗的防范为例，通过大数据分析，可以实现对电信诈骗的搜索查找、预警拦截和实时记录。2021 年，公安部就利用大数据技术推出了 “国家反诈中心”应用软件，为安装用户提供高效预警、快速举报的功能。

为了建立反应迅速、覆盖全面的预警机制，应当继续坚持大数据预警方法。大数据预警主要分为虚假信息的源头发现、识别和终端拦截三个流程。在第一阶段，利用大数据分析、机器学习、模式识别等多种技术从源头上发现虚假信息发布平台; 第二阶段，通过关键词识别、黑名单来电预警、建模预警帮助识别虚假信息; 第三阶段，在电脑、手机等终端安装安全软件或手机应用，进行终端拦截。 $\textcircled{3}$

为提高预警的有效性，政府应当制定详细的应急预案，明确预警信息的发布标准、流程和渠道，确保在发现潜在风险时能够迅速启动预警程序，并通过官方网站、社交平台、手机短信等多种方式发布预警信息，以实现虚假信息预警全覆盖。在预警结束后，有关部门应当及时收集反馈信息，对预警效果进行评估，总结经验教训，不断完善预警机制，提高预警的准确性和时效性。

# ( 三) 构建责任明确、分级分类的辟谣制度

前文指出，我国当前的专门性辟谣平台影响有限，需要完善的两个方向如下:

其一，建立责任明确的辟谣制度，特别是要强化内容平台、普通内容发布者和专业媒体的辟谣责任。在传统的专业生产内容 ( PGC) 时代，专业媒体是主要的内容发布者，而在如今用户也参与生产内容 ( UGC) 的大众传播环境下，呈现 PGC 和 UGC 交织共存的传播生态。由于专业媒体和普通用户都是重要的内容发布者， $\textcircled{4}$ 故两者均应承担对所发布内容的辟谣义务。虽然这两类主体的辟谣义务在 《民法典》中都有所体现，但均偏重对个体名誉的救济，而非普遍意义上的辟谣责任。 $\textcircled{1}$ 就消除虚假信息的外溢影响而言，应当对其普遍性的辟谣义务予以明确。至于内容平台，其辟谣义务体现为对辟谣内容促进传播的义务，因为在如今的传播生态下，平台的推荐算法决定了哪些内容可被广泛浏览抑或无人问津。这意味着，若无平台辅助，内容发布者的辟谣很容易变成无效辟谣，因此需要明确规定平台的辟谣推进义务，要求其设置相应的栏目，采取优先推送措施，并设计有效算法，将辟谣内容精准投送给曾经浏览相应虚假内容的用户。

其二，建立分级分类的专门辟谣制度。社会心理学研究表明，谣言的传播强度与信息的重要程度、信息的不透明程度高度相关。 $\textcircled{2}$ 辟谣平台应当根据不同的信息特性，对虚假信息进行精细的分级分类。申言之，中央级别的互联网联合辟谣平台应当制定、发布各类信息的分级分类执行细则，按照不透明度、受众接受度、紧要性、危害性等指标编制虚假信息类目，并分别设置有针对性的辟谣及时性要求和辟谣策略。比如，对涉及政治稳定、国家安全、社会舆论等方面的信息，应当以与其他权威媒体联动的形式迅速辟谣，确保辟谣信息的可信度和及时性。此外，当前的官方辟谣平台较少涉及对个人虚假信息的澄清，接下来可以尝试设置相应板块，这不仅有助于保护个人名誉权，还可帮助辟谣平台获得更高的关注度，解决前述官方辟谣平台空转的问题。

# ( 四) 针对 “深度伪造抗辩”设置抗辩人的举证责任

在司法实践中，越来越多的证据以电子数据的形式呈现，在证明案件事实方面发挥着重要作用。不过，电子数据证据既存在被深度伪造技术篡改的风险，也面临 “深度伪造抗辩”的可能。因此，法官应当保持审慎思维，谨慎对待具有深度伪造嫌疑的证据。

如前所述，在技术层面，深度伪造防御技术以及区块链技术能够为检测和保存电子数据提供保障。法院或当事人都可以对电子数据进行鉴定或者申请鉴定，以确保证据的真实性。但是，这仍然不能避免某些当事人利用 “深度伪造抗辩”故意拖延诉讼程序、干扰法官自由心证，以获得 “说谎者红利”的可能。因此，法律需要为当事人发动 “深度伪造抗辩”设定条件，限制其滥用。换言之，如果一方当事人提出对方的证据系深度伪造，以此进行抗辩，那么，抗辩方对伪造事实的存在应当承担初步的证明责任，例如提交初步的检测报告。也就是说，当事人提出“深度伪造抗辩”必须基于一定的事实基础，而不能在毫无根据的情况下信口雌黄。 $\textcircled{3}$ 进而，法官需要审查判断，如果认为明显不可能具有伪造事实的，对当事人的 “深度伪造抗辩”应不予采信。一般情况下，针对书证、物证等不太可能实施深度伪造的证据，不能提出 “深度伪造抗辩”。如若当事人有相反证据，足以推翻有关电子数据证据的真实性推定的，则可以认为相关证据存在伪造可能。在这种情况下，法院应当委托专业鉴定机构对有关电子数据进行鉴定，并结合其他证据综合判断待证事实存在与否。

# 结 语

日前，著名人工智能专家约书亚·本吉奥 ( Yoshua Bengio) 指出，人工智能主要存在三类风险: 恶意使用风险、功能故障风险和系统性风险。针对这三类风险，当前的风险评估和降低风险的方法存在局限性，因为我们对人工智能的理解仍然不够深入。例如，我们并不完全理解当前的 AI 模型即神经网络，它们是如何作出决策、如何得到特定输出的，从而给风险管理带来了挑战。面对这些挑战，我们需要加大对 AI 安全研究的投入，开发更有效的风险评估和降低风险的方法。 $\textcircled{1}$ 对于深度伪造而言，它所带来的是非常典型的恶意使用风险。深度伪造的生成与鉴别技术也一直处于 “道高一尺，魔高一丈”的博弈之中。

为了有效应对深度伪造滥用带来的侵害公民权益、破坏社会信任体系、威胁国家安全和政治稳定等现实威胁，需要建立更完善的内容标识、预警机制和辟谣机制，并为 “深度伪造抗辩”设置相应的举证责任。不过，必须指出，这些措施还只是停留在 “术”的层面，寻求深度伪造技术的治理之 “道”，需要跳出 “头痛医头、脚痛医脚”的线性思维模式，以更全面、更系统地思考人工智能的风险治理，否则就会被问题牵着鼻子走，最终陷入 “按下葫芦浮起瓢”的怪圈。

全面地、系统地思考人工智能的风险治理，意味着不能简单地将人工智能视作一个纯粹的“技术”问题，尤其不能仅仅依靠技术主义路径和单一的场景化逻辑，而应当将其作为一个随着新技术的发展而涌现的社会问题来看待。社会问题需要遵循社会问题的治理逻辑。人工智能的治理，除了技术专家的参与， “人文和社会科学领域的学者专家一定要站到这个舞台的中央 $r _ { \bigstar } ( \ r _ { 2 } )$ ，更重要的是，也要加强社会的参与，“加强公众对人工智能的认知与理解，提高公众对人工智能安全性的认识，提升公众的数字素养与安全意识” $\textcircled { 3 }$ 。唯有如此，才能推动人工智能健康发展，赋能人类共同的福祉和未来。

责任编辑: 李天卿

velopment of the AI industry． Currently，there are doctrinal obstacles to incorporating AI into the category of inventors，and the relevant provisions of patent law need to be improved． The recognition of inventorship should be defined as a public mechanism for disclosing the origin of the invention，while patent rights should be viewed as a mechanism for distributing the market benefits of inventions． In terms of recognizing the “creative contribution”of inventors in the age of AI，it is necessary to adapt the current framework to the characteristics of the invention model in the AI era，and to distinguish between natural persons and AI when assigning inventorship．

Keywords: generative artificial intelligence; inventorship; incentivizing innovation; patent law

# Misuse and Legal Regulation of Deepfake Technology

Liu Dongliang，Huang An，Yang Xiaoke

Abstract: Deepfake technology is a derivative of generative artificial intelligence． Due to its synthetic nature，this technology carries inherent risks of distortion and is prone to generating and spreading false information． It not only infringes on the legitimate rights of citizens but also erodes social trust，threatens political stability，and poses challenges to evidence review in judicial trials． While existing legal norms provide basic directions and paths for regulating the misuse of deepfake technology，there is still significant room for improvement． It is necessary to establish a uniform and explicit content identification system，create a rapid －response and comprehensive early warning mechanism，develop a clear and tiered rumor refutation system，and establish rules for the burden of proof for“deepfake defense”in order to address the challenges posed by deepfake technology．

Keywords: deepfake; legal regulation; false information; rumor refutation mechanism; electronic data

# China's Family Culture and Traditional Residential Architecture

Zhou Daming

Abstract: In recent years，the study of family culture and traditional residential architecture in China has sparked continuous theoretical discussions in the fields of anthropology，sociology，ethnology，and even architecture，leading to an active exploration of Chinese family culture and architectural practices within academia． This paper focuses on the relationship between family culture and traditional residential architecture，discussing the connotations and significance of Chinese family culture． It also highlights the social phenomena and family conflicts that arise from their inherent connection，further exploring the role of the “traditional residential architecture”concept in village development planning，architectural design，spa